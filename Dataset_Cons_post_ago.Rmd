---
title: "Dataset Consolidation"
output:
  distill::distill_article:
    code_folding: true
    fig_height: 6
    fig_width: 8
    theme: spacelab
    toc: yes
    toc_depth: 5
    toc_float: yes
    output_dir: "docs"
---

```{css zoom-lib-src, echo = FALSE}
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

```{=html}
<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
  border: 1px solid black;
  }
.centrado {
  text-align: center;
}
.table.center {
  margin-left:auto; 
  margin-right:auto;
}
.table_wrapper{
  display: block;
  overflow-x: auto;
  white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
    text-align: justify;
}
.superbigimage{
  overflow-y:scroll;
  white-space: nowrap;
}
.superbigimage img{
  overflow-y: scroll;
  overflow-x: hidden;
}
p.comment {
  background-color: #FF7F79;
    padding: 10px;
  border: 1px solid black;
  margin-left: 25px;
  border-radius: 5px;
  font-style: italic;
}
</style>
```
```{=html}
<style>
  p.comment {
    background-color: #ff9a9a;
      padding: 10px;
    border: 1px solid red;
    margin-left: 25px;
    border-radius: 5px;
    font-style: italic;
  }

</style>
```
```{r setup0, include=FALSE}
rm(list=ls());gc()
# xaringan::inf_mr()
```

```{r setup, include=FALSE}
#arriba puse algunas opciones para que por defecto escondiera el código
#también cargue algunos estilo .css para que el texto me apareciera justificado, entre otras cosas.
#*local({r <- getOption("repos")
#*       r["CRAN"] <- "http://cran.r-project.org" 
#       options(repos=r)
#})

try(unlink('C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/Dataset_Cons_post_ago_cache', recursive = TRUE))

`%>%` <- magrittr::`%>%`
copiar_nombres <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  

unlink('Dataset_Cons_post_ago_cache', recursive = TRUE) #para borrar datos alojados en cache
pacman::p_unlock(lib.loc = .libPaths()) #para no tener problemas reinstalando paquetes
knitr::opts_chunk$set(echo = TRUE)
#dejo los paquetes estadísticos que voy a utilizar
try(devtools::install_github("joachim-gassen/tidycovid19", quiet=T,  upgrade="never"))   
try(if(!require(rWBclimate)){devtools::install_github("ropensci/rWBclimate", quiet=T,  upgrade="never")})
try(if(!require(WHOmortality)){devtools::install_github("eugejoh/WHOmortality", quiet=T,  upgrade="never")})
try(if(!require(wwmetrics)){devtools::install_github("emlaet/wwmetrics", quiet=T,  upgrade="never")})
try(if(!require(ExPanDaR)){devtools::install_github("joachim-gassen/ExPanDaR", quiet=T,  upgrade="never")})

if(!require(polycor)){install.packages("polycor")}
if(!require(ggcorrplot)){install.packages("ggcorrplot")}
if(!require(codebook)){install.packages("codebook")}
if(!require(plotly)){install.packages("plotly")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(htmlwidgets)){install.packages("htmlwidgets")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(gganimate)){install.packages("gganimate")}
if(!require(gapminder)){install.packages("gapminder")}
if(!require(gifski)){install.packages("gifski")}
if(!require(readr)){install.packages("readr")}
if(!require(stringr)){install.packages("stringr")}
if(!require(data.table)){install.packages("data.table")}
if(!require(DT)){install.packages("DT")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(ggseas)){install.packages("ggseas")}
if(!require(lattice)){install.packages("lattice")}
if(!require(forecast)){install.packages("forecast")}
if(!require(zoo)){install.packages("zoo")}
if(!require(panelView)){install.packages("panelView")}
if(!require(janitor)){install.packages("janitor")}
if(!require(rjson)){install.packages("rjson")}
if(!require(estimatr)){install.packages("estimatr")} 
if(!require(jsonlite)){install.packages("jsonlite")}
if(!require(RJSONIO)){install.packages("RJSONIO")}
if(!require(RCurl)){install.packages("RCurl")}
if(!require(textreg)){install.packages("textreg")}
if(!require(sjPlot)){install.packages("sjPlot")}
if(!require(geojson)){install.packages("geojson")}
if(!require(rworldmap)){install.packages("rworldmap")}
if(!require(tweenr)){install.packages("tweenr")}
if(!require(ggthemes)){install.packages("ggthemes")}
if(!require(rgeos)){install.packages("rgeos")}
if(!require(curl)){install.packages("curl")}
if(!require(countrycode)){install.packages("countrycode")}
if(!require(wbstats)){install.packages("wbstats")}
if(!require(climate)){install.packages("climate")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(raster)){install.packages("raster")}# raster spatial data processing
if(!require(rasterVis)){install.packages("rasterVis")}
if(!require(sf)){install.packages("sf")}# vector spatial data processing
if(!require(sp)){install.packages("sp")}
if(!require(ncdf4)){install.packages("ncdf4")}
if(!require(rgdal)){install.packages("rgdal")}
if(!require(rnaturalearth)){install.packages("rnaturalearth")}
if(!require(rnaturalearthdata)){install.packages("rnaturalearthdata")}
if(!require(future)){install.packages("future")}

Sys.setlocale(category = "LC_ALL", locale = "english")

```

# First Join of the Datasets

## date: `r format(Sys.time(), '%d %B, %Y')`

In first place, we downloaded the data and count the amount of rows that every country in a single date. The following countries show more than one entry in each single date:

```{r setting, echo=T, cache= T, paged.print=TRUE, warning=F}
#xaringan::inf_mr()
jhudata <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv", sep=",", encoding="UTF-8", header=T)

jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(dates<lubridate::parse_date_time(as.character("11.01.2020"),"%m.%d.%y")) %>% 
#:#:#:#:#:#:#:#:
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 1: ', htmltools::em('Countries with more than one entry by date')))
```

<br>

We explored these countries, and found that Australia, Canada, China & France had the information dis aggregated by provinces. In contrast, United Kingdom, Netherlands & Denmark had an entry that seems to be the total amount of cases by date. For the former countries, we collapsed the information by getting the sum of the cases by province; but for the latter, we dropped the reports regarding provinces or regions. This let us have one a dataset with one entry by country and date.

<br>

```{r setting2, echo=T, cache= T, paged.print=TRUE, warning=F,message=F}
coronavirus<-
jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(dates<lubridate::parse_date_time(as.character("11.01.2020"),"%m.%d.%y")) %>% 
#:#:#:#:#:#:#:#:
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  #elimino a los casos distintos
  dplyr::mutate(descarte=case_when(country=="United Kingdom"&Province.State!=""~1,
                          country=="Netherlands"&Province.State!=""~1,
                          country=="Denmark"&Province.State!=""~1,
                          TRUE~0))%>%
  dplyr::filter(descarte==0)%>%
  #genero una suma para cada fecha por país
  dplyr::group_by(country, dates)%>%
  dplyr::summarise(cases=sum(sum,na.rm=T))%>%
  dplyr::ungroup()%>%
  dplyr::group_by(country)%>%
  dplyr::mutate(ndays_zero=row_number())%>%
 # dplyr::filter(cases>0)%>%
  dplyr::ungroup()
```

<br>

Next, we added a 3-letter ISO format to every country and a date column in ISO 8601 format (YYYY-MM_DD). We used data available from the following [webpage] (<https://ourworldindata.org/coronavirus-source-data>). However, some countries did not match any of the available labels, as can be seen in the following table. For more information about the official, please go to the following [link](https://unstats.un.org/unsd/methodology/m49/).

<br>

```{r setting3, echo=T, cache= T, paged.print=TRUE, warning=F}
owid_covid_data <- readr::read_csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv")%>%
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(date<as.Date("2020-11-01")) %>% 
#:#:#:#:#:#:#:#:
  distinct(iso_code,.keep_all=T) 
#Aplicando distinct, nos permite que no se generen valroes duplicados en la combinación de bases de datos.

coronavirus%>%
    dplyr::left_join(dplyr::select(owid_covid_data,location,iso_code), by=c("country"="location"))%>% dplyr::filter(is.na(iso_code))%>% group_by(country) %>% 
  dplyr::summarise("% w/ missing values"=scales::percent(sum(is.na(iso_code))/max(ndays_zero)))%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 2: ', htmltools::em('Not matched countries w/ Owid Data')))
  #combinar con otra base de datos que tiene los iso. 

earlyDate<-min(coronavirus$dates)
```

<br>

We decided to work with some of these countries, particularly those with a greater population, testings or more relevant public policies. That is why we only changed the names of "US" "South Korea", "Taiwan", "Congo "Congo (Kinshasa)", "Democratic Congo", "Burma" and "Czechia". The rest of countries will be dropped, since they were not eligible for further analysis. The Diamond Princess & the MS Zaandam are ships. Also, we had information of China since January 22, 52 days after the first case in Dec. 1st of 2019. We added 52 days to China. Update 2021, October: Czhechia & Eswatini did not need a conversion.

<br>

```{r setting4, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus%>%
    dplyr::mutate(country=case_when(country=="Korea, South"~"South Korea",
                                    country=="Taiwan*"~"Taiwan",
                                    country=="Congo (Kinshasa)"~"Democratic Republic of Congo",
                                    country=="Congo (Brazzaville)"~"Congo",
                                    country=="Cabo Verde"~"Cape Verde",
                                    #country=="Czechia"~"Czechia",
                                    #country=="Eswatini"~"Swaziland",
                                    country=="Timor-Leste"~"Timor",
                                    country=="Burma"~"Myanmar",
                                    country=="US"~"United States",TRUE~country))%>%
    #combinar con otra base de datos que tiene los iso. 
    dplyr::left_join(owid_covid_data,location, by=c("country"="location"), suffix=c("","owid"))%>% 
    dplyr::filter(!is.na(iso_code))%>% #me baja de 32,148 a 30,096
    #group_by(country) %>% summarise(perc_days_with_nas=sum(is.na(iso_code))/max(ndays))%>%datatable()
    assign("coronavirus_iso3c",., envir = .GlobalEnv)

invisible("IMPORTANTE: Ver que no se pierdan países con OWID data")

corona_no_day_zero<-
    coronavirus_iso3c%>%
    dplyr::group_by(iso_code)%>%
    dplyr::filter(cases>0)%>%
    #assigned china +52 days since 01-12-2019
    dplyr::mutate(ndays=case_when(iso_code=="CHN"~as.numeric(row_number())+52,
                                  TRUE~as.numeric(row_number()))) %>% 
  dplyr::ungroup()
  
  coronavirus_iso3c%>%
    dplyr::left_join(dplyr::select(corona_no_day_zero,iso_code,dates,ndays),by=c("iso_code"="iso_code","dates"="dates"))%>%
    dplyr::select(country,dates,cases,ndays_zero,iso_code,continent,population,population_density,
                  median_age,aged_65_older,aged_70_older,gdp_per_capita,extreme_poverty,
                  diabetes_prevalence,female_smokers,male_smokers,handwashing_facilities,hospital_beds_per_thousand,
                  life_expectancy,ndays)%>%
    assign("coronavirus_iso3c",., envir = .GlobalEnv)
```

<br>

WHO data may have errors regarding cumulative number of cases, as shown below. **It is important to solve these type of errors somehow**.

<br>

```{r test_serial, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c%>%
  dplyr::arrange(iso_code, dates)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate(lag_cases=dplyr::lag(cases),
                lag_dates=dplyr::lag(dates),
                diff_cases=cases-lag_cases)%>%
  dplyr::filter(diff_cases<0)%>%
  dplyr::select(country,iso_code,dates,cases,lag_cases,lag_dates)%>%
  datatable( filter = 'top',caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 3: ', htmltools::em('Problems with serial report of New Cases by Countries')))
```

# Deaths JHU

We joined the confirmed cases with WHO Datasets.

<br>

```{r set_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
jhudata <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv", sep=",", encoding="UTF-8", header=T)

jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(dates<lubridate::parse_date_time(as.character("11.01.2020"),"%m.%d.%y")) %>% 
#:#:#:#:#:#:#:#:
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%
    datatable(caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 4: ', htmltools::em('Countries with more than one entry by date, data of deaths')))
```

<br>

We explored these countries, and found that Australia, Canada, China France had the information disaggregated by provinces. In contrast, United Kingdom, Netherlands & Denmark had an entry that seems to be the total amount of cases by date. For the former countries, we collapsed the information by getting the sum of the cases by province; but for the latter, we dropped the reports regarding provinces or regions. This let us have one a dataset with one entry by country and date.

<br>

```{r set_deaths2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_deaths<-
  jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(dates<lubridate::parse_date_time(as.character("11.01.2020"),"%m.%d.%y")) %>% 
#:#:#:#:#:#:#:#:
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  #elimino a los casos distintos
  dplyr::mutate(descarte=case_when(country=="United Kingdom"&Province.State!=""~1,
                                   country=="Netherlands"&Province.State!=""~1,
                                   country=="Denmark"&Province.State!=""~1,
                                   TRUE~0))%>%
  dplyr::filter(descarte==0)%>%
  dplyr::mutate(country=case_when(country=="Korea, South"~"South Korea",
                                country=="Taiwan*"~"Taiwan",
                                country=="Congo (Kinshasa)"~"Democratic Republic of Congo",
                                country=="Congo (Brazzaville)"~"Congo",
                                country=="Cabo Verde"~"Cape Verde",
                                #country=="Czechia"~"Czech Republic",
                                #country=="Eswatini"~"Swaziland",
                                country=="Timor-Leste"~"Timor",
                                country=="Burma"~"Myanmar",
                                #country=="North Macedonia"~"Macedonia",
                                
                                country=="US"~"United States",TRUE~country))%>%
  #genero una suma para cada fecha por país
  dplyr::group_by(country, dates)%>%
  dplyr::summarise(cases=sum(sum,na.rm=T))%>%
  dplyr::ungroup()%>%
  dplyr::group_by(country)%>%
  dplyr::mutate(ndays_zero=row_number())%>%
  # dplyr::filter(cases>0)%>%
  dplyr::rename("cases_deaths"="cases")%>%
  dplyr::ungroup()

if(
coronavirus_deaths%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%nrow()
>0){"still problems with duplicated data"}
```

<br>

Next, we merged this dataset with our consolidated dataset. However, must notice that, similar to the dataset of cases, some countries could not be matched, as can be seen in the following Table.

<br>

```{r set_deaths3, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_deaths%>%
  dplyr::left_join(coronavirus_iso3c, by="country", suffix=c("","_cons"))%>% 
  dplyr::filter(is.na(iso_code))%>% 
  group_by(country) %>% 
  dplyr::summarise("% w/ missing values"=scales::percent(sum(is.na(iso_code))/max(ndays_zero)))%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 5: ', htmltools::em('Not matched countries of Deaths w/ Consolidated Dataset')))
  #combinar con otra base de datos que tiene los iso. 
earlyDate_deaths<-min(coronavirus_deaths$dates)

```

<br>

```{r cons_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c%>%
  #combinar con otra base de datos que tiene los iso. 
  dplyr::left_join(coronavirus_deaths, by=c("country","dates"), suffix=c("","_deaths"))%>% 
  #group_by(country) %>% summarise(perc_days_with_nas=sum(is.na(iso_code))/max(ndays))%>%datatable()
  dplyr::mutate(text= paste("Country:", country,"<br> Dates:", dates,"<br> Cum.cases:",formatC(cases, format="f", big.mark=",", digits=0),"<br> No. Days Since 1st Case:",ndays, "<br> Cum.deaths:",formatC(cases_deaths, format="f", big.mark=",", digits=0)))%>%
  assign("coronavirus_iso3c_1",., envir = .GlobalEnv)
Sys.setlocale(category = "LC_ALL", locale = "english")
gg<- ggplot(data=coronavirus_iso3c_1,aes(x= dates, y=log10(cases_deaths),group=iso_code, text= text, color=iso_code))+
   geom_line()+
  sjPlot::theme_sjplot2() +
theme(panel.border = element_blank(),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.line = element_line(colour = "black"),
      plot.margin = margin(5.5, 40, 5.5, 5.5))+
    #scale_x_date(date_breaks= "14 days", date_minor_breaks = "7 days", date_labels = "%m/%d") +
    theme(plot.caption = element_text(hjust = 0, face= "italic"))+
    theme(plot.tag.position =  c(.81,0.01),
          plot.tag = element_text(hjust = -.05, size=8,
                                  margin = margin(l = 10)))+
   # xlim(c(earlyDate,lastDate))+
   # scale_y_log10(labels = scales::trans_format("log10", scales::math_format(10^.x)))+
    theme(legend.position = "none", axis.title.x = element_blank())

ggplotly(gg,tooltip = "text", dynamicTicks=T) 
```

<br>

WHO data does not show errors regarding cumulative number of deaths, as shown below.

<br>

```{r test_serial_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_1%>%
  dplyr::arrange(iso_code, dates)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate(lag_cases=dplyr::lag(cases_deaths),
                lag_dates=dplyr::lag(cases_deaths),
                diff_cases=cases-lag_cases)%>%
  dplyr::filter(diff_cases<0)%>%
  dplyr::select(country,iso_code,dates,cases,lag_cases,lag_dates)%>%
  datatable(caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 6: ', htmltools::em('Problems with serial report of New Deaths by Countries')))
if(
coronavirus_iso3c_1%>%
    dplyr::mutate(error_no_days=ifelse(ndays_zero!=ndays_zero_deaths,1,0))%>%
    dplyr::filter(error_no_days==1)%>% nrow()>0
){"there are some cases with different days available in datasets of deaths and new cases"}
```

# Oxford Dataset

Academics from the University of Oxford have launched a dataset that track government responses (<https://www.bsg.ox.ac.uk/sites/default/files/2020-06/Lockdown%20Rollback%20Checklist%20v4.pdf>). This tool tracks the following indicators: - school closure; - workplace closures; - public event cancellation; - public transport closure; - public information campaigns; - restriction on internal movement; - international travel controls; - fiscal measures; - monetary measures; - emergency investment in healthcare; - investment in vaccines.

Then, they generated an index that compares the stringency of policy responses by countries. Despite the 'Stringency Index' is not a direct measure of "the appropriateness or effectiveness of a country's response" to the evolution of contagion, may be useful to understand measures that could be effective in determined periods and countries.

<br>

```{r set_oxford, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, fig.cap="Figure 2. Linear Trends of Stringency Index by Country"}
library(readr)
OxCGRT_latest <- read_csv("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv")%>%
                  dplyr::mutate(Date=as.Date(as.character(Date), "%Y%m%d"))%>% 
                  janitor::clean_names() %>% 
#:#:#:#:#:#:#: Nov 2020- filter until october 2020
  dplyr::filter(date<"2020-11-01") 
#:#:#:#:#:#:#:#:
    
#oxf_npi<- download_oxford_npi_data(cached = TRUE, silent = TRUE)
#oxf_npi<- https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv

OxCGRT_latest_join<-
    OxCGRT_latest%>%
      #dplyr::group_by(CountryCode, Date)%>% 
      dplyr::select(country_code,country_name, date,stringency_index)
Sys.setlocale(category = "LC_ALL", locale = "english")


plot_ly(
  x     = ~date, y = ~stringency_index, 
  color = ~country_code,
  data  = OxCGRT_latest,
  type = 'scatter',
        mode = 'lines')%>%
  layout(showlegend = FALSE)%>%
 # highlight(on = "plotly_click",off = "plotly_doubleclick")
  #highlight(on = "plotly_hover", off = "plotly_deselect", color = "red")
  highlight(on="plotly_hover",off="plotly_deselect",color="blue",opacityDim=.2, persistent = F)%>%
  layout(xaxis=list(spikethickness=4, spikecolor="gray50"))%>%
  layout(scene = list(
      xaxis = list(title = "Date"),
      yaxis = list(title = "Stringency Index")))


#BASE DE DATOS OXFORD Y CORONAVIRUS. UNION
coronavirus_iso3c_1%>%
    dplyr::mutate(iso_code= ifelse(iso_code=="OWID_KOS","RKS", as.character(iso_code)))%>%
    dplyr::left_join(dplyr::select(OxCGRT_latest_join,-country_name),by=c("iso_code"="country_code","dates"="date"))%>%
    dplyr::rename("stringency_ind_oxf"="stringency_index")->
                "coronavirus_iso3c_2"

unmatched_2_no_inf_on_quarantene<-
  coronavirus_iso3c_2%>% 
    dplyr::filter(is.na(stringency_ind_oxf))%>% 
    dplyr::group_by(iso_code)%>% 
    dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
    dplyr::filter(N>=100)%>%
    dplyr::ungroup()%>%
    distinct(iso_code)%>%
    unlist()%>%
  as.character()
```

<br>

In case of Kosovo, we changed the ISO 3 code created by OWID dataset (OWID_KOS) in order to match with Oxford (RKS), but we must take note that Kosovo could be identified with the letters "XKO". In contrast, we selected countries that did not had information on specific dates. These missing values tend to be present on most recent dates. Possibly due to lack of updates on Oxford datasets.

<br>

```{r set_oxford2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
#para ver el comportamiento de los países en iso3 que no calzan con la base de datos de las medidas de oxford
#
#coronavirus_iso3c_2%>% 
#  dplyr::filter(iso_code %in% unmatched_2_no_inf_on_quarantene)%>% View()
coronavirus_iso3c_2%>% 
    dplyr::filter(is.na(stringency_ind_oxf))%>% 
    dplyr::group_by(iso_code,country)%>% 
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N<=100,N>1)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 7: ', htmltools::em('Dates with missing values on each country in Stringency Index as a result of the match')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '80%'});",
        "}")))

```

<br>

Reversely, the following countries did not join with our database. Most of these countries are still in a complicated position in terms of geopolitical matters.

<br>

```{r set_oxford3, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
OxCGRT_latest_join%>%
    dplyr::anti_join(coronavirus_iso3c_2,by=c("country_code"="iso_code","date"="dates"))%>%
    dplyr::filter(date>="2020-01-22")%>%
    group_by(country_code,country_name)%>%
    dplyr::summarise(N=n(),first_date=min(date),last_date=max(date))%>%
    dplyr::filter(N>10)%>%
      datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
                caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 8: ', htmltools::em('Countries of Oxford Dataset that did not match with the merged database')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '80%'});",
        "}")))

#"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
#coronavirus%>% dplyr::filter(grepl("Guam",country)), por lo visto no hay ninguno

#OxCGRT_latest_join%>%
    #dplyr::mutate(country_code= dplyr::case_when(country_code=="ABW"~"NLD",
    #                                             country_code=="AIA"~"GBR",
    #                                             country_code=="BMU"~"GBR",
    #                                             country_code=="CYM"~"GBR",
    #                                             country_code=="FLK"~"GBR",
    #                                             country_code=="GIB"~"GBR",
    #                                             country_code=="GRL"~"DNK",
    #                                             country_code=="GUM"~"USA",
    #                                             country_code=="MAC"~"CHN",
    #                                             country_code=="HKG"~"CHN",
    #                                             country_code=="MSR"~"GBR",
    #                                             country_code=="PCN"~"GBR",
    #                                             country_code=="PRI"~"USA",
    #                                             country_code=="TCA"~"GBR",
    #                                             country_code=="VGB"~"GBR",
    #                                             country_code=="VIR"~"USA"
    #                                             TRUE~country_code)) %>% 
#BASE DE DATOS OXFORD Y CORONAVIRUS. UNION
#coronavirus_iso3c_1%>%
#    dplyr::mutate(iso_code= ifelse(iso_code=="OWID_KOS","RKS", as.character(iso_code)))%>%
#    dplyr::left_join(dplyr::select(OxCGRT_latest_join,-country_name),by=c("iso_code"="country_code","dates"="date"))%>%
#    dplyr::rename("stringency_ind_oxf"="stringency_index")->
#                "coronavirus_iso3c_2"
```

<br>

As seen in the Table above, some countries did not appear in the JHU database. Some of them were islands or departaments of other countries (UK, USA or China), and some others such as Vanuatu had no information in JHU database.

<br>

Once the dataset is merged, we may see that some variables still have missing data in different variables (Table 10). Most of them are available or not by country, because this measure was not available for the whole country (time-invariant variable), and not only for a single or few days, excepting for `stringency_ind_oxf`, which had missing values because of the updates, as seen in Table 7.

<br>

```{r set_wb_oxf_miss1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_2%>%
  dplyr::select(-ndays_zero_deaths, -text, -ndays)%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:stringency_ind_oxf),~scales::percent(sum(is.na(.))/n()))%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 9. Percentage of Missing data in the Different Time Points By Country"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_2),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

<br>

We can see the variables that had the most share of missing values in the following table.

<br>

```{r set_wb_oxf_miss2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_2%>%
  dplyr::select(-ndays_zero_deaths, -text, -ndays)%>%
    summarise_at(vars(population:stringency_ind_oxf),~scales::percent(sum(is.na(.))/n()))%>%
  data.frame()%>% t()%>%  data.table::as.data.table(keep.rownames = T)%>% 
#rmarkdown::paged_table(options = list(rows.print = 15, cols.print = 5))
datatable(filter = 'top', colnames = c('Row number' =1,'Variable' = 2, 'Percentage'= 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 10: ', htmltools::em('Percentage of Missing data in the Different Time Points & Country By Variables')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
  # 
  # knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
  #              caption = paste0("Table 10. Percentage of Missing data in the Different Time Points & Country By Variables"),
  #              align =rep('c', 101),
  #              col.names = c("Variables", "% of Miss.")) %>%
  # kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  # kableExtra::add_footnote( c("Note. "), 
  #                           notation = "none") %>%
  # kableExtra::scroll_box(width = "100%", height = "375px")

#rm(list=setdiff(ls(), c("coronavirus_iso3c_2","copiar_nombres")))
```

<br>

# Environmental Datasets

## World Bank Climate Data

We joined the dataset with `ropensci/rWBclimate` [repository](https://github.com/ropensci/rWBclimate), which is an R interface for the World Bank climate data used in the World Bank climate knowledge portal. Unfortunately, Kosovo (RKS), South Sudan (SSD), was not in the datasets. **This is very strange, because "SSD" notation is present in UN coding**. We obtained the monthly historical average temperature for each country, based on records from 1901 to 2009. The average obtained by month will depend on the historical data available by country. Additionally, we obtained the average indicator of decade for each variable, selecting the data related to 2010. **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_wb_climate, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=F}

    #https://cran.r-project.org/web/packages/rWBclimate/rWBclimate.pdf
    #Monthly average	The monthly average for all 12 months for a given time period
    #Annual average	a single average for a given time period
    #Monthly anomaly	Average monthly change (anomaly). The control period is 1961-1999 for temperature and precipitation variables, and 1961-2000 for derived statistics.
    #Annual anomaly	Average annual change (anomaly). The control period is 1961-1999 for temperature and precipitation variables, and 1961-2000 for derived statistics.
    #install.packages("rWBclimate")
    #https://github.com/ropensci/rWBclimate
#Month will return 12 values, a historical average for that month across all years.

country.list <- coronavirus_iso3c_2 %>% dplyr::filter(!iso_code %in% c("RKS", "SSD"))%>% distinct(iso_code)%>% unlist()%>% as.character()

Sys.setlocale(category = "LC_ALL", locale = "english")
### Grab temp data
global_hist_temp_month <- get_historical_temp(country.list, "month") %>% dplyr::mutate(date_month=stringr::str_extract(month, "^.{3}"))
global_hist_temp_decade <-get_historical_temp(country.list, "decade")

global_hist_prec_month <- get_historical_precip(country.list, "month") %>% dplyr::mutate(date_month=stringr::str_extract(month, "^.{3}"))
global_hist_prec_decade<- get_historical_precip(country.list, "decade")

```

<br>

In order to match with monthly information, we had to transform the databases, including a variable to identify the month of each date, in a three-character format (`date_month`).

<br>

```{r set_wb_climate1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
#rm(list=setdiff(ls(), c("coronavirus_iso3c_2", "global_hist_temp_month", "global_hist_temp_decade","global_hist_prec_month","global_hist_prec_decade")))
Sys.setlocale(category = "LC_ALL", locale = "english")
global_hist_prec_month <- 
global_hist_prec_month%>% dplyr::mutate(date_month=stringr::str_extract(tolower(month), "^.{3}"))
Sys.setlocale(category = "LC_ALL", locale = "english")
global_hist_temp_month <- 
global_hist_temp_month%>% dplyr::mutate(date_month=stringr::str_extract(tolower(month), "^.{3}"))

if(abs(nrow(global_hist_temp_month)-nrow(global_hist_temp_month))>0){
  paste("different amount of rows in the dataset")
}

if(abs(nrow(global_hist_temp_decade)-nrow(global_hist_prec_decade))>0){
  paste("different amount of rows in the dataset")
}
if(abs(nrow(global_hist_temp_decade)-nrow(global_hist_temp_decade))>0){
  paste("different amount of rows in the dataset")
}

if(identical(data.frame(iso=unique(global_hist_prec_month$locator)),data.frame(iso=unique(global_hist_temp_month$locator)))==F){
  paste0("countries obtained are different in the datasets")
}
if(identical(data.frame(iso=unique(global_hist_prec_decade$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)))==F){
  paste0("countries obtained are different in the datasets")
}
if(identical(data.frame(iso=unique(global_hist_prec_month$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)))==F){
  paste0("countries obtained are different in the datasets")
}

global_hist_temp_decade <-global_hist_temp_decade%>% dplyr::filter(year=="2010")
global_hist_prec_decade <-global_hist_prec_decade%>% dplyr::filter(year=="2010")

#all.equal(data.frame(iso=unique(global_hist_prec_decade$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)), tolerance = 0)

#data.frame(isos=unique(global_hist_prec_decade$locator))%>% dplyr::anti_join(data.frame(isos=unique(global_hist_temp_decade$locator)))

Sys.setlocale(category = "LC_ALL", locale = "english")
coronavirus_iso3c_2%>%
    dplyr::select(-ndays_zero_deaths)%>%
    dplyr::mutate(date_month=months(dates),
                  date_month=stringr::str_extract(tolower(date_month), "^.{3}"))%>%
    dplyr::left_join(dplyr::select(global_hist_temp_month,locator,date_month,data),by=c("date_month"="date_month","iso_code"="locator"))%>%
    dplyr::rename("monthly_temp"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_prec_month,locator,date_month,data),by=c("date_month"="date_month","iso_code"="locator"))%>%
    dplyr::rename("monthly_prec"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_temp_decade,locator,data),by=c("iso_code"="locator"))%>%
    dplyr::rename("decade_temp"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_prec_decade,locator,data),by=c("iso_code"="locator"))%>%
    dplyr::rename("decade_prec"="data")%>%
    dplyr::select(country, iso_code, dates, date_month,cases, cases_deaths, ndays,ndays_zero,text,everything())->
  #dplyr::select(dates, date_month)%>% View()
  coronavirus_iso3c_3
```

<br>

The following countries could not be joined with the dataset, because they were not found. From the dataset, it could be possible that dichotomous response of missing vs. not-missing may be explained because there were no monthly differences in availability of information. **We must think about the convenience of including these countries**.

<br>

```{r set_wb_climate2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
coronavirus_iso3c_3%>%
    dplyr::group_by(iso_code, country) %>% 
    summarise_at(vars(monthly_temp:decade_prec),~sum(is.na(.))/n())%>%
    dplyr::ungroup()%>%
    dplyr::mutate(sumVar = rowSums(.[3:6]))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::select(-sumVar)%>%
    dplyr::mutate_at(vars(monthly_temp:decade_prec),~scales::percent(.))%>%
  #dplyr::mutate(sumVar = rowSums(dplyr::select(monthly_temp:decade_prec)))%>% 
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Monthly Temp' = 4,'Monthly Prec' = 5,'Decade Temp' = 6,'Decade Prec' = 7),
              caption = htmltools::tags$caption(
                  style = 'caption-side: top; text-align: left;',
                  'Table 11: ', htmltools::em('Countries of merged dataset that did not match with WB Climate Datasets')),
              options=list(
                  initComplete = JS(
                      "function(settings, json) {",
                      "$(this.api().tables().body()).css({'font-size': '80%'});",
                      "}")))
```

## World Bank Climate Data at 2007

We added the monthly average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal [available in this link](%22https://climateknowledgeportal.worldbank.org/download-data%22). **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_cckp_temp1_07, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/temp.csv")
    },
    error = function(e){
        readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"temp.csv"))
    }
)

temp <- temp%>% 
  dplyr::filter(Year==2007)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,temperature_celsius)%>%
  dplyr::rename("month_temp_07"="temperature_celsius")

temp%>%
  dplyr::anti_join(coronavirus_iso3c_3,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 12: ', htmltools::em('Countries and Months of CCKP dataset (Temp 07) that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")

```

<br>

As seen in Table 12, many countries did not had a 3-letter ISO code, possibly to geopolitical reasons. We replaced the missing values of ISO3 to join the dataset adequately.

<br>

```{r set_cckp_temp2_07, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp07<- 
 temp%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))
 
coronavirus_iso3c_3%>%
  dplyr::left_join(dplyr::select(temp07,iso3,date_month, month_temp_07),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_temp_07))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 13: ', htmltools::em('Countries of our dataset (Temp 07) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_1<-
      coronavirus_iso3c_3%>%
        dplyr::left_join(dplyr::select(temp07,iso3,date_month, month_temp_07),by= c("iso_code"="iso3","date_month"="date_month"))
```

<br>

Then, we added the dataset of rainfalls. We already resolved some of the problems in 3-letter ISO codes in Temperatures dataset.

<br>

```{r set_cckp_rain_07, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain <-tryCatch(
        {
           readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/rainfall.csv")
        },
        error = function(e){
           readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"rainfall.csv"))
        }
)
rain <- rain%>%
  dplyr::filter(Year==2007)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,rainfall_mm)%>%
  dplyr::rename("month_rainfall_mm_07"="rainfall_mm")

rain07 <-
rain%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))

rain%>%
  dplyr::anti_join(coronavirus_iso3c_3,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 14: ', htmltools::em('Countries and Months of CCKP (rain 07) dataset that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

```{r set_cckp_rain2_07, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
coronavirus_iso3c_3%>%
  dplyr::left_join(dplyr::select(rain07,iso3,date_month, month_rainfall_mm_07),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_rainfall_mm_07))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 15: ', htmltools::em('Countries of our dataset (rain 07) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_2<-
        coronavirus_iso3c_3_1%>%
          dplyr::left_join(dplyr::select(rain07,iso3,date_month, month_rainfall_mm_07),by= c("iso_code"="iso3","date_month"="date_month"))
```

<br>

## World Bank Climate Data at 2016

We added the monthly average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal [available in this link](%22https://climateknowledgeportal.worldbank.org/download-data%22). **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_cckp_temp1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/temp.csv")
    },
    error = function(e){
        readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"temp.csv"))
    }
)

temp <- temp%>% 
  dplyr::filter(Year==2016)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,temperature_celsius)%>%
  dplyr::rename("month_temp_16"="temperature_celsius")

temp%>%
  dplyr::anti_join(coronavirus_iso3c_3_2,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 16: ', htmltools::em('Countries and Months of CCKP dataset (Temp) that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")

```

<br>

As seen in Table 16, many countries did not had a 3-letter ISO code, possibly to geopolitical reasons. We replaced the missing values of ISO3 to join the dataset adequately.

<br>

```{r set_cckp_temp2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp<- 
 temp%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))
temp_exp_16_to_recover_later<- temp %>% 
  tidyr::pivot_wider(names_from=date_month,values_from=month_temp_16) %>% 
  dplyr::select(-year)
 
coronavirus_iso3c_3_2%>%
  dplyr::left_join(dplyr::select(temp,iso3,date_month, month_temp_16),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_temp_16))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 17: ', htmltools::em('Countries of our dataset (Temp) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_3<-
      coronavirus_iso3c_3_2%>%
        dplyr::left_join(dplyr::select(temp,iso3,date_month, month_temp_16),by= c("iso_code"="iso3","date_month"="date_month"))
```

<br>

Then, we added the dataset of rainfalls. We already resolved some of the problems in 3-letter ISO codes in Temperatures dataset.

<br>

```{r set_cckp_rain, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain <-tryCatch(
        {
           readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/rainfall.csv")
        },
        error = function(e){
           readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"rainfall.csv"))
        }
)

rain <- rain%>%
  dplyr::filter(Year==2016)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,rainfall_mm)%>%
  dplyr::rename("month_rainfall_mm_16"="rainfall_mm")

rain <-
rain%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))

rain%>%
  dplyr::anti_join(coronavirus_iso3c_3_3,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 18: ', htmltools::em('Countries and Months of CCKP (rain) dataset that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

```{r set_cckp_rain2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
coronavirus_iso3c_3_3%>%
  dplyr::left_join(dplyr::select(rain,iso3,date_month, month_rainfall_mm_16),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_rainfall_mm_16))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 19: ', htmltools::em('Countries of our dataset (rain) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_4<-
        coronavirus_iso3c_3_3%>%
          dplyr::left_join(dplyr::select(rain,iso3,date_month, month_rainfall_mm_16),by= c("iso_code"="iso3","date_month"="date_month"))
```

<br>

## World Bank Climate Data, Aggregated Decennial

We added the decennial average temperature (Celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal, by getting the average number of the available monthly data by country: one from 1997-2006, and other from 2007-2016 [available in this link](%22https://climateknowledgeportal.worldbank.org/download-data%22). **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_cckp_97_06_07_16_temp1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp_agg <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/tmp_1991_2016.csv")
    },
    error = function(e){
        readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"tmp_1991_2016.csv"))
    }
)

temp_agg_97_06 <- temp_agg%>% 
  dplyr::filter(Year>=1997 & Year <= 2006)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,countrycode)%>%
  dplyr::select(countrycode,country,year, statistics,temperature_celsius)%>%
  dplyr::summarise(month_temp_agg97_06=mean(temperature_celsius, na.rm=T))%>%
  dplyr::rename("iso3"="countrycode")%>%
  ungroup()
temp_agg_07_16 <- temp_agg%>% 
  dplyr::filter(Year>=2007 & Year <= 2016)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,countrycode)%>%
  dplyr::select(countrycode,country,year, statistics,temperature_celsius)%>%
  dplyr::summarise(month_temp_agg07_16=mean(temperature_celsius, na.rm=T))%>%
  dplyr::rename("iso3"="countrycode")%>%
  ungroup()

temp_agg_97_06%>%
  dplyr::anti_join(coronavirus_iso3c_3_4,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 20a: ', htmltools::em('Countries and Months of CCKP dataset (Temp) from 1997 to 2006, that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))

temp_agg_07_16%>%
  dplyr::anti_join(coronavirus_iso3c_3_4,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 20b: ', htmltools::em('Countries and Months of CCKP dataset (Temp) from 2007 to 2016, that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")

```

<br>

As seen in Tables 20a & 20b, many countries did not had a 3-letter ISO code, possibly to geopolitical reasons. We replaced the missing values of ISO3 to join the dataset adequately.

<br>

```{r set_cckp_97_06_07_16_temp2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp_agg_97_06<- 
 temp_agg_97_06%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))
temp_agg_07_16<- 
 temp_agg_07_16%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))

coronavirus_iso3c_3_4%>%
  dplyr::left_join(dplyr::select(temp_agg_97_06,iso3,month_temp_agg97_06),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_temp_agg97_06))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 21a: ', htmltools::em('Countries of our dataset (Aggr. Temp 97-06) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_4%>%
  dplyr::left_join(dplyr::select(temp_agg_07_16,iso3,month_temp_agg07_16),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_temp_agg07_16))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 21b: ', htmltools::em('Countries of our dataset (Aggr. Temp 07-16) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_5<-
      coronavirus_iso3c_3_4%>%
  dplyr::left_join(dplyr::select(temp_agg_97_06,iso3,month_temp_agg97_06),by= c("iso_code"="iso3"))%>%
        dplyr::left_join(dplyr::select(temp_agg_07_16,iso3,month_temp_agg07_16),by= c("iso_code"="iso3"))
  
```

<br>

Then, we added the dataset of rainfalls. We already resolved some of the problems in 3-letter ISO codes in Temperatures dataset.

<br>

```{r set_cckp_97_06_07_16_rain1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain_agg <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/pr_1991_2016.csv")
    },
    error = function(e){
        readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"pr_1991_2016.csv"))
    }
)

rain_agg_97_06 <- rain_agg%>% 
  dplyr::filter(Year>=1997 & Year <= 2006)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,iso3)%>%
  dplyr::select(iso3,country,year, statistics,rainfall_mm)%>%
  dplyr::summarise(month_rain_agg97_06=mean(rainfall_mm, na.rm=T))%>%
  ungroup()
rain_agg_07_16 <- rain_agg%>% 
  dplyr::filter(Year>=2007 & Year <= 2016)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,iso3)%>%
  dplyr::select(iso3,country,year, statistics,rainfall_mm)%>%
  dplyr::summarise(month_rain_agg07_16=mean(rainfall_mm, na.rm=T))%>%
  ungroup()

rain_agg_97_06%>%
  dplyr::anti_join(coronavirus_iso3c_3_5,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Rain' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 22a: ', htmltools::em('Countries and Months of CCKP dataset (Rain) from 1997 to 2006, that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))

rain_agg_07_16%>%
  dplyr::anti_join(coronavirus_iso3c_3_5,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Rain' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 22b: ', htmltools::em('Countries and Months of CCKP dataset (Rain) from 2007 to 2016, that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")
```

```{r set_cckp_97_06_07_16_rain2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain_agg_97_06<- 
 rain_agg_97_06%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))
rain_agg_07_16<- 
 rain_agg_07_16%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The, BHS"~"BHS",
                                        iso3=="The, GMB"~"GMB",
                                        grepl("PRK",iso3)~"PRK",
                                        grepl("KOR",iso3)~"KOR",
                                        grepl("TZA",iso3)~"TZA", T~as.character(iso3)))

coronavirus_iso3c_3_5%>%
  dplyr::left_join(dplyr::select(rain_agg_97_06,iso3,month_rain_agg97_06),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_rain_agg97_06))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 23a: ', htmltools::em('Countries of our dataset (Aggr. Temp 97-06) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_5%>%
  dplyr::left_join(dplyr::select(rain_agg_07_16,iso3,month_rain_agg07_16),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_rain_agg07_16))%>%
  dplyr::group_by(iso_code,country)%>%
  dplyr::summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 23b: ', htmltools::em('Countries of our dataset (Aggr. Temp 07-16) that did not match with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_6<-
      coronavirus_iso3c_3_5%>%
  dplyr::left_join(dplyr::select(rain_agg_97_06,iso3,month_rain_agg97_06),by= c("iso_code"="iso3"))%>%
        dplyr::left_join(dplyr::select(rain_agg_07_16,iso3,month_rain_agg07_16),by= c("iso_code"="iso3"))
```

<br>

## NOAA Datasets

This data was obtained from `open-covid-19/weather` repository ([link](https://github.com/open-covid-19/weather)), and takes information from NOAA. It reproduces the last 2 years worth of records for all active stations from the Global Historical Climatology Network from the National Oceanic and Atmospheric Administration. Weather stations which are at most 300km from the location coordinates are considered. However, if we take a look into the nearer 100 stations to Chile, we may see that they could be very different and far away from the centroids, so we may be cautious when using these variables.

<br>

```{r noaa, echo=T, cache= T, paged.print=TRUE,eval=T, fig.height=13,fig.width=4,  warning=F,message=F}
library(climate)
tryCatch(
    {
ns = climate::nearest_stations_nooa(country ="CHILE",#SPAIN NORWAY UNITED KINGDOM
                                    no_of_stations = 100, add_map = TRUE)
    },
    error = function(e){
                    tryCatch(
                            {
                              knitr::include_graphics('C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/map_chile_stations_noaa.png', dpi=96)
                            },
                            error = function(e){
                             knitr::include_graphics('C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/map_chile_stations_noaa.png', dpi=96)
                            }
                    )
          }
)
```

<br>

We checked the process and what they did is to obtain daily information from NOAA ("<https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/>"`{station.id}`".csv"\`), then they got all the weather stations with data up until 2020 from [link](%22https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-inventory.txt%22) and that provide at least max and min temperatures. We included the 3-letter-ISO into the dataset, to let us merge it with out dataset.

<br>

```{r noaa_1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error= T}
index <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/index.csv")

if(file.exists("weather.zip")){
weather <- readr::read_csv(gsub("Dataset_Cons_post_ago.Rmd","weather.zip",rstudioapi::getSourceEditorContext()$path))
} else {
weather <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/weather.csv") 
}

unlink(gsub("Dataset_Cons_post_ago.Rmd","weather.csv",rstudioapi::getSourceEditorContext()$path), recursive = TRUE)

weather2<-
weather %>% 
      dplyr::left_join(dplyr::select(index,key,`3166-1-alpha-3`,aggregation_level),
                       by=c("key"="key"))%>%
      dplyr::filter(aggregation_level==0)%>%
      dplyr::rename("iso_3"=`3166-1-alpha-3`)%>%
      dplyr::select(iso_3,everything())
#rm(list=setdiff(ls(), c("coronavirus_iso3c_3_2","copiar_nombres","weather","index")))
```

<br>

We looked into the countries that could have more than one entry by date.

<br>

```{r noaa_2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
#40190099999
  weather2%>%
         dplyr::group_by(iso_3, date)%>%
         dplyr::mutate(n=n())%>%
         dplyr::filter(n>1)%>%
        dplyr::select(iso_3,date, key,n)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Date' =3,'Key' = 4,'No. of Times' = 5),
              caption = htmltools::tags$caption(
                  style = 'caption-side: top; text-align: left;',
                  'Table 24: ', htmltools::em('Countries with more than one entry by date')),
              options=list(
                  initComplete = JS(
                      "function(settings, json) {",
                      "$(this.api().tables().body()).css({'font-size': '80%'});",
                      "}")))
  
 # <br>

#As can be seen in the following dataset Netherlands Antilles (AN) and Gaza (NZ) were not a member of a recognized state. Most of these countries are still in a complicated position in terms of geopolitical matters. That is why we deleted them from the join with our dataset.
```

<br>

Next, we filtered the dataset starting from Jan. 22, and looked over the dates that did not match with our entries.

<br>

```{r noaa_3, echo=T, cache= T, paged.print=TRUE,eval=T}
#40190099999
weather2%>%
  dplyr::filter(key!="AN"|key!="GZ")%>%
  dplyr::filter(date>="2020-01-22"& date<="2020-12-31")%>%
  dplyr::anti_join(coronavirus_iso3c_3_6,by=c("iso_3"="iso_code","date"="dates"))%>%
  dplyr::left_join(dplyr::select(index,key,`3166-1-alpha-3`,country_name),
                       by=c("key"="key"))%>%
  group_by(iso_3,country_name)%>%
  dplyr::summarise(N=n(),first_date=min(date),last_date=max(date))%>%
  dplyr::filter(N>10)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 25: ', htmltools::em('Countries of NOAA dataset that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

As seen in Table 25, most of these countries are still in a complicated position in terms of geopolitical matters, many are islands and territorial departments of greater countries. **We decided to exclude them from analysis**.

<br>

```{r noaa_4, echo=T, cache= T, paged.print=TRUE,eval=T}
#40190099999
weather3<-
      weather2%>%
        dplyr::filter(key!="AN"|key!="GZ")%>%
        dplyr::filter(date>="2020-01-22")  

  coronavirus_iso3c_3_6%>%
  dplyr::left_join(dplyr::select(weather3,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(dates) %>% 
    summarise_at(vars(noaa_station:rainfall),~sum(is.na(.))/n())%>%
    dplyr::ungroup()%>%
    dplyr::mutate(sumVar = scales::percent(rowSums(.[2:7])/6))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::rename("mean_miss_data_noaa"="sumVar")%>%
    dplyr::mutate_at(vars(noaa_station:rainfall),~scales::percent(.))%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 26. Percentage Dates of our dataset that did not match with NOAA dataset"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_3_2),"observations of the total dataset")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

<br>

We decided to join the dataset but excluding `snowfall` variable, due to lack of information among many countries. Still, there is a considerable amount of missing data. Possibly, this problem may be explained because a determined country or date does not have stations, or because more recent dates are still being updated (such as `r max(coronavirus_iso3c_3_6$dates)`)

<br>

In the following two tables we may see countries with missing information in NOAA stations. In Table 23a, we see that many developed countries did not have information related to climate from NOAA stations.

<br>

```{r noaa_5_1, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_6%>%
  dplyr::left_join(dplyr::select(weather3,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 27a: ', htmltools::em('Missing Information by Country in NOAA Station (In approx. every date)')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
#ESP	Spain  FRA	France FIN	Finland BEL	Belgium	 DNK	Denmark	GBR	United Kingdom	PRT	Portugal NOR	Norway NLD	Netherlands IRL	Ireland ISL	Iceland SWE	Sweden	
```

<br>

Most of these data could not be retrieved because is aggregated by macro-region within countries, but do not represent the whole country. Excluding Eritrea, England in Great Britain & Svalbard in Norway, every country had more than one regional information.**We should discuss what would be inclusion criteria in this matter**.

<br>

```{r noaa_mod_by_find_in_5_1, echo=T, cache= T, paged.print=TRUE,eval=T}
country_noaa_data_only_subregions<-
coronavirus_iso3c_3_6%>%
    dplyr::left_join(dplyr::select(weather3,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    distinct(iso_code)%>%
    unlist()%>%
    as.character()

if(file.exists("weather.zip")){
weather_or <- readr::read_csv(gsub("Dataset_Cons_post_ago.Rmd","weather.zip",rstudioapi::getSourceEditorContext()$path))
} else {
weather_or <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/weather.csv") 
}
weather_or<-
weather_or %>%
    dplyr::left_join(dplyr::select(index,key,`3166-1-alpha-3`,subregion1_name,aggregation_level),
                     by=c("key"="key"))%>%
    dplyr::rename("iso_3"=`3166-1-alpha-3`)%>%
    dplyr::filter(iso_3 %in% country_noaa_data_only_subregions)%>%
    dplyr::select(iso_3,everything())

weather_or %>%
    dplyr::distinct(subregion1_name,.keep_all=T)%>% 
  dplyr::select(iso_3, noaa_station, noaa_distance, subregion1_name)%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Station' = 3,'Distance' = 4, "Subregion"= 5),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 27b: ', htmltools::em('Countries with not aggregated data concerning Climate')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
#*The reported weather station refers to the nearest station which provides temperature measurements, but rainfall and snowfall may come from a different nearby weather station. In all cases, only weather stations which are at most 300km from the location coordinates are considered.

#noaa_station= Identifier for the weather station	
#noaa_distance= Distance between the location coordinates and the weather station	
#average_temperature= Recorded hourly average temperature	
#minimum_temperature= Recorded hourly minimum temperature	
#maximum_temperature= Recorded hourly maximum temperature	
#rainfall= Rainfall during the entire day	
```

<br>

In the following two tables we may see countries with missing information in NOAA stations.**Most of these countries should not be considered**.

<br>

```{r noaa_5_2, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_6%>%
  dplyr::left_join(dplyr::select(weather_or,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N<=100,N>1)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 27c: ', htmltools::em('Missing Information by Country in NOAA Station (Not in every date, but at least in more than one)')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

Considering this temporary limitations, **for now** we merged the data for countries with aggregated data only. Meaning that **information directly obtained from NOAA was not considered for posterior analyses**.

<br>

```{r noaa_6, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_6%>%
  dplyr::left_join(dplyr::select(weather_or,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))->
  coronavirus_iso3c_3_6_5
```

# Worldwide Indicators

## Corruption Perceptions Index

We accessed Transparency International to query the Corruption [Perceptions Index](https://www.transparency.org/en/cpi/2019), which ranks 180 countries and territories by their perceived levels if public sector corruption. It is a composite index, a combination of surveys and assessments of corruption, collected by a variety of reputable institutions. The CPI is one of the most widely used indicator of corruption worldwide. The data is available in the following [link](https://images.transparencycdn.org/images/2019_CPI_FULLDATA.zip).

<br>

```{r CPI2019, echo=T, cache= T, paged.print=TRUE,eval=T}
CPI2019 <- tryCatch(
                            {
                            readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/CPI2019.xlsx", skip=2,
    range = "A3:d1000")%>% janitor::clean_names()%>%
  dplyr::filter(!is.na(country))
                            },
                            error = function(e){
                              readxl::read_excel(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"CPI2019.xlsx"), skip=2,
    range = "A3:d1000")%>% janitor::clean_names()%>%
  dplyr::filter(!is.na(country))
                            }
                    )
```

<br>

We first explored for the countries that could not be matched.

<br>

```{r CPI2019_2, echo=T, cache= T, paged.print=TRUE, eval=T}
CPI2019%>%
  dplyr::anti_join(coronavirus_iso3c_3_6_5, by=c("iso3"="iso_code"))%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Region' = 4,'CPI Score' = 5),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 28: ', htmltools::em('Countries of CPI2019 dataset that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#es de 0 a 100
```

<br>

The following Table shows countries that could not be match because they were not available in the dataset of CPI 2019. Most of the countries shown are developed countries or are still in a complicated position in terms of geopolitical matters. **We should not consider them**.

<br>

```{r CPI2019_3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_6_5%>%
  dplyr::left_join(CPI2019, by=c("iso_code"="iso3"), suffix=c("",".y"))%>%
  dplyr::select(-country.y, -region)%>%
  dplyr::filter(is.na(cpi_score_2019))%>%
  dplyr::group_by(iso_code, country)%>%
  dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 29: ', htmltools::em('Missing Information by Country in CPI2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))  

coronavirus_iso3c_3_6_5%>%
  dplyr::left_join(CPI2019, by=c("iso_code"="iso3"), suffix=c("",".y"))%>%
  dplyr::select(-country.y, -region)->
coronavirus_iso3c_3_6_9  
#es de 0 a 100
```

<br>

## UN HDI Dataset

We incorporated the Human Development Index (1990-2018), but some entries did not match with country names of our dataset. Most of them are in a complicated position in geopolitical terms, and other did not correspond to actual countries or had never been one (such as aggregated regions, global, etc.).

<br>

```{r hdi, echo=T, cache= T, paged.print=TRUE,eval=T}
hdi <- tryCatch(
  {
      readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/Human Development Index (HDI).csv", 
    skip = 1)%>% janitor::clean_names()
  },
      error = function(e){
      readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"Human Development Index (HDI).csv"), 
    skip = 1)%>% janitor::clean_names()
      }
)

hdi%>%
  dplyr::select(hdi_rank_2018,country,x2018)%>%
  dplyr::anti_join(coronavirus_iso3c_3_6_9,by="country")%>%
  dplyr::distinct(country,.keep_all=T)%>%    
    datatable(filter = 'top', colnames = c('Rank HDI 18' =2,'Country' = 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 30: ', htmltools::em('Countries of HDI dataset that did not match with our dataset')),
      options=list(
    #autoWidth = TRUE,
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

We standardized the names of many countries. However, **we still have problems with a few of them**.

<br>

```{r hdi_3, echo=T, cache= T, paged.print=TRUE,eval=T}
hdi<-hdi%>%
  dplyr::mutate(country=case_when(country=="Bolivia (Plurinational State of)"~"Bolivia",
                                country=="Brunei Darussalam"~"Brunei",
                                country=="Cabo Verde"~"Cape Verde",
                                country=="Congo (Democratic Republic of the)"~"Democratic Republic of Congo",
                                country=="Czechia"~"Czech Republic",
                                country=="Côte d'Ivoire"~"Cote d'Ivoire",
                                country=="Eswatini (Kingdom of)"~"Eswatini",
                                country=="Iran (Islamic Republic of)"~"Iran",
                                country=="Korea (Republic of)"~"South Korea",
                                country=="Lao People's Democratic Republic"~"Laos",
                                country=="Syrian Arab Republic"~"Syria",
                                country=="Tanzania (United Republic of)"~"Tanzania",
                                country=="Venezuela (Bolivarian Republic of)"~"Venezuela",
                                country=="Russian Federation"~"Russia",
                                country=="Timor-Leste"~"Timor",
                                country=="Moldova (Republic of)"~"Moldova",
                                country=="Viet Nam"~"Vietnam",TRUE~country))
hdi%>%
  dplyr::select(hdi_rank_2018,country,x2018)%>%
  dplyr::anti_join(coronavirus_iso3c_3_6_9,by="country")%>%
  dplyr::distinct(country,.keep_all=T)%>%    
    datatable(filter = 'top', colnames = c('Rank HDI 18' =2,'Country' = 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 31: ', htmltools::em('Countries of HDI dataset that did not match with our dataset (tidy)')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

We merged the HDI dataset with our dataset. However, there still are some issues with some of the countries shown in Table 31.

<br>

```{r hdi_4, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_6_9%>%
    dplyr::left_join(dplyr::select(hdi,hdi_rank_2018,country,x2018),by="country")%>%
    dplyr::filter(is.na(hdi_rank_2018))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 32: ', htmltools::em('Missing Information by Country in HDI 2018')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))

coronavirus_iso3c_3_6_9%>%
    dplyr::left_join(dplyr::select(hdi,hdi_rank_2018,country,x2018),by="country")%>%
  dplyr::rename("hdi_index_2018"="x2018")%>%
  dplyr::mutate(hdi_rank_2018=as.numeric(hdi_rank_2018))%>%
  dplyr::mutate(hdi_index_2018=as.numeric(hdi_index_2018))->
  coronavirus_iso3c_3_6_99
```

<br>

## Good Country Index

Good country index (v. 1.3) measures how much each of the countries contribute to the planet and the human race through their policies and behaviors, consistent in Science & Technology, Culture, International Peace & Security, World Order, Planet & Climate, Prosperity & Equality, and Health & Well-being [link](https://www.goodcountry.org/index/source-data/). Covers 153 countries. For more information about this index, please go to the following [link](https://www.goodcountry.org/index/source-data/).

<br>

```{r gci, echo=T, cache= T, paged.print=TRUE,eval=T}
gci_dataset <- tryCatch(
  {
     readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/gci dataset.xlsx")
  },
      error = function(e){
        readxl::read_excel(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"gci dataset.xlsx"))
      }
)

gci_dataset%>%
  dplyr::left_join(dplyr::select(index,country_name,`3166-1-alpha-3`), by=c("country"="country_name"))%>%
  dplyr::rename("iso_code"=`3166-1-alpha-3`)%>%
  dplyr::filter(is.na(iso_code))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33: ', htmltools::em('Missing Information by Country in GCI 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the above, some countries did not match with ISO codes available due to their condition or character mistypings. We assumed that Republic of Korea corresponded to South Korea. In case of Congo, **we did not know if corresponded to Kinshasa or Brazzaville, but we decided to match it with Brazzaville (Republic of Congo)**.

<br>

```{r gci2, echo=T, cache= T, paged.print=TRUE,eval=T}
gci_dataset_iso<-
gci_dataset%>%
  dplyr::left_join(dplyr::select(index,country_name,`3166-1-alpha-3`), by=c("country"="country_name"))%>%
  dplyr::rename("iso_code"=`3166-1-alpha-3`)%>%
  dplyr::mutate(iso_code=dplyr::case_when(country=="Republic of Macedonia / FYROM"~"MKD",
                                          country=="Republic of Korea"~"KOR",
                                          country=="Russian Federation"~"RUS",
                                          country=="Viet Nam"~"VNM",
                                          country=="Brunei Darussalam"~"BRN",
                                          country=="Congo"~"COG",
                                          country=="Côte d'Ivoire"~"CIV",TRUE~iso_code))%>%
  dplyr::distinct(iso_code,.keep_all=T)

coronavirus_iso3c_3_6_99%>%
  dplyr::left_join(dplyr::select(gci_dataset_iso, iso_code, rank), by="iso_code")%>%
  dplyr::rename("gci_2018_rank"="rank")->
coronavirus_iso3c_7
#gci_dataset_iso%>%
 # dplyr::filter(is.na(iso_code))
coronavirus_iso3c_7%>%
  dplyr::filter(is.na(gci_2018_rank))%>% 
  dplyr::group_by(iso_code, country)%>%
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>0)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 34: ', htmltools::em('Missing Information by Country in GCI 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

There are some countries that do not include this indicator because there is not many information available to construct this index [(more info on this in the link)](%22https://www.goodcountry.org/index/your-questions/countries-included/%22).

<br>

## Economist Intelligence Unit's Democracy Index

<br>

The Unit of Intelligence of The Economist created a Democracy Index of different countries worldwide categorizing them from full democracies through to authoritarian regimes.

<br>

```{r eiu, echo=T, cache= T, paged.print=TRUE,eval=T}
The_Economist_Dem_Index <- tryCatch(
  {
     readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/The Economist Dem Index.xlsx", 
    skip = 1)%>% janitor::clean_names()
  },
      error = function(e){
        readxl::read_excel(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"The Economist Dem Index.xlsx"), 
    skip = 1)%>% janitor::clean_names()
      }
)

The_Economist_Dem_Index%>%
    dplyr::anti_join(coronavirus_iso3c_7, by="country")%>%
    dplyr::distinct(country,.keep_all=T)%>%
  dplyr::select(country, qualification,rank, everything())%>%
  dplyr::select(1:4)%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Rank' = 4,'Overall Score' = 5),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 35: ', htmltools::em('Missing Information by Country in EIU 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As shown in the Table above, most of these countries could not be matched due to mistyping, or because they do not provide data on confirmed cases with COVID-19. For those that were type in a different manner, we changed their names to match with our dataset.

<br>

```{r eiu2, echo=T, cache= T, paged.print=TRUE,eval=T}
The_Economist_Dem_Index<-
  The_Economist_Dem_Index%>%
    dplyr::mutate(country=dplyr::case_when(country=="United States of America"~"United States",
                                            country=="Cabo Verde"~"Cape Verde",
                                            country=="Timor-Leste"~"Timor",
                                            country=="Kyrgyz Republic"~"Kyrgyzstan",
                                            country=="Côte d’Ivoire"~"Cote d'Ivoire",
                                            country=="Bosnia and Hercegovina"~"Bosnia and Herzegovina",
                                            country=="eSwatini"~"Eswatini",
                                            country=="Congo (Brazzaville)"~"Congo",
                                            country=="Côte d'Ivoire"~"CIV",TRUE~country))%>%
  dplyr::select(country, qualification,rank, overall_score)
  #dplyr::anti_join(coronavirus_iso3c_7, by="country")%>%
  #  dplyr::distinct(country,.keep_all=T)%>%
  #dplyr::select(country, qualification,rank, everything())%>%
  #dplyr::select(1:4)
  
coronavirus_iso3c_7%>%
  dplyr::left_join(The_Economist_Dem_Index, by="country")%>%
  dplyr::rename("eiu_2019_rank"="rank")%>%
  dplyr::rename("eiu_2019_overall_score"="overall_score")->
coronavirus_iso3c_8
#gci_dataset_iso%>%
 # dplyr::filter(is.na(iso_code))
coronavirus_iso3c_8%>%
  dplyr::filter(is.na(eiu_2019_rank))%>% 
  dplyr::group_by(iso_code, country)%>%
    dplyr::summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>0)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 36: ', htmltools::em('Missing Information by Country in EIU 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, most of the countries that were not considered in this index are undeveloped countries or in a complicated position in geopolitical terms.

<br>

## World Bank datasets

<br>

We considered the following additional variables to include them in the dataset: - SP.POP.TOTL= Population, Total

-   EN.POP.DNST= Population Density

-   SH.MED.PHYS.ZS= Physicians (per 1,000 people)

-   SH.MED.BEDS.ZS= Hospital beds (per 1,000 people)

-   EN.ATM.PM25.MC.M3 PM2.5= air pollution, mean annual exposure (micrograms per cubic meter) Brauer, M. et al. 2017, for the Global Burden of Disease Study 2017

-   SP.DYN.LE00.IN= Life expectancy at birth, total (years)

-   SP.DYN.CDRT.IN= Death rate, crude (per 1,000 people)

<br>

However, we must consider the time span for which we would tolerate lagged years, depending on the amount of countries that had this information updated.

<br>

```{r wb_candidates1, echo=T, cache= T, paged.print=TRUE,eval=T, fig.cap="Figure 4.No of Countries By Tolerance on Last Days in Variables of Interest", error=T}
#SH.MED.PHYS.ZS Physicians (per 1,000 people)
#SH.MED.BEDS.ZS Hospital beds (per 1,000 people)
#SH.PRV.SMOK Smoking prevalence, total (ages 15+)
#EN.ATM.PM25.MC.M3 PM2.5 air pollution, mean annual exposure (micrograms per cubic meter) Brauer, M. et al. 2017, for the Global Burden of Disease Study 2017.
require(wbstats)
 #wb(country = "all", indicator = "SH.PRV.SMOK", mrv = 3) #no funciona
data_frame<-data.frame(iso3c="1",N=1, name="1",v="1")
  for (i in c("SP.POP.TOTL","EN.POP.DNST","SH.MED.PHYS.ZS","SH.MED.BEDS.ZS","EN.ATM.PM25.MC.M3","SP.DYN.LE00.IN", "SP.DYN.CDRT.IN")) {
      for (v in 1:7){
        df<-wb(country = "all", indicator = i, mrv = v)%>% 
                        group_by(iso3c)%>% summarise(N=n())%>%
          dplyr::mutate(name=paste0(i),v=paste0(v))
          #assign(paste0(i,"_",v),., envir = .GlobalEnv)
        data_frame<-rbind(data_frame,df)
      }
  }
data_frame<-
  data_frame%>%
    dplyr::filter(iso3c!="1")%>%
  dplyr::select(name, iso3c,v,N)%>%
  dplyr::rename("years_covered"="v")%>%
  group_by(name, years_covered)%>%
  dplyr::summarise(no_countries=n())%>%
  ungroup()

ggplot(data_frame, aes(x=name, y=no_countries, fill=years_covered))+
  geom_bar(stat="identity")+
  geom_hline(yintercept =170, color="darkred",linetype=5)+
   facet_grid(years_covered~.)+
  theme_minimal()+
  labs(caption="red line= 170 countries")+ 
  theme(legend.position="bottom")+
  guides(fill=guide_legend(ncol=7))

```

<br>

Considering the figure above and what we discussed with Kassim & Thamara, we decided to tolerate 6 years of delay in the update of these statistics, in order to include a greater amount of countries.

<br>

Additionally, we test whether `EN.ATM.PM25.MC.M3` had different values from the consolidated dataset obtained from this [link](https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/edit#gid=0).

<br>

```{r wb_prueba_con_covid19_con_wb, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}

  for (i in c("SP.POP.TOTL","EN.POP.DNST","SH.MED.PHYS.ZS","SH.MED.BEDS.ZS","EN.ATM.PM25.MC.M3","SP.DYN.LE00.IN","SP.DYN.CDRT.IN")) {
        wb_data(country = "all", indicator = i, mrv = 6)%>%
      dplyr::filter(date<2020 & date>=2000) %>% 
      dplyr::rename("value"=i) %>% 
        assign(paste0("wb_",i),.,envir=.GlobalEnv)
  }
#https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/export?format=csv&id=1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8&gid=447690624

google_covid19 <- readr::read_csv("https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/export?format=csv&id=1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8&gid=0")%>%
  janitor::clean_names() 
#no calza en un puros paises de pija
invisible(
google_covid19 %>%
  dplyr::select(iso3,name_engli,air_pollution)%>%
  dplyr::anti_join(wb_EN.ATM.PM25.MC.M3,by=c("iso3"="iso3c"))
)

invisible(
                  wb_EN.ATM.PM25.MC.M3%>%
                    #dplyr::select(iso3c,name_engli,air_pollution)%>%
                    dplyr::anti_join(google_covid19,by=c("iso3c"="iso3"))%>%
                    dplyr::select(iso3c,country,date)%>%
                    dplyr::group_by(iso3c,country)%>%
                    dplyr::summarise(N=n(),first_date=min(date),last_date=max(date))
)
#SELECCIONO EL DATO MAS RECIENTE POR PAIS
invisible(
wb_EN.ATM.PM25.MC.M3%>%
    group_by(iso3c)%>%
    dplyr::filter(!is.na(value))%>%
    dplyr::filter(date==max(date))%>%
  #janitor::tabyl(iso3c,date) #todos 2017
  dplyr::ungroup()%>%
  dplyr::anti_join(google_covid19,by=c("iso3c"="iso3"))
)

#no eran paises los que no calzaron

if(
wb_EN.ATM.PM25.MC.M3%>%
    group_by(iso3c)%>%
    dplyr::filter(!is.na(value))%>%
    dplyr::filter(date==max(date))%>%
  #janitor::tabyl(iso3c,date) #todos 2017
  dplyr::ungroup()%>%
  dplyr::left_join(google_covid19,by=c("iso3c"="iso3"))%>%
  #dplyr::filter(is.na(value)) #no hay perdidos
  dplyr::mutate(distinct=abs(air_pollution-value))%>%
  #dplyr::mutate(distinct=ifelse(air_pollution-value,1,0))%>%
  dplyr::filter(distinct>0.00001)%>%
  dplyr::select(iso3c, name_engli,air_pollution,value,distinct)%>%
  nrow()>0){toupper("**there are differences between covid19 dataset and world bank**")}
#NO HAY DIFERENCIAS MAYORES DE 0.00001

#If you do not know the latest date an indicator you are interested in is available for you country you can use the mrv instead of startdate and enddate. mrv stands for most recent value and takes a integer corresponding to the number of most recent values you wish to return

#If you use the mrv parameter in wb() with mutliple countries or regions, it searches for the most recent dates for which any country or region in your selection has data and then returns the data for those dates. In other words the mrv value is not determined on a country by country basis, rather it is determined across the entire selection.

#Unless you know the country and indicator codes that you want to download the first step would be searching for the data you are interested in. wbsearch() provides grep style searching of all available indicators from the World Bank API and returns the indicator information that matches your query.

#To access what countries or regions are available you can use the countries data frame from either wb_cachelist or the saved return from wbcache(). This data frame contains relevant information regarding each country or region. More information on how to use this for downloading data is covered later.

```

```{r wb1_miss_a, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
t1<-wb_SP.POP.TOTL%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t2<-wb_EN.POP.DNST%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t3<-wb_SH.MED.PHYS.ZS%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t4<-wb_SH.MED.BEDS.ZS%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t5<-wb_EN.ATM.PM25.MC.M3%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t6<-wb_SP.DYN.LE00.IN%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t7<-wb_SP.DYN.CDRT.IN%>% dplyr::group_by(iso3c,country)%>% dplyr::summarise(n=n(),year=max(date))%>% dplyr::arrange(year)


coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SP.POP.TOTL,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("total_pop"="value", "year_total_pop"="date")%>%
  dplyr::filter(is.na(total_pop))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37a: ', htmltools::em('Missing Information by Country in Total Pop')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_b, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_EN.POP.DNST,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("pop_density"="value", "year_pop_density"="date")%>%
  dplyr::filter(is.na(pop_density))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37b: ', htmltools::em('Missing Information by Country in Pop Density')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_c, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SH.MED.PHYS.ZS,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("physicians_per_1000"="value", "year_physicians_per_1000"="date")%>%
  dplyr::filter(is.na(physicians_per_1000))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37c: ', htmltools::em('Missing Information by Country in No. of Physicians')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_d, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SH.MED.BEDS.ZS,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("hosp_beds_per_1000"="value", "year_hosp_beds_per_1000"="date")%>%
  dplyr::filter(is.na(hosp_beds_per_1000))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37d: ', htmltools::em('Missing Information by Country in Hospital Beds')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_e, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_EN.ATM.PM25.MC.M3,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("air_pollution_year_pm25"="value", "year_air_pollution_year_pm25"="date")%>%
  dplyr::filter(is.na(air_pollution_year_pm25))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37e: ', htmltools::em('Missing Information by Country in Pollution PM25')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_f, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
  dplyr::left_join(dplyr::select(wb_SP.DYN.LE00.IN,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("life_exp"="value", "year_life_exp"="date")%>%
  dplyr::filter(is.na(life_exp))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37f: ', htmltools::em('Missing Information by Country in Life Expectancy')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

```{r wb1_miss_g, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
  dplyr::left_join(dplyr::select(wb_SP.DYN.CDRT.IN,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("life_exp"="value", "year_life_exp"="date")%>%
  dplyr::filter(is.na(life_exp))%>%
  dplyr::group_by(country, iso_code)%>%
  dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37g: ', htmltools::em('Missing Information by Country in Death rate, crude (x1,000)')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
#
```

<br>

Considering the missing data patterns, we decided to merge these indicators anyway.

<br>

```{r wb2, echo=T, cache= T, paged.print=TRUE, eval=T, error=T}
wb_SP.POP.TOTL<-
  wb_SP.POP.TOTL%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_EN.POP.DNST<-
  wb_EN.POP.DNST%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_SH.MED.PHYS.ZS<-
  wb_SH.MED.PHYS.ZS%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_SH.MED.BEDS.ZS<-
    wb_SH.MED.BEDS.ZS%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()
wb_EN.ATM.PM25.MC.M3<-
    wb_EN.ATM.PM25.MC.M3%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()
wb_SP.DYN.LE00.IN<-
    wb_SP.DYN.LE00.IN%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()

wb_SP.DYN.CDRT.IN<-
  wb_SP.DYN.CDRT.IN%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()

coronavirus_iso3c_9<- coronavirus_iso3c_8%>%
        dplyr::left_join(dplyr::select(wb_SP.POP.TOTL,iso3c,date,value),#SP.POP.TOTL
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("total_pop"="value", "year_total_pop"="date")%>%
        dplyr::left_join(dplyr::select(wb_EN.POP.DNST,iso3c,date,value),#EN.POP.DNST
                         by=c("iso_code"="iso3c"))%>%  
        dplyr::rename("pop_density"="value", "year_pop_density"="date")%>%
        dplyr::left_join(dplyr::select(wb_SH.MED.BEDS.ZS,iso3c,date,value),#SH.MED.BEDS.ZS
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("hosp_beds_per_1000"="value", "year_hosp_beds_per_1000"="date")%>%
        dplyr::left_join(dplyr::select(wb_EN.ATM.PM25.MC.M3,iso3c,date,value),#EN.ATM.PM25.MC.M3
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("air_pollution_year_pm25"="value", "year_air_pollution_year_pm25"="date")%>%
        dplyr::left_join(dplyr::select(wb_SP.DYN.LE00.IN,iso3c,date,value),#SP.DYN.LE00.IN
                             by=c("iso_code"="iso3c"))%>%
        dplyr::rename("life_exp"="value", "year_life_exp"="date") %>% 
        dplyr::left_join(dplyr::select(wb_SP.DYN.CDRT.IN,iso3c,date,value),#SP.DYN.CDRT.IN
                             by=c("iso_code"="iso3c"))%>%
        dplyr::rename("death_rate_crude"="value", "year_death_rate_crude"="date")
```

## COVID19 dataset indices

Taking into account that `EN.ATM.PM25.MC.M3` matched almost perfectly with the source ow World Bank, we considered that the information from this [link](https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/edit#gid=0) was reliable.

<br>

-   `dalys_asthma_normalized`: Years of healthy life lost to premature death and disability due to asthma. DALYs are the sum of years of life lost (YLLs) and years lived with disability (YLDs).
-   `dalys_lung_disease`= "Years of healthy life lost to premature death and disability due to lung disease. DALYs are the sum of years of life lost (YLLs) and years lived with disability (YLDs)."
-   `obesity_both_percent`= Percentage of Obesity for Both Sexes.

<br>

```{r covid19_data1, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
google_covid19%>%
  dplyr::select(iso3,name_engli,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent)%>%
  dplyr::anti_join(coronavirus_iso3c_9, by=c("iso3"="iso_code"))%>%
        datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 38: ', htmltools::em('Countries of COVID19 dataset that did not match with our Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, most of these regions had a problematic status in geopolitical terms. Posteriorly, we analized if the merging with our datasets may generate missing data in any country.

<br>

```{r covid19_data2, echo=T, cache= T, paged.print=TRUE, eval=T, error=T}
coronavirus_iso3c_9%>%
  dplyr::left_join(dplyr::select(google_covid19,iso3,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent), by=c("iso_code"="iso3"))%>%
  dplyr::mutate(obesity_both_percent=str_replace(obesity_both_percent, "%", ""),
                obesity_both_percent=as.numeric(obesity_both_percent))%>%
  dplyr::group_by(country) %>% 
  summarise_at(vars(dalys_asthma_normalized:obesity_both_percent),~sum(is.na(.))/n())%>%  
  dplyr::mutate(sumVar = rowSums(dplyr::select(., .dots = all_of(c("dalys_asthma_normalized","dalys_lung_disease","obesity_both_percent")))))%>%
  dplyr::mutate_at(vars(dalys_asthma_normalized:obesity_both_percent),~scales::percent(.))%>%
  dplyr::filter(sumVar>0)%>%
  dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
        datatable(filter = 'top',
                  colnames = c('Country' =2,'Sum of Missing Data' = 3,'DALYs Asthma' = 4,'DALYs Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 39: ', htmltools::em('Countries with missing values in COVID19 dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, most of these regions had a problematic status in geopolitical terms. **That is why we merged the datasets anyway**.

<br>

```{r covid19_data3, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_10<-
    coronavirus_iso3c_9%>%
      dplyr::left_join(dplyr::select(google_covid19,iso3,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent), by=c("iso_code"="iso3"))%>%
      dplyr::mutate(obesity_both_percent=str_replace(obesity_both_percent, "%", ""),
                    obesity_both_percent=as.numeric(obesity_both_percent))
```

<br>

## Causes of Death, WHO Data

```{r who_mortality1, echo=T, cache= T, paged.print=TRUE, eval=T, error=F}
#  WHO Mortality database (MDB)

#The deaths registered in national vital registration systems up to Dec 15 (obtained from [here](https://www.who.int/healthinfo/statistics/mortality_rawdata/en/)), with underlying cause of death as coded by the relevant national authority. More information on this [link](http://www.ccs.neu.edu/home/kathleen/classes/cs3200/WHODocumentation2015.pdf). We selected the maximum available year with information for each country.

#<br>
  
invisible(c("https://rdrr.io/github/eugejoh/WHOmortality/man/download_who.html"))
invisible(c("https://rdrr.io/github/eugejoh/WHOmortality/"))
invisible(c("https://www.rdocumentation.org/packages/heemod/versions/0.9.0/topics/who-mortality"))
#For instance, it would be useful to extract the number of deaths by country around 2016 (if I do not mistake on the year we are finally using) but only those attributed to respiratory infections (A.2 or A.2.2 and A.2.3)

invisible(c(key= "TdicjbOHEEs96ujLEseRyJmqJy0UotIq56pvg3+00/cYJCOdj+1xePAuK+yBx4lU")) 

#
invisible(c("http://svante.mit.edu/~mwli/Li_2019/Data_and_Analysis/Health/WHO/y0_oz_ICD10.R"))

library(WHOmortality)

data(dd_mort)
#List of ICD revision used � see Annex Table 2 below.
#Cause of death � For details consult Part 2 below or ICD publications
#Data files - Last updated: 15 December 2019


#mort_df <- WHOmortality::import_who(path=getwd(),data="mort")

#dd_mort[1:10,1]
#
country_code_who <-read.csv("https://raw.githubusercontent.com/dancingCamel/WHO-Mortality-Data-API/master/raw_data/country_codes.csv", header=T)
Morticd10_part1 <-read.csv(unz(gsub("Dataset_Cons_post_ago.Rmd","Morticd10_part1.zip",rstudioapi::getSourceEditorContext()$path), "Morticd10_part1"), header=T,skip=0)
Morticd10_part2 <-read.csv(unz(gsub("Dataset_Cons_post_ago.Rmd","Morticd10_part2.zip",rstudioapi::getSourceEditorContext()$path), "Morticd10_part2"), header=T,skip=0)

rbind(Morticd10_part1,Morticd10_part2)%>%
  dplyr::mutate_at(dplyr::vars(tidyselect::matches("Deaths[0-9]{,2}$|Pop|Lb")), as.numeric)%>%
  dplyr::mutate_at(dplyr::vars("Sex"), as.factor)%>%
  dplyr::mutate_at(dplyr::vars("Year"), as.integer)%>%
  dplyr::left_join(country_code_who, by=c("Country"="country"))%>%
  dplyr::select(Country, name,Admin1,SubDiv, Year, List, Cause, Sex, Frmat, IM_Frmat, Deaths1,Deaths26)%>%
  janitor::clean_names()%>%
  #dplyr::group_by(country)%>%
  #dplyr::mutate(max_yr=max(year)) %>% 
  #dplyr::filter(year==max_yr) %>% #el último año disponible para cada país
  dplyr::ungroup() %>% #janitor::tabyl(admin1)
  dplyr::filter(is.na(admin1)) %>% 
  dplyr::filter(is.na(sub_div)|sub_div=="") %>%  #If both fields 'Admin1' and 'Subdiv' are blank, data reported refer to the country
  dplyr::filter(cause=="AAA") %>% #“# the cause \”AAA\” refers to total deaths from all causes combined\n”,
      dplyr::group_by(country,year) %>% 
  dplyr::mutate(tot_deaths=sum(deaths1)) %>%  #Deaths at all ages
  dplyr::slice(1) %>% 
  dplyr::ungroup() %>%
  dplyr::arrange(name,year) %>% 
  dplyr::select(-deaths1, -deaths26,-sex,-frmat,-im_frmat) %>% 
  assign("Morticd10_total_std_col",.,envir=.GlobalEnv)

Morticd10_total_std_col %>% 
  dplyr::group_by(country) %>% 
  slice(1) %>% 
  assign("Morticd10_total_std_col_filt",.,envir=.GlobalEnv)

write.csv2(Morticd10_total_std_col_filt,"mortality_cntry.csv", row.names=FALSE, na="")

 #Morticd10_total_std_col_filt %>% 
#dplyr::filter(name=="Chile") #111.914	en DF, pero lo que tengo es 106,388

#número de años distintos
anos_distintos_por_pais<-
rbind(Morticd10_part1,Morticd10_part2)%>%
  dplyr::mutate_at(dplyr::vars(tidyselect::matches("Deaths[0-9]{,2}$|Pop|Lb")), as.numeric)%>%
  dplyr::mutate_at(dplyr::vars("Sex"), as.factor)%>%
  dplyr::mutate_at(dplyr::vars("Year"), as.integer)%>%
  dplyr::left_join(country_code_who, by=c("Country"="country"))%>%
  dplyr::select(Country, name,Admin1,SubDiv, Year, List, Cause, Sex, Frmat, IM_Frmat, Deaths1,Deaths26)%>%
  janitor::clean_names()%>%
  dplyr::group_by(country)%>%
  dplyr::mutate(max_yr=max(year)) %>% 
  #dplyr::filter(year==max_yr) %>% #el último año disponible para cada país
  dplyr::ungroup() %>% #janitor::tabyl(admin1)
  dplyr::filter(is.na(admin1)) %>% 
  dplyr::filter(is.na(sub_div)|sub_div=="") %>%  #If both fields 'Admin1' and 'Subdiv' are blank, data reported refer to the country
  dplyr::filter(cause=="AAA") %>% #“# the cause \”AAA\” refers to total deaths from all causes combined\n”,
      dplyr::group_by(country) %>% 
  dplyr::mutate(tot_deaths=sum(deaths1)) %>%  #Deaths at all ages
  dplyr::ungroup() %>%
  
  dplyr::group_by(country)%>%
  dplyr::mutate(max_yr=max(year)) %>% 
  dplyr::mutate(ndis_yr=n_distinct(year)) %>% 
  dplyr::ungroup() %>%
  dplyr::select(name,ndis_yr) %>% 
  dplyr::group_by(name)%>%
  slice(1)

dd_icd10<-dd_icd10%>%
  dplyr::mutate(code=as.character(code))

pop <- read.csv(gsub("Dataset_Cons_post_ago.Rmd","pop",rstudioapi::getSourceEditorContext()$path), header=T,skip=0)%>% janitor::clean_names()

#Morticd10_total_std_col%>%
# dplyr::left_join(dd_icd10, by=c("cause"="code"))

#https://www.cia.gov/library/publications/the-world-factbook/rankorder/2066rank.html


#We selected the following diseases: 
# - 1073= Influenza
# - 1074= Pneumonia
# - 1006= Other Tuberculosis
# - 1005= Respiratory Tuberculosis
# - 1010= Whooping Cough
# - 1020= HIV
# - 1075= Other accute lower respiratorio infections

#ICD-10 Code  Diagnoses
#Upper Respiratory Infections
#J00  Acute Nasopharyngitis (Common Cold)
#J01.90 Acute Sinusitis, Unspecified
#J02.0  Streptococcal Pharyngitis
#J02.9  Acute Pharyngitis, Unspecified
#J03.90 Acute Tonsillitis, Unspecified
#J06.9  Acute Upper Respiratory Infection, Unspecified
#J31.0  Chronic Rhinitis
#J32.9  Chronic Sinusitis, Unspecified
#R05  Cough

#Lower Respiratory Infections
#A37.90 Whooping Cough, Unspecified Species Without Pneumonia
#B97.4  Respiratory Syncytial Virus As The Cause Of Diseases Classified Elsewhere
#J18.9  Pneumonia, Unspecified Organism
#J20.9  Acute Bronchitis, Unspecified
#R06.02 Shortness Of Breath
#R06.89 Other Abnormalities Of Breathing
#R09.1  Pleurisy
#R76.11 Nonspecific Reaction To Tuberculin Skin Test Without Active Tuberculosis


#data("eiu")
#eiu%>%
#    group_by(eiu_country)%>%
#    dplyr::filter(year==max(year))%>% #resulta que todos son 2018
#  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
#               caption = paste0("Table 27. Whole Dataset (maxmimum)"),
#               align =rep('c', 101)) %>%
#  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
#  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_7),"observations")), 
#                            notation = "none") %>%
#  kableExtra::scroll_box(width = "100%", height = "375px")
Morticd10_total_std_col_last_5<-
Morticd10_total_std_col %>% 
  dplyr::group_by(country) %>% 
  top_n(year,n=5) %>% 
  dplyr::ungroup()
```

<br>

Considering that many countries had dissimilar years available, we selected the last five observations of each country.

<br>

```{r linear_deaths_who_plot, echo=T, cache= T, fig.align='center', paged.print=TRUE,eval=T, error=T, fig.cap="Figure 5. Linear Trends of Deaths By Year"}
Sys.setlocale(category = "LC_ALL", locale = "english")

plot_ly(
  x     = ~year, y = ~log10(tot_deaths), 
  color = ~name,
  data  = Morticd10_total_std_col_last_5,
  type = 'scatter',
        mode = 'lines')%>%
  layout(showlegend = FALSE)%>%
 # highlight(on = "plotly_click",off = "plotly_doubleclick")
  #highlight(on = "plotly_hover", off = "plotly_deselect", color = "red")
  highlight(on="plotly_hover",off="plotly_deselect",color="blue",opacityDim=.2, persistent = F)%>%
  layout(xaxis=list(title = "Year", spikethickness=4, spikecolor="gray50"),
         yaxis = list(title = "Sum of Yearly Deaths by Any Cause, Sex & Age (Log10)"))
```

```{r who_mortality_who2, echo=T, cache= T, paged.print=TRUE,eval=T}
 #coronavirus_iso3c_10 %>%dplyr::filter(grepl("Mau",country)) %>% dplyr::select(country,iso_code)

Morticd10_total_std_col_last_5%>%
    dplyr::anti_join(coronavirus_iso3c_10, by=c("name"="country"))%>%
  dplyr::group_by(country,name)%>%
  dplyr::summarise(N=n(),min_year=min(year),max_year=max(year))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 40: ', htmltools::em('Countries of WHO Mortality that did not match with our Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, many of these countries that did not match, correspond to aggregated territories or countries that do not exist at 2020, or are still in a complicated position in geopolitical terms.

<br>

```{r who_mortality_who3, echo=T, cache= T, paged.print=TRUE,eval=T}

#MUS #Mauritius
# Aruba a NLD, hacer suma Netherlands
# Réunion, an overseas region/department of France
# Mayotte, Es un departamento de la región de Francia - France
# Anguilla, un territorio británico en el Caribe oriental,- United Kingdom
# Las Bermudas son un territorio británico en el océano Atlántico Norte- United Kingdom
# British Virgin Islands, a Britain- United Kingdom
# Las Islas Caimán son un territorio británico de ultramar que abarca 3 islas en el mar Caribe occidental- United Kingdom
# La Guayana Francesa es una región francesa de ultramar en la costa noreste de Sudamérica - France
# Guadeloupe- No subdivisions relevant for this standard. Included also as subdivision of France - France
# Martinica es una accidentada isla del Caribe que pertenece a las Antillas Menores. Es una región de ultramar francesa  - France- United Kingdom
# La isla de Montserrat es un territorio británico de ultramar ubicado al sureste de la isla de Puerto Rico, en aguas del mar Caribe.
# Netherlands Antilles- perteneciente al Reino de los Países Bajos
# Puerto Rico -Puerto Rico es una isla del Caribe y un territorio no incorporado de Estados Unidos
# Saint Pierre and Miquelon- San Pedro y Miquelón​ es un archipiélago situado en América del Norte, frente a las costas canadienses de Terranova. Desde 1985 es una colectividad territorial francesa
# Saint Vincent and Grenadines- VCT
# Turks and Caicos Islands	- Turcas y Caicos es un archipiélago de 40 islas bajas con corales en el océano Atlántico, un territorio británico de ultramar al sureste de las Bahamas. 
# United States of America	- cambiar por United States
# Virgin Islands (USA) - cambiar por United States
# Brunei Darussalam- cambiar por Brunei
# Hong Kong SAR - cambiar por china
# Iran (Islamic Republic of) - Iran
# Republic of Korea	- South Korea
# Syrian Arab Republic- cambiar por Syria
# TFYR Macedonia- North Macedonia (MKD)
# Republic of Moldova- Moldova
# United Kingdom, England and Wales- United Kingdom
# United Kingdom, Northern Ireland, England and Wales- United Kingdom
# United Kingdom, Scotland- United Kingdom

Morticd10_total_std_col_last_5_std<-
  Morticd10_total_std_col_last_5 %>% 
  dplyr::mutate(name= dplyr::case_when(name=="Aruba"~"Netherlands",
                                          name=="Réunion"~"France",
                                          name=="Mayotte"~"France",
                                          name=="Anguilla"~"United Kingdom",
                                          name=="Bermuda"~"United Kingdom",
                                          name=="British Virgin Islands"~"United Kingdom",
                                          name=="Cayman Islands"~"United Kingdom",
                                          name=="French Guiana"~"France",
                                          name=="Guadeloupe"~"France",
                                          name=="Martinique"~"France",
                                          name=="Montserrat"~"United Kingdom",
                                          name=="Netherlands Antilles	"~"Netherlands",
                                          name=="Puerto Rico"~"United States",
                                          name=="Saint Pierre and Miquelon	"~"France",
                                          name=="Puerto Rico"~"United States",
                                          name=="United States of America"~"United States",
                                          name=="Virgin Islands (USA)"~"United States",
                                          name=="Brunei Darussalam"~"Brunei",
                                          name=="Hong Kong SAR"~"China",
                                          name=="Iran (Islamic Republic of)"~"Iran",
                                          name=="Republic of Korea"~"South Korea",
                                          name=="Syrian Arab Republic"~"Syria",
                                          name=="PTFYR Macedonia"~"North Macedonia",
                                          name=="Republic of Moldova"~"Moldova",
                                          name=="United Kingdom, England and Wales"~"United Kingdom",
                                          name=="United Kingdom, Northern Ireland, England and Wales"~"United Kingdom",
                                       name=="United Kingdom, Northern Ireland"~"United Kingdom",
                                       name=="Turks and Caicos Islands"~"United Kingdom",
                                       name=="Rodrigues"~"Mauritius",
                                       name=="Reunion"~"France",
                                       
                                          name=="United Kingdom, Scotland"~"United Kingdom",
                                          TRUE~name)) %>% 
  dplyr::group_by(name,year) %>% 
  dplyr::mutate(tot_deaths= sum(tot_deaths,na.rm=T)) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(name) %>% 
  top_n(year,n=5) %>% 
  dplyr::ungroup()


Morticd10_total_std_col_last_1_std<-
  Morticd10_total_std_col_last_5 %>% 
  dplyr::mutate(name= dplyr::case_when(name=="Aruba"~"Netherlands",
                                          name=="Réunion"~"France",
                                          name=="Mayotte"~"France",
                                          name=="Anguilla"~"United Kingdom",
                                          name=="Bermuda"~"United Kingdom",
                                          name=="British Virgin Islands"~"United Kingdom",
                                          name=="Cayman Islands"~"United Kingdom",
                                          name=="French Guiana"~"France",
                                          name=="Guadeloupe"~"France",
                                          name=="Martinique"~"France",
                                          name=="Montserrat"~"United Kingdom",
                                          name=="Netherlands Antilles	"~"Netherlands",
                                          name=="Puerto Rico"~"United States",
                                          name=="Saint Pierre and Miquelon	"~"France",
                                          name=="Puerto Rico"~"United States",
                                          name=="United States of America"~"United States",
                                          name=="Virgin Islands (USA)"~"United States",
                                          name=="Brunei Darussalam"~"Brunei",
                                          name=="Hong Kong SAR"~"China",
                                          name=="Iran (Islamic Republic of)"~"Iran",
                                          name=="Republic of Korea"~"South Korea",
                                          name=="Syrian Arab Republic"~"Syria",
                                          name=="PTFYR Macedonia"~"North Macedonia",
                                          name=="Republic of Moldova"~"Moldova",
                                          name=="United Kingdom, England and Wales"~"United Kingdom",
                                          name=="United Kingdom, Northern Ireland, England and Wales"~"United Kingdom",
                                       name=="United Kingdom, Northern Ireland"~"United Kingdom",
                                       name=="Turks and Caicos Islands"~"United Kingdom",
                                       name=="Rodrigues"~"Mauritius",
                                       name=="Reunion"~"France",
                                       
                                          name=="United Kingdom, Scotland"~"United Kingdom",
                                          TRUE~name)) %>% 
  dplyr::group_by(name,year) %>% 
  dplyr::mutate(tot_deaths= sum(tot_deaths,na.rm=T)) %>% 
  dplyr::ungroup() %>% 
  dplyr::group_by(name) %>% 
  top_n(tot_deaths,n=1) %>% 
  dplyr::ungroup()

    coronavirus_iso3c_10%>%
    dplyr::left_join(dplyr::select(Morticd10_total_std_col_last_5_std,name,year,tot_deaths), by=c("country"="name"))%>%
    dplyr::rename("owid_gbd_year"="year")%>%
    dplyr::group_by(country,iso_code)%>%
    dplyr::filter(is.na(tot_deaths))%>%
    dplyr::summarise(N=n(),min_year=min(dates),max_year=max(dates))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 41: ', htmltools::em('Countries of our dataset that did not match with WHO Mortality Data')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

```{r who_mortality_who_105, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_105<-
    coronavirus_iso3c_10%>%
    dplyr::left_join(dplyr::select(Morticd10_total_std_col_last_1_std,name,year,tot_deaths), by=c("country"="name"))%>%
    dplyr::rename("who_tot_deaths_year"="year")
```

On the table above, we observe that many countries did not have any information regarding deaths in the WHO database. Given that many adinistrative subregions of coutries also reported deaths separately and possibly more recently than the the bulk of deaths of the country, we selected the year with the maximum sum of deaths in the last 5 years.

<br>

## Causes of Death, OWID Data

<br>

We obtained the causes of death by country from an OWID repository (available in this [link](https://ourworldindata.org/causes-of-death)).

<br>

```{r who_mortality_owid, echo=T, cache= T, paged.print=TRUE,eval=T}

ann_no_deaths_by_cause<- tryCatch(
               {
                           read.csv(gsub("Dataset_Cons_post_ago.Rmd","annual-number-of-deaths-by-cause.csv",rstudioapi::getSourceEditorContext()$path))%>%
          janitor::clean_names()%>%
          dplyr::select(entity, code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths)
               },
                   error = function(e){
                           read.csv(gsub("Dataset_Cons_post_ago.Rmd","annual-number-of-deaths-by-cause.csv",rstudioapi::getSourceEditorContext()$path))%>%
        janitor::clean_names()%>%
        dplyr::select(entity, code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths)
                   }
             )

ann_no_deaths_by_cause%>%
    dplyr::anti_join(coronavirus_iso3c_10, by=c("code"="iso_code"))%>%
  dplyr::group_by(code,entity)%>%
  dplyr::summarise(N=n(),min_year=min(year),max_year=max(year))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 42: ', htmltools::em('Countries of OWID Causes Of Death Dataset that did not match with our Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, many of these countries that did not match, correspond to aggregated territories or countries that do not exist at 2020, or are still in a complicated position in geopolitical terms.

<br>

```{r who_mortality_owid2, echo=T, cache= T, paged.print=TRUE,eval=T}
ann_no_deaths_by_cause <- 
    ann_no_deaths_by_cause%>%
    dplyr::group_by(code)%>%
     slice(1)%>%
        ungroup()

    coronavirus_iso3c_105%>%
    dplyr::left_join(dplyr::select(ann_no_deaths_by_cause,code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths), by=c("iso_code"="code"))%>%
    dplyr::rename("owid_gbd_year"="year")%>%
    dplyr::group_by(country,iso_code)%>%
    dplyr::filter(is.na(dalys_asthma_normalized))%>%
    dplyr::summarise(N=n(),min_year=min(dates),max_year=max(dates))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 43: ', htmltools::em('Countries of our dataset that did not match with OWID Data')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, some countries did not contained any information regarding causes of death.

<br>

```{r who_mortality_owid3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_11<-
    coronavirus_iso3c_105%>%
    dplyr::left_join(dplyr::select(ann_no_deaths_by_cause,code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths), by=c("iso_code"="code"))%>%
    dplyr::rename("owid_gbd_year"="year")
```

## Life Expectancy at Age 60 (e60)

We incorporated the Life expectancy at age 60 (years) ([link](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/life-expectancy-at-age-60-(years))), as one of the prospect that WHO has available. We had to standardize the names of the following countries: Czechia, Venezuela, Bolivia, Macronesia, Moldova, Russia, North Macedonia, Tanzania, Congo, Sao Tome and Principe, Eswatini, Cabo Verde, Cote d Ivoire, Syria, Iran, Macao, North & South Korea, Brunei, Lao, Timor-Leste, Vietnam, and Guadeloupe.

<br>

```{r life_exp_60_1, echo=T, cache= T, paged.print=TRUE,eval=T}
# Life Expectancy at Age 60 (e60) 
WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES <-tryCatch(
    {
       readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES.xlsx", 
    skip = 16)%>%
  dplyr::select(3,5,7,`2015-2020`)
    },
    error = function(e){
 readxl::read_excel(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES.xlsx"), 
    skip = 16)%>%
  dplyr::select(3,5,7,`2015-2020`)
    }
)
who_life_exp_60_both_sex<-
WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES%>%
  left_join(dplyr::select(index,country_name,`3166-1-alpha-3`), by=c("Region, subregion, country or area *"="country_name"))%>%
  dplyr::mutate(iso= 
                  dplyr::case_when(`Region, subregion, country or area *`=="Czechia"~"CZE",
                      `Region, subregion, country or area *`=="Venezuela (Bolivarian Republic of)"~"VEN",
                      `Region, subregion, country or area *`=="Bolivia (Plurinational State of)"~"BOL",
                      `Region, subregion, country or area *`=="Micronesia (Fed. States of)"~"FSM",
                      `Region, subregion, country or area *`=="Republic of Moldova"~"MDA",
                      `Region, subregion, country or area *`=="Russian Federation"~"RUS",
                      `Region, subregion, country or area *`=="North Macedonia"~"MKD",
                      `Region, subregion, country or area *`=="United Republic of Tanzania"~"TZA",
                      `Region, subregion, country or area *`=="Congo"~"COG",
                      `Region, subregion, country or area *`=="Sao Tome and Principe"~"STP",
                      `Region, subregion, country or area *`=="Eswatini"~"SWZ",
                      `Region, subregion, country or area *`=="Cabo Verde"~"CPV",
                      `Region, subregion, country or area *`=="Côte d'Ivoire"~"CIV",
                      `Region, subregion, country or area *`=="Syrian Arab Republic"~"SYR",
                      `Region, subregion, country or area *`=="Iran (Islamic Republic of)"~"IRN",
                      `Region, subregion, country or area *`=="China, Macao"~"MAC",
                      `Region, subregion, country or area *`=="Republic of Korea Dem. People's"~"PRK",
                      `Region, subregion, country or area *`=="Republic of Korea"~"KOR",
                      `Region, subregion, country or area *`=="Brunei Darussalam"~"BRN",
                      `Region, subregion, country or area *`=="Lao People's Democratic Republic"~"LAO",
                      `Region, subregion, country or area *`=="Timor-Leste"~"TLS",
                      `Region, subregion, country or area *`=="Viet Nam"~"VNM",
                      `Region, subregion, country or area *`=="Guadeloupe"~"GLP",
                            TRUE~as.character(`3166-1-alpha-3`)))%>%
  distinct(iso,.keep_all=T)
```

```{r life_exp_60_2, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_11%>%
    dplyr::left_join(dplyr::select(who_life_exp_60_both_sex,iso, `2015-2020`),
                     by=c("iso_code"="iso"))%>%
    dplyr::filter(is.na(`2015-2020`))%>%
    dplyr::group_by(iso_code,country)%>%
    dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
    dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 44: ', htmltools::em('Countries of our dataset that did not match with  dataset in Life-Expectancy at 60')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

As seen in the Table above, most of these countries did have a complicated position in geopolitical terms. **That is why we matched the data anyways.**

<br>

```{r life_exp_60_3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_115<-
          coronavirus_iso3c_11%>%
              dplyr::left_join(dplyr::select(who_life_exp_60_both_sex,iso, `2015-2020`),
                               by=c("iso_code"="iso"))%>%
            dplyr::rename("life_exp_15_20"="2015-2020")%>%
            dplyr::group_by(iso_code)%>%
            dplyr::mutate(ndays_zero=row_number()+52)%>%
            ungroup()
```

## DALYs All ages

We also obtained the Disability-Adjusted Life Year (DALYs) from all causes per 100,000 individuals, standardized by age groups available in this [link](https://ourworldindata.org/burden-of-disease). The variables selected were `DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: Age-standardized (Rate)` and `DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: All Ages (Rate)`.

```{r dalys1, echo=T, cache= T, paged.print=TRUE,eval=T}
daly_all_ages <-tryCatch(
    {
       readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/daly-rates-from-all-causes-by-age.csv")%>% 
        dplyr::select(matches("Entity|Code|Year$|All Ages|Age-standardized")) %>% 
        dplyr::rename("dalys_std_age_rate"="DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: Age-standardized (Rate)", "dalys_all_ages_rate"="DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: All Ages (Rate)")
    },
    error = function(e){
 readr::read_csv(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"daly-rates-from-all-causes-by-age.csv")) %>% 
        dplyr::select(matches("Entity|Code|Year$|All Ages|Age-standardized")) %>% 
        dplyr::rename("dalys_std_age_rate"="DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: Age-standardized (Rate)", "dalys_all_ages_rate"="DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: All Ages (Rate)")
    }
)
```


```{r dalys2, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_115%>%
    dplyr::left_join(dplyr::select(daly_all_ages,Code, dalys_std_age_rate),
                     by=c("iso_code"="Code"))%>%
    dplyr::filter(is.na(dalys_std_age_rate))%>%
    dplyr::group_by(iso_code,country)%>%
    dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
    dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 45: ', htmltools::em('Countries of our dataset that did not match with dataset of GBD All causes')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

```{r dalys3, echo=T, cache= T, paged.print=TRUE,eval=T}
daly_all_ages%>%
    dplyr::anti_join(coronavirus_iso3c_115,
                     by=c("Code"="iso_code"))%>%
    dplyr::group_by(Code, Entity)%>%
    dplyr::summarise(N=n(), last_date=max(Year),first_date=min(Year))%>%
    dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 46: ', htmltools::em('Countries of GBD All causes dataset that did not match with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

```{r dalys4, echo=T, cache= T, paged.print=TRUE,eval=T}
daly_all_ages_sum<-
daly_all_ages %>% 
    dplyr::group_by(Code) %>% 
    dplyr::arrange(Code, desc(Year)) %>% 
    dplyr::slice_max(order_by = desc("Year"),n=1)

coronavirus_iso3c_12<-
    coronavirus_iso3c_115%>%
    dplyr::left_join(dplyr::select(daly_all_ages_sum,Code,Year,dalys_all_ages_rate, dalys_std_age_rate), by=c("iso_code"="Code"))%>%
    dplyr::rename("dalys_all_ages_year"="Year")
```

<br>

## Temperature from ERA5

### a. TEMPERATURE

2m temperature or near surface temperature is the air temperature at 2 meters above the surface, so it is the temperature that affects people. Reanalysis data uses forecast models and data assimilation systems to "reanalyse" archived observations, creating global data sets describing the recent history of the atmosphere, land surface, and oceans. What was obtained: 2m temperature from ERA5 monthly averaged data on single levels from 1979 to present.

The request included data from Nov2019 to Oct2020, area: globally, grid: 0.25 x 0.25.

ERA 5: <https://cds.climate.copernicus.eu/cdsapp#!/home>

### b. COUNTRY PROFILES

To obtain country information, 148 country profiles were obtained from GADM: <https://gadm.org/index.html>

These profiles are used to obtain specific country areas considering temperature grids. Two countries were not find in this database, so were profiled using coordinate in ERA5 requirement.

::: {style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:650px; overflow-x: scroll; width:100%"}
```{r era5_1, echo=T, cache= T, paged.print=TRUE,eval=T}
#####################################################################
#         Analysis 2m temperature (Near-Surface Temperature) ERA5
#         Profiling each country to obtain monthly temp information
#####################################################################

#####################################################################
# Data and Sources
#####################################################################
# 1. TEMPERATURE 
# 2m temperature or near surface temperature is the air temperature 
# at 2 meters above the surface, so it is the temperature that 
# affects people.
# Reanalysis data uses forecast models and data assimilation systems
# to "reanalyse" archived observations, creating global data sets 
# describing the recent history of the atmosphere, land surface, and oceans.
# What was obtained: 2m temperature from ERA5 monthly averaged data 
# on single levels from 1979 to present. 
# The request included data from Nov2019 to Oct2020, area: globally,
# grid: 0.25 x 0.25.
# ERA 5: https://cds.climate.copernicus.eu/cdsapp#!/home

# 2. COUNTRY PROFILES
# To obtain country information, 148 country profiles were obtained from:
# GADM: https://gadm.org/index.html
# These profiles are used to obtain specific country areas considering 
# temperature grids. Two countries were not find in this database, so were
# profiled using coordinate in ERA5 requirement. 

## Some libraries:
library(raster)    # raster spatial data processing
library(rasterVis)
library(sf)        # vector spatial data processing
library(sp)
library(ncdf4)
library(rgdal)
library(dplyr)

#####################################################################
# Loading profiles of countries
#####################################################################
#setwd("C:/Users/yasna/OneDrive/Escritorio/Kasim/Countries")

path_rds<-gsub("Dataset_Cons_post_ago.Rmd","TemperatureGRID/TemperaturesGRIDdata/Countries/",rstudioapi::getSourceEditorContext()$path)


bordersAFG <- readRDS(paste0(path_rds,"gadm36_AFG_0_sp.rds"))
bordersALB <- readRDS(paste0(path_rds,"gadm36_ALB_0_sp.rds"))
bordersDZA <- readRDS(paste0(path_rds,"gadm36_DZA_0_sp.rds"))
bordersAGO <- readRDS(paste0(path_rds,"gadm36_AGO_0_sp.rds"))
bordersARG <- readRDS(paste0(path_rds,"gadm36_ARG_0_sp.rds"))
bordersAUS <- readRDS(paste0(path_rds,"gadm36_AUS_0_sp.rds"))
bordersAUT <- readRDS(paste0(path_rds,"gadm36_AUT_0_sp.rds"))
bordersAZE <- readRDS(paste0(path_rds,"gadm36_AZE_0_sp.rds"))
bordersBHR <- readRDS(paste0(path_rds,"gadm36_BHR_0_sp.rds"))
bordersBGD <- readRDS(paste0(path_rds,"gadm36_BGD_0_sp.rds"))
bordersBRB <- readRDS(paste0(path_rds,"gadm36_BRB_0_sp.rds"))
bordersBLR <- readRDS(paste0(path_rds,"gadm36_BLR_0_sp.rds"))
bordersBEL <- readRDS(paste0(path_rds,"gadm36_BEL_0_sp.rds"))
bordersBLZ <- readRDS(paste0(path_rds,"gadm36_BLZ_0_sp.rds"))
bordersBEN <- readRDS(paste0(path_rds,"gadm36_BEN_0_sp.rds"))
bordersBTN <- readRDS(paste0(path_rds,"gadm36_BTN_0_sp.rds"))
bordersBOL <- readRDS(paste0(path_rds,"gadm36_BOL_0_sp.rds"))
bordersBIH <- readRDS(paste0(path_rds,"gadm36_BIH_0_sp.rds"))
bordersBWA <- readRDS(paste0(path_rds,"gadm36_BWA_0_sp.rds"))
bordersBRA <- readRDS(paste0(path_rds,"gadm36_BRA_0_sp.rds"))
bordersBRN <- readRDS(paste0(path_rds,"gadm36_BRN_0_sp.rds"))
bordersBGR <- readRDS(paste0(path_rds,"gadm36_BGR_0_sp.rds"))
bordersBFA <- readRDS(paste0(path_rds,"gadm36_BFA_0_sp.rds"))
bordersBDI <- readRDS(paste0(path_rds,"gadm36_BDI_0_sp.rds"))
bordersKHM <- readRDS(paste0(path_rds,"gadm36_KHM_0_sp.rds"))
bordersCMR <- readRDS(paste0(path_rds,"gadm36_CMR_0_sp.rds"))
bordersCPV <- readRDS(paste0(path_rds,"gadm36_CPV_0_sp.rds"))
bordersCAF <- readRDS(paste0(path_rds,"gadm36_CAF_0_sp.rds"))
bordersTCD <- readRDS(paste0(path_rds,"gadm36_TCD_0_sp.rds"))
bordersCAN <- readRDS(paste0(path_rds,"gadm36_CAN_0_sp.rds"))
bordersCHL <- readRDS(paste0(path_rds,"gadm36_CHL_0_sp.rds"))
bordersCHN <- readRDS(paste0(path_rds,"gadm36_CHN_0_sp.rds"))
bordersCOL <- readRDS(paste0(path_rds,"gadm36_COL_0_sp.rds"))
bordersCRI <- readRDS(paste0(path_rds,"gadm36_CRI_0_sp.rds"))
bordersCIV <- readRDS(paste0(path_rds,"gadm36_CIV_0_sp.rds"))
bordersHRV <- readRDS(paste0(path_rds,"gadm36_HRV_0_sp.rds"))
bordersCYP <- readRDS(paste0(path_rds,"gadm36_CYP_0_sp.rds"))
bordersCZE <- readRDS(paste0(path_rds,"gadm36_CZE_0_sp.rds"))
bordersCOD <- readRDS(paste0(path_rds,"gadm36_COD_0_sp.rds"))
bordersDNK <- readRDS(paste0(path_rds,"gadm36_DNK_0_sp.rds"))
bordersDJI <- readRDS(paste0(path_rds,"gadm36_DJI_0_sp.rds"))
bordersDOM <- readRDS(paste0(path_rds,"gadm36_DOM_0_sp.rds"))
bordersECU <- readRDS(paste0(path_rds,"gadm36_ECU_0_sp.rds"))
bordersEGY <- readRDS(paste0(path_rds,"gadm36_EGY_0_sp.rds"))
bordersSLV <- readRDS(paste0(path_rds,"gadm36_SLV_0_sp.rds"))
bordersEST <- readRDS(paste0(path_rds,"gadm36_EST_0_sp.rds"))
bordersETH <- readRDS(paste0(path_rds,"gadm36_ETH_0_sp.rds"))
bordersFJI <- readRDS(paste0(path_rds,"gadm36_FJI_0_sp.rds"))
bordersFIN <- readRDS(paste0(path_rds,"gadm36_FIN_0_sp.rds"))
bordersFRA <- readRDS(paste0(path_rds,"gadm36_FRA_0_sp.rds"))
bordersGAB <- readRDS(paste0(path_rds,"gadm36_GAB_0_sp.rds"))
bordersGMB <- readRDS(paste0(path_rds,"gadm36_GMB_0_sp.rds"))
bordersGEO <- readRDS(paste0(path_rds,"gadm36_GEO_0_sp.rds"))
bordersDEU <- readRDS(paste0(path_rds,"gadm36_DEU_0_sp.rds"))
bordersGHA <- readRDS(paste0(path_rds,"gadm36_GHA_0_sp.rds"))
bordersGRC <- readRDS(paste0(path_rds,"gadm36_GRC_0_sp.rds"))
bordersGTM <- readRDS(paste0(path_rds,"gadm36_GTM_0_sp.rds"))
bordersGIN <- readRDS(paste0(path_rds,"gadm36_GIN_0_sp.rds"))
bordersGUY <- readRDS(paste0(path_rds,"gadm36_GUY_0_sp.rds"))
bordersHTI <- readRDS(paste0(path_rds,"gadm36_HTI_0_sp.rds"))
bordersHND <- readRDS(paste0(path_rds,"gadm36_HND_0_sp.rds"))
bordersHUN <- readRDS(paste0(path_rds,"gadm36_HUN_0_sp.rds"))
bordersISL <- readRDS(paste0(path_rds,"gadm36_ISL_0_sp.rds"))
bordersIND <- readRDS(paste0(path_rds,"gadm36_IND_0_sp.rds"))
bordersIRN <- readRDS(paste0(path_rds,"gadm36_IRN_0_sp.rds"))
bordersIRQ <- readRDS(paste0(path_rds,"gadm36_IRQ_0_sp.rds"))
bordersIRL <- readRDS(paste0(path_rds,"gadm36_IRL_0_sp.rds"))
bordersIDN <- readRDS(paste0(path_rds,"gadm36_IDN_0_sp.rds"))
bordersISR <- readRDS(paste0(path_rds,"gadm36_ISR_0_sp.rds"))
bordersITA <- readRDS(paste0(path_rds,"gadm36_ITA_0_sp.rds"))
bordersJAM <- readRDS(paste0(path_rds,"gadm36_JAM_0_sp.rds"))
bordersJPN <- readRDS(paste0(path_rds,"gadm36_JPN_0_sp.rds"))
bordersJOR <- readRDS(paste0(path_rds,"gadm36_JOR_0_sp.rds"))
bordersKAZ <- readRDS(paste0(path_rds,"gadm36_KAZ_0_sp.rds"))
bordersKEN <- readRDS(paste0(path_rds,"gadm36_KEN_0_sp.rds"))
bordersKWT <- readRDS(paste0(path_rds,"gadm36_KWT_0_sp.rds"))
bordersKGZ <- readRDS(paste0(path_rds,"gadm36_KGZ_0_sp.rds"))
bordersLAO <- readRDS(paste0(path_rds,"gadm36_LAO_0_sp.rds"))
bordersLVA <- readRDS(paste0(path_rds,"gadm36_LVA_0_sp.rds"))
bordersLBN <- readRDS(paste0(path_rds,"gadm36_LBN_0_sp.rds"))
bordersLBR <- readRDS(paste0(path_rds,"gadm36_LBR_0_sp.rds"))
bordersLBY <- readRDS(paste0(path_rds,"gadm36_LBY_0_sp.rds"))
bordersLTU <- readRDS(paste0(path_rds,"gadm36_LTU_0_sp.rds"))
bordersLUX <- readRDS(paste0(path_rds,"gadm36_LUX_0_sp.rds"))
bordersMDG <- readRDS(paste0(path_rds,"gadm36_MDG_0_sp.rds"))
bordersMWI <- readRDS(paste0(path_rds,"gadm36_MWI_0_sp.rds"))
bordersMYS <- readRDS(paste0(path_rds,"gadm36_MYS_0_sp.rds"))
bordersMLI <- readRDS(paste0(path_rds,"gadm36_MLI_0_sp.rds"))
bordersMRT <- readRDS(paste0(path_rds,"gadm36_MRT_0_sp.rds"))
bordersMUS <- readRDS(paste0(path_rds,"gadm36_MUS_0_sp.rds"))
bordersMEX <- readRDS(paste0(path_rds,"gadm36_MEX_0_sp.rds"))
bordersMDA <- readRDS(paste0(path_rds,"gadm36_MDA_0_sp.rds"))
bordersMNG <- readRDS(paste0(path_rds,"gadm36_MNG_0_sp.rds"))
bordersMAR <- readRDS(paste0(path_rds,"gadm36_MAR_0_sp.rds"))
bordersMOZ <- readRDS(paste0(path_rds,"gadm36_MOZ_0_sp.rds"))
bordersNPL <- readRDS(paste0(path_rds,"gadm36_NPL_0_sp.rds"))
bordersNLD <- readRDS(paste0(path_rds,"gadm36_NLD_0_sp.rds"))
bordersNIC <- readRDS(paste0(path_rds,"gadm36_NIC_0_sp.rds"))
bordersNZL <- readRDS(paste0(path_rds,"gadm36_NZL_0_sp.rds"))
bordersNER <- readRDS(paste0(path_rds,"gadm36_NER_0_sp.rds"))
bordersNGA <- readRDS(paste0(path_rds,"gadm36_NGA_0_sp.rds"))
bordersNOR <- readRDS(paste0(path_rds,"gadm36_NOR_0_sp.rds"))
bordersOMN <- readRDS(paste0(path_rds,"gadm36_OMN_0_sp.rds"))
bordersPAK <- readRDS(paste0(path_rds,"gadm36_PAK_0_sp.rds"))
bordersPAN <- readRDS(paste0(path_rds,"gadm36_PAN_0_sp.rds"))
bordersPNG <- readRDS(paste0(path_rds,"gadm36_PNG_0_sp.rds"))
bordersPRY <- readRDS(paste0(path_rds,"gadm36_PRY_0_sp.rds"))
bordersPER <- readRDS(paste0(path_rds,"gadm36_PER_0_sp.rds"))
bordersPHL <- readRDS(paste0(path_rds,"gadm36_PHL_0_sp.rds"))
bordersPOL <- readRDS(paste0(path_rds,"gadm36_POL_0_sp.rds"))
bordersPRT <- readRDS(paste0(path_rds,"gadm36_PRT_0_sp.rds"))
bordersROU <- readRDS(paste0(path_rds,"gadm36_ROU_0_sp.rds"))
bordersRUS <- readRDS(paste0(path_rds,"gadm36_RUS_0_sp.rds"))
bordersRWA <- readRDS(paste0(path_rds,"gadm36_RWA_0_sp.rds"))
bordersSAU <- readRDS(paste0(path_rds,"gadm36_SAU_0_sp.rds"))
bordersSEN <- readRDS(paste0(path_rds,"gadm36_SEN_0_sp.rds"))
bordersSYC <- readRDS(paste0(path_rds,"gadm36_SYC_0_sp.rds"))
bordersSLE <- readRDS(paste0(path_rds,"gadm36_SLE_0_sp.rds"))
bordersSGP <- readRDS(paste0(path_rds,"gadm36_SGP_0_sp.rds"))
bordersSVK <- readRDS(paste0(path_rds,"gadm36_SVK_0_sp.rds"))
bordersSVN <- readRDS(paste0(path_rds,"gadm36_SVN_0_sp.rds"))
bordersZAF <- readRDS(paste0(path_rds,"gadm36_ZAF_0_sp.rds"))
bordersKOR <- readRDS(paste0(path_rds,"gadm36_KOR_0_sp.rds"))
bordersESP <- readRDS(paste0(path_rds,"gadm36_ESP_0_sp.rds"))
bordersLKA <- readRDS(paste0(path_rds,"gadm36_LKA_0_sp.rds"))
bordersSUR <- readRDS(paste0(path_rds,"gadm36_SUR_0_sp.rds"))
bordersSWZ <- readRDS(paste0(path_rds,"gadm36_SWZ_0_sp.rds"))
bordersSWE <- readRDS(paste0(path_rds,"gadm36_SWE_0_sp.rds"))
bordersCHE <- readRDS(paste0(path_rds,"gadm36_CHE_0_sp.rds"))
bordersTJK <- readRDS(paste0(path_rds,"gadm36_TJK_0_sp.rds"))
bordersTZA <- readRDS(paste0(path_rds,"gadm36_TZA_0_sp.rds"))
bordersTHA <- readRDS(paste0(path_rds,"gadm36_THA_0_sp.rds"))
bordersTGO <- readRDS(paste0(path_rds,"gadm36_TGO_0_sp.rds"))
bordersTTO <- readRDS(paste0(path_rds,"gadm36_TTO_0_sp.rds"))
bordersTUN <- readRDS(paste0(path_rds,"gadm36_TUN_0_sp.rds"))
bordersTUR <- readRDS(paste0(path_rds,"gadm36_TUR_0_sp.rds"))
bordersUGA <- readRDS(paste0(path_rds,"gadm36_UGA_0_sp.rds"))
bordersUKR <- readRDS(paste0(path_rds,"gadm36_UKR_0_sp.rds"))
bordersARE <- readRDS(paste0(path_rds,"gadm36_ARE_0_sp.rds"))
bordersGBR <- readRDS(paste0(path_rds,"gadm36_GBR_0_sp.rds"))
bordersURY <- readRDS(paste0(path_rds,"gadm36_URY_0_sp.rds"))
bordersUSA <- readRDS(paste0(path_rds,"gadm36_USA_0_sp.rds"))
bordersUZB <- readRDS(paste0(path_rds,"gadm36_UZB_0_sp.rds"))
bordersVEN <- readRDS(paste0(path_rds,"gadm36_VEN_0_sp.rds"))
bordersVNM <- readRDS(paste0(path_rds,"gadm36_VNM_0_sp.rds"))
bordersYEM <- readRDS(paste0(path_rds,"gadm36_YEM_0_sp.rds"))
bordersZMB <- readRDS(paste0(path_rds,"gadm36_ZMB_0_sp.rds"))
bordersZWE <- readRDS(paste0(path_rds,"gadm36_ZWE_0_sp.rds"))

# Pending: Congo and Timor
# Get these countries based on coordinates:
# Congo: N=5.1; S=-11 ; E=28 ; W=12
# Timor: N=-8; S=-9 ; E=127 ; W=125

#####################################################################
# Temperature - Global grids
#####################################################################

#setwd(gsub("Dataset_Cons_post_ago.Rmd","TemperatureGRID/TemperaturesGRIDdata/Temperature",rstudioapi::getSourceEditorContext()$path))

path_temp<-
gsub("Dataset_Cons_post_ago.Rmd","TemperatureGRID/TemperaturesGRIDdata/Temperature/",rstudioapi::getSourceEditorContext()$path)

# Exploring .nc
t2019 <- nc_open(paste0(path_temp,"kasim2019.nc"))
print(t2019)

t2020 <- nc_open(paste0(path_temp,"kasim2020.nc")) # For 2020, 2 variables. Why? 01 for Jan-Aug, 05 for Sep,Nov
print(t2020)
names(t2020)
names(t2020$var)
head(t2020$var)

t2020Congo <- nc_open(paste0(path_temp,"kasim2020Congo.nc"))
print(t2020Congo)

# TRANSFORM TO BRICK AND DELETE SOME LAYERS
# T Global
t2019B <- brick(paste0(path_temp,"kasim2019.nc"), varname="t2m")

t2020B_01 <- brick(paste0(path_temp,"kasim2020.nc"), varname="t2m_0001")
names(t2020B_01)
t2020B_01 <- dropLayer(t2020B_01, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01)

t2020B_05 <- brick(paste0(path_temp,"kasim2020.nc"), varname="t2m_0005")
names(t2020B_05)
t2020B_05 <- dropLayer(t2020B_05, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                    "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                    "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05)

# T SA
t2019B_SA <- brick(paste0(path_temp,"kasim2019SA.nc"), varname="t2m")
t2020B_01_SA <- brick(paste0(path_temp,"kasim2020SA.nc"), varname="t2m_0001")
t2020B_01_SA <- dropLayer(t2020B_01_SA, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_SA)
t2020B_05_SA <- brick(paste0(path_temp,"kasim2020SA.nc"), varname="t2m_0005")
t2020B_05_SA <- dropLayer(t2020B_05_SA, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                    "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                    "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_SA)

# T NA
t2019B_NA <- brick(paste0(path_temp,"kasim2019NA.nc"), varname="t2m")
t2020B_01_NA <- brick(paste0(path_temp,"kasim2020NA.nc"), varname="t2m_0001")
t2020B_01_NA <- dropLayer(t2020B_01_NA, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_NA)
t2020B_05_NA <- brick(paste0(path_temp,"kasim2020NA.nc"), varname="t2m_0005")
t2020B_05_NA <- dropLayer(t2020B_05_NA, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                          "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                          "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_NA)

# T C. America & Caribbean
t2019B_Car <- brick(paste0(path_temp,"kasim2019Car.nc"), varname="t2m")
t2020B_01_Car <- brick(paste0(path_temp,"kasim2020Car.nc"), varname="t2m_0001")
t2020B_01_Car <- dropLayer(t2020B_01_Car, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_Car)
t2020B_05_Car <- brick(paste0(path_temp,"kasim2020Car.nc"), varname="t2m_0005")
t2020B_05_Car <- dropLayer(t2020B_05_Car, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                          "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                          "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_Car)

# T Africa
t2019B_Africa <- brick(paste0(path_temp,"kasim2019Africa.nc"), varname="t2m")
t2020B_01_Africa <- brick(paste0(path_temp,"kasim2020Africa.nc"), varname="t2m_0001")
t2020B_01_Africa <- dropLayer(t2020B_01_Africa, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_Africa)
t2020B_05_Africa <- brick(paste0(path_temp,"kasim2020Africa.nc"), varname="t2m_0005")
t2020B_05_Africa <- dropLayer(t2020B_05_Africa, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                          "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                          "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_Africa)

# T Europe
t2019B_EU <- brick(paste0(path_temp,"kasim2019EU.nc"), varname="t2m")
t2020B_01_EU <- brick(paste0(path_temp,"kasim2020EU.nc"), varname="t2m_0001")
t2020B_01_EU <- dropLayer(t2020B_01_EU, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_EU)
t2020B_05_EU <- brick(paste0(path_temp,"kasim2020EU.nc"), varname="t2m_0005")
t2020B_05_EU <- dropLayer(t2020B_05_EU, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                          "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                          "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_EU)

# T Iceland
t2019B_Iceland <- brick(paste0(path_temp,"kasim2019Iceland.nc"), varname="t2m")
t2020B_01_Iceland <- brick(paste0(path_temp,"kasim2020Iceland.nc"), varname="t2m_0001")
t2020B_01_Iceland <- dropLayer(t2020B_01_Iceland, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
plot(t2020B_01_Iceland)
t2020B_05_Iceland <- brick(paste0(path_temp,"kasim2020Iceland.nc"), varname="t2m_0005")
t2020B_05_Iceland <- dropLayer(t2020B_05_Iceland, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                          "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                          "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
plot(t2020B_05_Iceland)

# T Congo
t2019CongoB <- brick(paste0(path_temp,"kasim2019Congo.nc"), varname="t2m")
t2020CongoB_01 <- brick(paste0(path_temp,"kasim2020Congo.nc"), varname="t2m_0001")
t2020B_01_Congo <- dropLayer(t2020CongoB_01, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
t2020CongoB_05 <- brick(paste0(path_temp,"kasim2020Congo.nc"), varname="t2m_0005")
t2020B_05_Congo <- dropLayer(t2020CongoB_05, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                                    "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                                    "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))
# T Timor
t2019TimorB <- brick(paste0(path_temp,"kasim2019Timor.nc"), varname="t2m")
t2020TimorB_01 <- brick(paste0(path_temp,"kasim2020Timor.nc"), varname="t2m_0001")
t2020B_01_Timor <- dropLayer(t2020TimorB_01, c("X2020.09.01.01.00.00", "X2020.10.01.01.00.00"))
t2020TimorB_05 <- brick(paste0(path_temp,"kasim2020Timor.nc"), varname="t2m_0005")
t2020B_05_Timor <- dropLayer(t2020TimorB_05, c("X2020.01.01.00.00.00", "X2020.02.01.00.00.00", "X2020.03.01.00.00.00",
                                               "X2020.04.01.01.00.00", "X2020.05.01.01.00.00", "X2020.06.01.01.00.00",
                                               "X2020.07.01.01.00.00", "X2020.08.01.01.00.00"))

# MERGE FILES 2019-2020
tGlobal <- stack(t2019B, t2020B_01, t2020B_05)
nlayers(tGlobal)
plot(tGlobal)

tSA <- stack(t2019B_SA, t2020B_01_SA, t2020B_05_SA)
tNA <- stack(t2019B_NA, t2020B_01_NA, t2020B_05_NA)
tCar <- stack(t2019B_Car, t2020B_01_Car, t2020B_05_Car)
tAfrica <- stack(t2019B_Africa, t2020B_01_Africa, t2020B_05_Africa)
tEU <- stack(t2019B_EU, t2020B_01_EU, t2020B_05_EU)
tIceland <- stack(t2019B_Iceland, t2020B_01_Iceland, t2020B_05_Iceland)
tCongo <- stack(t2019CongoB, t2020B_01_Congo, t2020B_05_Congo)
tTimor <- stack(t2019TimorB, t2020B_01_Timor, t2020B_05_Timor)

tGlobal <- tGlobal - 273.15 
tSA <- tSA - 273.15 
tNA <- tNA - 273.15 
tCar <- tCar - 273.15 
tAfrica <- tAfrica - 273.15 
tEU <- tEU - 273.15 

#2021-09-05 Agregué la resta
tIceland <- tIceland- 273.15

tCongo <- tCongo - 273.15
tTimor <- tTimor - 273.15


#####################################################################
# Cropping data for each country
#####################################################################

t_AFG <- mask(tGlobal, bordersAFG) %>% crop(bordersAFG)
t_ALB <- mask(tGlobal, bordersALB) %>% crop(bordersALB)
t_DZA <- mask(tGlobal, bordersDZA) %>% crop(bordersDZA)
t_AGO <- mask(tGlobal, bordersAGO) %>% crop(bordersAGO)
t_ARG <- mask(tSA, bordersARG) %>% crop(bordersARG)
t_AUS <- mask(tGlobal, bordersAUS) %>% crop(bordersAUS)
t_AUT <- mask(tGlobal, bordersAUT) %>% crop(bordersAUT)
t_AZE <- mask(tGlobal, bordersAZE) %>% crop(bordersAZE)
t_BHR <- mask(tGlobal, bordersBHR) %>% crop(bordersBHR)
t_BGD <- mask(tGlobal, bordersBGD) %>% crop(bordersBGD)
t_BRB <- mask(tCar, bordersBRB) %>% crop(bordersBRB)
t_BLR <- mask(tGlobal, bordersBLR) %>% crop(bordersBLR)
t_BEL <- mask(tGlobal, bordersBEL) %>% crop(bordersBEL)
t_BLZ <- mask(tCar, bordersBLZ) %>% crop(bordersBLZ)
t_BEN <- mask(tGlobal, bordersBEN) %>% crop(bordersBEN)
t_BTN <- mask(tGlobal, bordersBTN) %>% crop(bordersBTN)
t_BOL <- mask(tSA, bordersBOL) %>% crop(bordersBOL)
t_BIH <- mask(tGlobal, bordersBIH) %>% crop(bordersBIH)
t_BWA <- mask(tGlobal, bordersBWA) %>% crop(bordersBWA)
t_BRA <- mask(tSA, bordersBRA) %>% crop(bordersBRA)
t_BRN <- mask(tGlobal, bordersBRN) %>% crop(bordersBRN)
t_BGR <- mask(tGlobal, bordersBGR) %>% crop(bordersBGR)
t_BFA <- mask(tGlobal, bordersBFA) %>% crop(bordersBFA)
t_BDI <- mask(tGlobal, bordersBDI) %>% crop(bordersBDI)
t_KHM <- mask(tGlobal, bordersKHM) %>% crop(bordersKHM)
t_CMR <- mask(tGlobal, bordersCMR) %>% crop(bordersCMR)
t_CPV <- mask(tAfrica, bordersCPV) %>% crop(bordersCPV)
t_CAF <- mask(tGlobal, bordersCAF) %>% crop(bordersCAF)
t_TCD <- mask(tGlobal, bordersTCD) %>% crop(bordersTCD)
t_CAN <- mask(tNA, bordersCAN) %>% crop(bordersCAN)
t_CHL <- mask(tSA, bordersCHL) %>% crop(bordersCHL)
t_CHN <- mask(tGlobal, bordersCHN) %>% crop(bordersCHN)
t_COL <- mask(tSA, bordersCOL) %>% crop(bordersCOL)
t_COG <- tCongo
t_CRI <- mask(tCar, bordersCRI) %>% crop(bordersCRI)
t_CIV <- mask(tAfrica, bordersCIV) %>% crop(bordersCIV)
t_HRV <- mask(tGlobal, bordersHRV) %>% crop(bordersHRV)
t_CYP <- mask(tGlobal, bordersCYP) %>% crop(bordersCYP)
t_CZE <- mask(tGlobal, bordersCZE) %>% crop(bordersCZE)
t_COD <- mask(tGlobal, bordersCOD) %>% crop(bordersCOD)
t_DNK <- mask(tGlobal, bordersDNK) %>% crop(bordersDNK)
t_DJI <- mask(tGlobal, bordersDJI) %>% crop(bordersDJI)
t_DOM <- mask(tCar, bordersDOM) %>% crop(bordersDOM)
t_ECU <- mask(tSA, bordersECU) %>% crop(bordersECU)
t_EGY <- mask(tGlobal, bordersEGY) %>% crop(bordersEGY)
t_SLV <- mask(tCar, bordersSLV) %>% crop(bordersSLV)
t_EST <- mask(tGlobal, bordersEST) %>% crop(bordersEST)
t_ETH <- mask(tGlobal, bordersETH) %>% crop(bordersETH)
t_FJI <- mask(tGlobal, bordersFJI) %>% crop(bordersFJI)
t_FIN <- mask(tGlobal, bordersFIN) %>% crop(bordersFIN)
t_FRA <- mask(tGlobal, bordersFRA) %>% crop(bordersFRA)
t_GAB <- mask(tGlobal, bordersGAB) %>% crop(bordersGAB)
t_GMB <- mask(tAfrica, bordersGMB) %>% crop(bordersGMB)
t_GEO <- mask(tGlobal, bordersGEO) %>% crop(bordersGEO)
t_DEU <- mask(tGlobal, bordersDEU) %>% crop(bordersDEU)
t_GHA <- mask(tGlobal, bordersGHA) %>% crop(bordersGHA)
t_GRC <- mask(tGlobal, bordersGRC) %>% crop(bordersGRC)
t_GTM <- mask(tCar, bordersGTM) %>% crop(bordersGTM)
t_GIN <- mask(tAfrica, bordersGIN) %>% crop(bordersGIN)
t_GUY <- mask(tSA, bordersGUY) %>% crop(bordersGUY)
t_HTI <- mask(tCar, bordersHTI) %>% crop(bordersHTI)
t_HND <- mask(tCar, bordersHND) %>% crop(bordersHND)
t_HUN <- mask(tGlobal, bordersHUN) %>% crop(bordersHUN)
#2021-09-05 Ver cómo se comporta
t_ISL <- mask(tIceland, bordersISL) %>% crop(bordersISL)
t_IND <- mask(tGlobal, bordersIND) %>% crop(bordersIND)
t_IRN <- mask(tGlobal, bordersIRN) %>% crop(bordersIRN)
t_IRQ <- mask(tGlobal, bordersIRQ) %>% crop(bordersIRQ)
t_IRL <- mask(tEU, bordersIRL) %>% crop(bordersIRL)
t_IDN <- mask(tGlobal, bordersIDN) %>% crop(bordersIDN)
t_ISR <- mask(tGlobal, bordersISR) %>% crop(bordersISR)
t_ITA <- mask(tGlobal, bordersITA) %>% crop(bordersITA)
t_JAM <- mask(tCar, bordersJAM) %>% crop(bordersJAM)
t_JPN <- mask(tGlobal, bordersJPN) %>% crop(bordersJPN)
t_JOR <- mask(tGlobal, bordersJOR) %>% crop(bordersJOR)
t_KAZ <- mask(tGlobal, bordersKAZ) %>% crop(bordersKAZ)
t_KEN <- mask(tGlobal, bordersKEN) %>% crop(bordersKEN)
t_KWT <- mask(tGlobal, bordersKWT) %>% crop(bordersKWT)
t_KGZ <- mask(tGlobal, bordersKGZ) %>% crop(bordersKGZ)
t_LAO <- mask(tGlobal, bordersLAO) %>% crop(bordersLAO)
t_LVA <- mask(tGlobal, bordersLVA) %>% crop(bordersLVA)
t_LBN <- mask(tGlobal, bordersLBN) %>% crop(bordersLBN)
t_LBR <- mask(tAfrica, bordersLBR) %>% crop(bordersLBR)
t_LBY <- mask(tGlobal, bordersLBY) %>% crop(bordersLBY)
t_LTU <- mask(tGlobal, bordersLTU) %>% crop(bordersLTU)
t_LUX <- mask(tGlobal, bordersLUX) %>% crop(bordersLUX)
t_MDG <- mask(tGlobal, bordersMDG) %>% crop(bordersMDG)
t_MWI <- mask(tGlobal, bordersMWI) %>% crop(bordersMWI)
t_MYS <- mask(tGlobal, bordersMYS) %>% crop(bordersMYS)
t_MLI <- mask(tGlobal, bordersMLI) %>% crop(bordersMLI)
t_MRT <- mask(tAfrica, bordersMRT) %>% crop(bordersMRT)
t_MUS <- mask(tGlobal, bordersMUS) %>% crop(bordersMUS)
t_MEX <- mask(tNA, bordersMEX) %>% crop(bordersMEX)
t_MDA <- mask(tGlobal, bordersMDA) %>% crop(bordersMDA)
t_MNG <- mask(tGlobal, bordersMNG) %>% crop(bordersMNG)
t_MAR <- mask(tAfrica, bordersMAR) %>% crop(bordersMAR)
t_MOZ <- mask(tGlobal, bordersMOZ) %>% crop(bordersMOZ)
t_NPL <- mask(tGlobal, bordersNPL) %>% crop(bordersNPL)
t_NLD <- mask(tGlobal, bordersNLD) %>% crop(bordersNLD)
t_NIC <- mask(tCar, bordersNIC) %>% crop(bordersNIC)
t_NZL <- mask(tGlobal, bordersNZL) %>% crop(bordersNZL)
t_NER <- mask(tGlobal, bordersNER) %>% crop(bordersNER)
t_NGA <- mask(tGlobal, bordersNGA) %>% crop(bordersNGA)
t_NOR <- mask(tGlobal, bordersNOR) %>% crop(bordersNOR)
t_OMN <- mask(tGlobal, bordersOMN) %>% crop(bordersOMN)
t_PAK <- mask(tGlobal, bordersPAK) %>% crop(bordersPAK)
t_PAN <- mask(tCar, bordersPAN) %>% crop(bordersPAN)
t_PNG <- mask(tGlobal, bordersPNG) %>% crop(bordersPNG)
t_PRY <- mask(tSA, bordersPRY) %>% crop(bordersPRY)
t_PER <- mask(tSA, bordersPER) %>% crop(bordersPER)
t_PHL <- mask(tGlobal, bordersPHL) %>% crop(bordersPHL)
t_POL <- mask(tGlobal, bordersPOL) %>% crop(bordersPOL)
t_PRT <- mask(tEU, bordersPRT) %>% crop(bordersPRT)
t_ROU <- mask(tGlobal, bordersROU) %>% crop(bordersROU)
t_RUS <- mask(tGlobal, bordersRUS) %>% crop(bordersRUS)
t_RWA <- mask(tGlobal, bordersRWA) %>% crop(bordersRWA)
t_SAU <- mask(tGlobal, bordersSAU) %>% crop(bordersSAU)
t_SEN <- mask(tAfrica, bordersSEN) %>% crop(bordersSEN)
t_SYC <- mask(tGlobal, bordersSYC) %>% crop(bordersSYC)
t_SLE <- mask(tAfrica, bordersSLE) %>% crop(bordersSLE)
t_SGP <- mask(tGlobal, bordersSGP) %>% crop(bordersSGP)
t_SVK <- mask(tGlobal, bordersSVK) %>% crop(bordersSVK)
t_SVN <- mask(tGlobal, bordersSVN) %>% crop(bordersSVN)
t_ZAF <- mask(tGlobal, bordersZAF) %>% crop(bordersZAF)
t_KOR <- mask(tGlobal, bordersKOR) %>% crop(bordersKOR)
t_ESP <- mask(tGlobal, bordersESP) %>% crop(bordersESP)
t_LKA <- mask(tGlobal, bordersLKA) %>% crop(bordersLKA)
t_SUR <- mask(tSA, bordersSUR) %>% crop(bordersSUR)
t_SWZ <- mask(tGlobal, bordersSWZ) %>% crop(bordersSWZ)
t_SWE <- mask(tGlobal, bordersSWE) %>% crop(bordersSWE)
t_CHE <- mask(tGlobal, bordersCHE) %>% crop(bordersCHE)
t_TJK <- mask(tGlobal, bordersTJK) %>% crop(bordersTJK)
t_TZA <- mask(tGlobal, bordersTZA) %>% crop(bordersTZA)
t_THA <- mask(tGlobal, bordersTHA) %>% crop(bordersTHA)
t_TLS <- tTimor
t_TGO <- mask(tGlobal, bordersTGO) %>% crop(bordersTGO)
t_TTO <- mask(tCar, bordersTTO) %>% crop(bordersTTO)
t_TUN <- mask(tGlobal, bordersTUN) %>% crop(bordersTUN)
t_TUR <- mask(tGlobal, bordersTUR) %>% crop(bordersTUR)
t_UGA <- mask(tGlobal, bordersUGA) %>% crop(bordersUGA)
t_UKR <- mask(tGlobal, bordersUKR) %>% crop(bordersUKR)
t_ARE <- mask(tGlobal, bordersARE) %>% crop(bordersARE)
t_GBR <- mask(tGlobal, bordersGBR) %>% crop(bordersGBR)
t_URY <- mask(tSA, bordersURY) %>% crop(bordersURY)
t_USA <- mask(tGlobal, bordersUSA) %>% crop(bordersUSA)
t_UZB <- mask(tGlobal, bordersUZB) %>% crop(bordersUZB)
t_VEN <- mask(tSA, bordersVEN) %>% crop(bordersVEN)
t_VNM <- mask(tGlobal, bordersVNM) %>% crop(bordersVNM)
t_YEM <- mask(tGlobal, bordersYEM) %>% crop(bordersYEM)
t_ZMB <- mask(tGlobal, bordersZMB) %>% crop(bordersZMB)
t_ZWE <- mask(tGlobal, bordersZWE) %>% crop(bordersZWE)


#####################################################################
# From grid data to time series for each country
#####################################################################
# Take the mean of each layer
# then save those averages as TS

#2021-09-05 changed grep to restrict regex to only these iso codes
tempListPre <- grep("^t_.{3}$", names(.GlobalEnv), value=TRUE)#[-"t_mean"]
temp_list <- do.call("list", mget(tempListPre)) # List with all countries

#2021-09-05

temp_df<-data.frame()
no_mostrar=0
if(no_mostrar==1){
  t_mean <- lapply(temp_list, function(x) cellStats(x, mean)) # List with all "mean per layer"
}
for (i in 1:length(tempListPre)){
  xi<-tempListPre[[i]]
  temp_df<-rbind(temp_df,
  cbind(xi,cellStats(temp_list[[xi]], mean, na.rm=T))
  )
}
temp_dt<-data.table::data.table(temp_df, keep.rownames = T)

temp_dt_cons<-
temp_dt %>% 
  #dplyr::filter(xi=="t_NZL") %>% 
  dplyr::mutate(country_cod=gsub("^t_","",xi)) %>% 
  dplyr::mutate(year=dplyr::case_when(grepl("X2019",rn)~"2019",
                                      grepl("X2020",rn)~"2020",
                                      T~NA_character_)) %>% 
  purrr::when(dplyr::filter(.,is.na(year)) %>% nrow()>0 ~ stop("missing months in transformation"), 
              ~.) %>% 
  dplyr::mutate(month=dplyr::case_when(grepl("^X2019.11",rn)~11,
                                       grepl("^X2019.12",rn)~12,
                                      grepl("^X2020.01",rn)~1,
                                      grepl("^X2020.02",rn)~2,
                                      grepl("^X2020.03",rn)~3,
                                      grepl("^X2020.04",rn)~4,
                                      grepl("^X2020.05",rn)~5,
                                      grepl("^X2020.06",rn)~6,
                                      grepl("^X2020.07",rn)~7,
                                      grepl("^X2020.08",rn)~8,
                                      grepl("^X2020.09",rn)~9,
                                      grepl("^X2020.10",rn)~10,
                                      grepl("^X2020.11",rn)~11,
                                      grepl("^X2020.12",rn)~12,
                                      T~NA_real_)) %>% 
  purrr::when(dplyr::filter(.,is.na(month)) %>% nrow()>0 ~ stop("missing months in transformation"), 
              ~.) %>% 
  dplyr::select(country_cod,V2,month, year) %>% 
  dplyr::mutate(V2=as.numeric(V2))%>% 
  dplyr::filter(!is.nan(V2)) %>% 
  dplyr::rename("CountryCode"="country_cod", "TemperatureAvg"="V2","Month"="month","Year"="year") 
  
options(OutDec= ",")
rio::export(temp_dt_cons,paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"TempCountryGridALL_2021.csv"), format=";")
options(OutDec= ".")
# Save all files as .csv
#2021-09-05
no_mostrar=0
if(no_mostrar==1){
  setwd(gsub("Dataset_Cons_post_ago.Rmd","TemperatureGRID/TemperaturesGRIDdata/allCSV",rstudioapi::getSourceEditorContext()$path))
lapply(1:length(t_mean), function(i) write.csv(t_mean[[i]], 
                                                file=paste0(names(t_mean[i]),".csv")))
}
```

::: 

```{r era5_2, echo=T, cache= T, paged.print=TRUE,eval=T}
Sys.setlocale(category = "LC_ALL", locale = "english")

coronavirus_iso3c_13<-
   coronavirus_iso3c_12%>%
            dplyr::mutate(mnth=month(dates),yr=as.character(year(dates))) %>% 
            dplyr::left_join(temp_dt_cons,
              by=c("iso_code"="CountryCode","mnth"="Month", "yr"="Year"))%>%
            ungroup()
```

<br>

# Exploration

## Missing values By Countries

<br>

```{r miss_by_cntry, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
col_names_df_pre<-coronavirus_iso3c_13%>%
    dplyr::select(population:last_col())%>% 
    names()

coronavirus_iso3c_13%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:last_col()),~sum(is.na(.))/n())%>%
      dplyr::mutate(sumVar = rowSums(dplyr::select(., .dots = all_of(col_names_df_pre))))%>%
      dplyr::mutate_at(vars(population:last_col()),~scales::percent(.))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 47. Percentage of Missing data in the Different Time Points By Country"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote(c(paste("Note. ",nrow(coronavirus_iso3c_13),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
#`month_temp_16_m`, `month_rainfall_mm_16_m`, `month_temp_07_m`, `month_rainfall_mm_07_m`, `jan`, etc. don't exist.
```

::: {style="border: 1px solid #ddd; padding: 5px; overflow-y: scroll; height:500px; overflow-x: scroll; width:100%"}
```{r miss_total, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T, fig.height=12}
myvars <- names(coronavirus_iso3c_13) %in% c("ndays") 

vim_agg<-
  VIM::aggr(coronavirus_iso3c_13, col=c('navyblue','gray80'),
                    numbers=F, sortVars=TRUE, prop=c(TRUE,FALSE),
                    labels=names(coronavirus_iso3c_13), cex.axis=.5,
                   combined=T,
                    gap=1, ylab=c("Missing data","Pattern"))
```
:::

# Collapse Information into Data Every 30 Days

We collapsed the information into monthly basis, by selecting the maximum number by each month on time variant variables. Also we deleted some variables related to NOAA (`noaa_station`, `noaa_distance`,`average_temperature`, `minimum_temperature`,`maximum_temperature` & `rainfall`) and some of the World Bank Datasets, due to a great amount of missing values (`handwashing_facilities` & `extreme_poverty`, `male_smokers`, `female_smokers`).

<br>

Must take note that Solomon Islands (`SLB`) did not have available information in many variables.

<br>

```{r collapse, message=F,eval=T, error=T, fig.show = 'hide', warning=F}

invisible("")
if(
coronavirus_iso3c_13%>% 
  dplyr::group_by(iso_code)%>%
      dplyr::mutate(month_temp_16_m=mean(month_temp_16,na.rm=T),
                month_rainfall_mm_16_m=mean(month_rainfall_mm_16,na.rm=T),
                month_temp_07_m=mean(month_temp_07,na.rm=T),
                month_rainfall_mm_07_m=mean(month_rainfall_mm_07,na.rm=T))%>%
  #dplyr::mutate_at(.vars = vars(cases_deaths, cases,ndays_zero,ndays,dates),
  #          .funs = funs(`mth`=max(.,na.rm=T)))%>%
  dplyr::ungroup()%>%
###:#:#:#:#:#:#:#
###:#:#:#:#:#:#:#2020-11-01
#  dplyr::mutate(date_month2=date_month) %>% 
#    dplyr::mutate(month_temp_162=month_temp_16) %>% 
#                  tidyr::pivot_wider(names_from =  date_month2, 
#                                   names_sep="_",
#                                   values_from = month_temp_162)%>%
#  dplyr::group_by(iso_code)%>%
#  dplyr::mutate_at(vars(jan:oct),~max(as.character(.),na.rm=T))%>%
#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_
  
#  dplyr::distinct(iso_code,date_month,.keep_all=T)%>%
  dplyr::filter(ndays %in% c(1,30,60,90,120))%>%
  dplyr::select(-noaa_station, -noaa_distance,-average_temperature, -minimum_temperature,- maximum_temperature,-rainfall,-handwashing_facilities,-extreme_poverty, -male_smokers,-female_smokers)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::summarise_all(n_distinct)%>%
  dplyr::filter_at(vars(population:TemperatureAvg), all_vars(.>=2))%>% nrow() >0) #life_exp_15_20 es la última variable después de las reconversiones de tiempo month temp month rainfall y esas 
{stop("We are losing countries due to missing covariates")} 

coronavirus_iso3c_13%>% 
  dplyr::group_by(iso_code)%>%
        dplyr::mutate(month_temp_16_m=mean(month_temp_16,na.rm=T),
                month_rainfall_mm_16_m=mean(month_rainfall_mm_16,na.rm=T),
                month_temp_07_m=mean(month_temp_07,na.rm=T),
                month_rainfall_mm_07_m=mean(month_rainfall_mm_07,na.rm=T))%>%
  
  #dplyr::mutate_at(.vars = vars(cases_deaths, cases,ndays_zero,ndays,stringency_ind_oxf),
  #         .funs = funs(`mth`=max(.)))%>%
  #dplyr::mutate(dates=max(dates))%>%
  dplyr::ungroup()%>%
###:#:#:#:#:#:#:#
###:#:#:#:#:#:#:#2020-11-01
#  dplyr::mutate(date_month2=date_month) %>% 
#    dplyr::mutate(month_temp_162=month_temp_16) %>% 
#                  tidyr::pivot_wider(names_from =  date_month2, 
#                                   names_sep="_",
#                                   values_from = month_temp_162)%>%
#  dplyr::group_by(iso_code)%>%
#  dplyr::mutate_at(vars(jan:oct),~max(as.character(.),na.rm=T))%>%
  
  dplyr::left_join(dplyr::select(temp_exp_16_to_recover_later,-country), by=c("iso_code"="iso3")) %>% 
#_#_#_#_#_#_#_#_#_#_
#_#_#_#_#_#_#_#_#_#_
    
  dplyr::filter(ndays %in% c(1,30,60,90,120))%>%
  #dplyr::distinct(iso_code,date_month,.keep_all=T)%>%
  dplyr::select(-noaa_station, -noaa_distance,-average_temperature, -minimum_temperature,- maximum_temperature,-rainfall,-handwashing_facilities,-extreme_poverty)%>%
  dplyr::select(-male_smokers, -female_smokers, -gci_2018_rank, -year_hosp_beds_per_1000, -hosp_beds_per_1000,
  -qualification, -eiu_2019_rank, -eiu_2019_overall_score, -hospital_beds_per_thousand, 
  -decade_temp, -decade_prec, -aged_65_older, -cpi_score_2019)%>%
assign("every_30_days_dataset",.,envir=.GlobalEnv)
  #assign("monthly_dataset",.,envir=.GlobalEnv)
```

<br>

We analyzed the variables with missing data. **We must determine the tolerable number of missing values**. If not, we may ignore that variable.

<br>

```{r miss_by_cntry2_col, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
col_names_df<-every_30_days_dataset%>% #monthly_dataset%>%
    dplyr::select(population:ncol(.))%>% 
    names()

#monthly_dataset%>%
every_30_days_dataset%>%
    dplyr::group_by(country) %>% 
    dplyr::summarise_at(vars(population:(ncol(.)-1)),~sum(is.na(.))/n())%>%
    dplyr::mutate(sumVar = rowSums(dplyr::select(., .dots = all_of(col_names_df))))%>%
    summarise_at(vars(population:(ncol(.)-1)),~sum(as.numeric(.)))%>% t()%>% data.frame()%>%
  dplyr::arrange(desc(.))%>%
  # knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
  #              caption = paste0("Table 46. Variables with no. of countries with missing data"),
  #              align =rep('c', 101)) %>%
  # kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  # kableExtra::add_footnote(c(paste("Note. ",nrow(every_30_days_dataset),"observations")), 
  #                           notation = "none") %>%
  # kableExtra::scroll_box(width = "100%", height = "375px")
datatable(filter = 'top', colnames = c('Variable' =1,'Missingness' = 2),#, 'Number of missing'= 3
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 48: ', htmltools::em('Variables with no. of countries with missing data')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))


```

```{r miss_scenarios, echo=T, cache= T, paged.print=TRUE,eval=F, warning=F, error=T}
#monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
every_30_days_dataset[,!(names(every_30_days_dataset) %in% drops)]%>%
  na.omit()%>%
    dplyr::distinct(iso_code)%>%
    nrow()
df<-data.frame(n=0)
for_imp<- c("aged_70_older", "gdp_per_capita", "year_life_exp", "life_exp", "life_exp_15_20",
"median_age", "year_air_pollution_year_pm25", "air_pollution_year_pm25", "dalys_lung_disease", "hdi_rank_2018",
"hdi_index_2018", "year_pop_density", "pop_density", "lower_respiratory_infections_deaths", "respiratory_diseases_deaths", "diabetes_deaths","obesity_both_percent","population_density","diabetes_prevalence",
"month_temp_16","month_rainfall_mm_16","year_total_pop","total_pop","owid_gbd_year","dalys_asthma_normalized","monthly_temp","monthly_prec","life_expectancy","population","TemperatureAvg")

for (i in 1:length(for_imp)){
  drops <- c(c("ndays", "cases_deaths","cases"),for_imp[i])
monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
  na.omit()%>%
    dplyr::distinct(iso_code)%>%
    nrow()->df2
df<-rbind(df,df2)
}
df<-df[2:length(for_imp),]
data.frame(cbind(for_imp,df))%>% arrange(desc(df))
data.frame(cbind(for_imp,df))%>% arrange(desc(df))

invisible(
    monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
          na.omit()%>%
          dplyr::distinct(iso_code)%>%
          nrow()
)
```

<br>

Posteriorly, we observed those countries that had at missing data in the variables selected. These countries would end up being deleted (Table 45).

<br>

```{r miss_by_cntry2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
#col_names_df<-monthly_dataset%>%
col_names_df<-every_30_days_dataset%>%
    dplyr::select(population:(ncol(.)))%>% 
    names()

paste("One variable that has many missing values:",
every_30_days_dataset%>%
      #monthly_dataset%>%
    dplyr::group_by(country) %>% 
    summarise_at(vars(population:(ncol(.)-1)),~sum(is.na(.))/n())%>%
    dplyr::mutate(sumVar = rowSums(dplyr::select(., .dots = all_of(col_names_df))))%>%
    summarise_at(vars(population:TemperatureAvg),~sum(as.numeric(.)))%>% t()%>% data.frame()%>%
  dplyr::filter(.>=20)%>% data.table(keep.rownames = T) %>%  toString( ),
"%")
#monthly_dataset%>%
every_30_days_dataset%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:(ncol(.)-1)),~sum(is.na(.))/n())%>%
      dplyr::mutate(sumVar = rowSums(dplyr::select(., .dots = all_of(col_names_df))))%>%
      dplyr::mutate_at(vars(population:(ncol(.)-1)),~scales::percent(.))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
  #assign("monthly_dataset_miss",.,envir=.GlobalEnv)%>%
  assign("very_30_days_dataset_miss",.,envir=.GlobalEnv)%>%  
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 49. Percentage of Missing data in the Different Time Points By Country (monthly Data)"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote(c(paste("Note. ",nrow(every_30_days_dataset),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")

#excluded_countries<-as.character(unlist(distinct(monthly_dataset_miss,country)))
excluded_countries<-as.character(unlist(distinct(very_30_days_dataset_miss,country)))

#monthly_dataset%>%
every_30_days_dataset%>%
  #dplyr::filter(!country %in% excluded_countries)%>%
  dplyr::mutate(rate_lo_resp_inf_dth=lower_respiratory_infections_deaths/100000)%>%
  dplyr::mutate(prop_lo_resp_inf_dth=lower_respiratory_infections_deaths/population)%>%
  dplyr::mutate(life_exp_15_20=as.numeric(life_exp_15_20))%>%
  ungroup()%>%
  #assign("monthly_dataset_comp_wise",.,envir=.GlobalEnv)
  assign("every_30_days_dataset_comp_wise",.,envir=.GlobalEnv)
#105 paises.
#gci_2018_rank	year_hosp_beds_per_1000	hosp_beds_per_1000
```

<br>

```{r miss_by_cntry_final_prueba, echo=T, cache= T, paged.print=TRUE,eval=F, warning=F, error=T}
 invisible("Países que tienen valores perdidos")
copiar_nombres(data.frame(sort(excluded_countries)))


invisible("Casos que no tienen valores perdidos")
drops2 <- c(c("ndays", "cases_deaths","cases"))
 #monthly_dataset_comp_wise[,!(names(monthly_dataset_comp_wise) %in% drops2)]%>%
  every_30_days_dataset_comp_wise[,!(names(every_30_days_dataset_comp_wise) %in% drops2)]%>%
   na.omit()%>%
    dplyr::distinct(country) %>%  #iso_code
  copiar_nombres()
```

<br>

Considering the Table above, we decided to eliminate `r nrow(distinct(very_30_days_dataset_miss,country))` countries in the dataset that had missing values on variables of interest. This let us with `r nrow(distinct(every_30_days_dataset_comp_wise,country))` countries.

<br>

## Hetcors

We generated a matrix of heterogeneous correlations, to get an idea of the collinearity of variables.

<br>

```{r hetcor, echo=T, cache= T, paged.print=TRUE, eval=T, error=T, fig.cap="Figure 6.Heterogeneous Correlation Matrix"}
require(polycor)

#monthly_dataset_comp_wise_dt<-monthly_dataset_comp_wise%>% dplyr::select_if(is.numeric)%>% dplyr::select(-stringency_ind_oxf,-owid_gbd_year)%>% dplyr::select(-ends_with("mth")) %>% data.frame()

every_30_days_dataset_comp_wise_dt<-every_30_days_dataset_comp_wise%>% dplyr::select_if(is.numeric)%>% dplyr::select(-owid_gbd_year)%>% dplyr::select(-ends_with("mth")) %>% dplyr::select(-mnth,-who_tot_deaths_year,-year_death_rate_crude,-year_total_pop,-year_pop_density,-year_air_pollution_year_pm25,-year_life_exp)%>% data.frame()


#Computes a heterogenous correlation matrix, consisting of Pearson product-moment correlations between numeric variables, polyserial correlations between numeric and ordinal variables, and polychoric correlations between 
hetcor_mat<-hetcor(every_30_days_dataset_comp_wise_dt, ML = T, std.err = T, use="complete.obs", bins=4, pd=TRUE)

#mix_cor<- psych::mixedCor(data=monthly_dataset_comp_wise_dt,
          #c=2:20, 
         #p=1, 
         #d=21:27, c(")
#         smooth=TRUE,
#         correct=.5,
#         global=TRUE,
#         ncat=8,
#         use="pairwise",
#         method="kendall",
#         weight=NULL)

# Getting the correlation matrix of the dataset.
# mix_cor$rho

ggcorrplot::ggcorrplot(hetcor_mat$correlations,
          ggtheme = ggplot2::theme_gray,
          colors = c("#E46726", "white", "#6D9EC1"), tl.cex=7) 
#owid_covid_data
#iso_code
#location

#land_area_skm
```

<br>

Finally, we transformed the dataset into a wide format, with the dates 1, 30, 60, and 90. China had missing data in dates in the day 1 and 30, while Solomon Islands had missing information in the days 30, 60 and 90. For China, we replaced the values at day 30 (2019-12-31), with data from WHO (total cases= 27, total deaths=0).

<br>


```{r codebook_prep, echo=T, cache=T, paged.print=TRUE,eval=T, warning=F}
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#
######3.0.Libro de códigos#####
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#
#iso_code [152]
#every_30_days_dataset_comp_wise
#monthly_dataset_comp_wise
codebook_data<-every_30_days_dataset_comp_wise%>%
  data.frame(stringsAsFactors = FALSE)%>%
  #dplyr::mutate(ndays_rn=dplyr::case_when(ndays==1~1,ndays==30~2,ndays==60~3,ndays==90~4,TRUE~NA_real_))%>%
  dplyr::mutate(month_temp_16_2=month_temp_16,
                month_rainfall_mm_16_2=month_rainfall_mm_16,
                month_temp_07_2=month_temp_07,
                month_rainfall_mm_07_2=month_rainfall_mm_07)%>%
                dplyr::rename("low_resp_inf_dths"="lower_respiratory_infections_deaths")%>%
                tidyr::pivot_wider(names_from = ndays, #ndays_rn
                                   names_sep="_",
                                   values_from = c(dates, date_month, cases, cases_deaths, ndays_zero, stringency_ind_oxf, monthly_temp, monthly_prec,month_temp_07, month_rainfall_mm_07,
month_temp_16, month_rainfall_mm_16,month_temp_agg97_06,month_temp_agg07_16,month_rain_agg97_06,month_rain_agg07_16, TemperatureAvg))%>% 
  tidyr::unnest()%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate_at(vars(dates_1:last_col()),~max(.,na.rm=T))%>% #(ncol(.)-1)
  #dplyr::mutate_at(vars(date_month_1 :date_month_90),~max(.,na.rm=T))%>%
  dplyr::slice(1)%>%
  #C:\Users\CISS Fondecyt\Dropbox\Covid-19_2020\Article_SecondManuscript\LT Environmental analysis\Databases\2020-08-04 Revision on China0s missing values.docx
  dplyr::mutate(cases_1=ifelse(iso_code=="CHN",1,cases_1), #no estoy seguro, nadie lo está, pero bueno.
                cases_30=ifelse(iso_code=="CHN",27,cases_30))%>%
  dplyr::mutate(cases_deaths_1=ifelse(iso_code=="CHN",0,cases_deaths_1), #no estoy seguro, nadie lo está, pero bueno.
                cases_deaths_30= ifelse(iso_code=="CHN",0,cases_deaths_30))%>%
  dplyr::mutate(dates_1=ifelse(iso_code=="CHN",as.Date("2019-12-01"),dates_1),
                dates_30= ifelse(iso_code=="CHN",as.Date("2019-12-30"),dates_30))%>%
  dplyr::mutate(date_month_1=ifelse(iso_code=="CHN","nov",date_month_1),
                date_month_30= ifelse(iso_code=="CHN","dec",date_month_30))%>%
  dplyr::mutate(ndays_zero_1=ifelse(iso_code=="CHN",1,ndays_zero_1),
                ndays_zero_30= ifelse(iso_code=="CHN",30,ndays_zero_30))%>%
  dplyr::mutate(monthly_temp_1=ifelse(iso_code=="CHN",dplyr::filter(global_hist_temp_month ,locator=="CHN",date_month=="nov")$data,monthly_temp_1),
                monthly_temp_30= ifelse(iso_code=="CHN",dplyr::filter(global_hist_temp_month ,locator=="CHN",date_month=="dec")$data,monthly_temp_30))%>%
  dplyr::mutate(monthly_prec_1=ifelse(iso_code=="CHN",dplyr::filter(global_hist_prec_month ,locator=="CHN",date_month=="nov")$data,monthly_prec_1),
                monthly_prec_30= ifelse(iso_code=="CHN",dplyr::filter(global_hist_prec_month ,locator=="CHN",date_month=="dec")$data,monthly_prec_30))%>%
  
  #dplyr::mutate(stringency_ind_oxf_1=ifelse(iso_code=="CHN",16.94781,stringency_ind_oxf_1), #NO ES POSIBLE PORQUE NO HAY DATOS
  #              stringency_ind_oxf_30= ifelse(iso_code=="CHN",9.502951,stringency_ind_oxf_30))%>%

  dplyr::mutate(month_temp_07_1=ifelse(iso_code=="CHN",as.numeric(temp07[which(temp07$iso3=="CHN" & temp07$date_month=="nov"),names(temp07)[5]]),
                                       month_temp_07_1),
                month_temp_07_30= ifelse(iso_code=="CHN",as.numeric(temp07[which(temp07$iso3=="CHN" & temp07$date_month=="dec"),names(temp07)[5]]),
                                         month_temp_07_30))%>%
  dplyr::mutate(month_rainfall_mm_07_1=ifelse(iso_code=="CHN",as.numeric(rain07[which(rain07$iso3=="CHN" & rain07$date_month=="nov"),names(rain07)[5]]),
                                              month_rainfall_mm_07_1),
                month_rainfall_mm_07_30= ifelse(iso_code=="CHN",as.numeric(rain07[which(rain07$iso3=="CHN" & rain07$date_month=="dec"),names(rain07)[5]]),
                                              month_rainfall_mm_07_30))%>%
  dplyr::mutate(month_temp_16_1= ifelse(iso_code=="CHN",as.numeric(temp[which(temp$iso3=="CHN" & temp$date_month=="nov"),names(temp)[5]]),
                                        month_temp_16_1),
                month_temp_16_30= ifelse(iso_code=="CHN",as.numeric(temp[which(temp$iso3=="CHN" & temp$date_month=="dec"),names(temp)[5]]),
                                         month_temp_16_30))%>%  
  dplyr::mutate(month_rainfall_mm_16_1= ifelse(iso_code=="CHN",as.numeric(rain[which(rain$iso3=="CHN" & rain$date_month=="nov"),names(rain)[5]]),
                                        month_rainfall_mm_16_1),
                month_rainfall_mm_16_30= ifelse(iso_code=="CHN",as.numeric(rain[which(rain$iso3=="CHN" & rain$date_month=="dec"),names(rain)[5]]),
                                         month_rainfall_mm_16_30))%>%  
  dplyr::mutate(month_temp_agg97_06_1=ifelse(iso_code=="CHN",month_temp_agg97_06_60,month_temp_agg97_06_1),
                month_temp_agg97_06_30= ifelse(iso_code=="CHN",month_temp_agg97_06_60,month_temp_agg97_06_30))%>%
  dplyr::mutate(month_temp_agg07_16_1=ifelse(iso_code=="CHN",month_temp_agg07_16_60,month_temp_agg07_16_1),
                month_temp_agg07_16_30= ifelse(iso_code=="CHN",month_temp_agg07_16_60,month_temp_agg07_16_30))%>%
  dplyr::mutate(month_rain_agg97_06_1=ifelse(iso_code=="CHN",month_rain_agg97_06_60,month_rain_agg97_06_1),
                month_rain_agg97_06_30= ifelse(iso_code=="CHN",month_rain_agg97_06_60,month_rain_agg97_06_30))%>%
  dplyr::mutate(month_rain_agg07_16_1=ifelse(iso_code=="CHN",month_rain_agg07_16_60,month_rain_agg07_16_1),
                month_rain_agg07_16_30= ifelse(iso_code=="CHN",month_rain_agg07_16_60,month_rain_agg07_16_30))%>%
  dplyr::mutate(TemperatureAvg_1=ifelse(iso_code=="CHN",as.numeric(temp_dt_cons[which(temp_dt_cons$CountryCode=="CHN" & temp_dt_cons$Month==11),"TemperatureAvg"]),TemperatureAvg_1),
                TemperatureAvg_30= ifelse(iso_code=="CHN",as.numeric(temp_dt_cons[which(temp_dt_cons$CountryCode=="CHN" & temp_dt_cons$Month==12),"TemperatureAvg"]),TemperatureAvg_30))%>%
  ungroup()%>%
  dplyr::mutate(month_temp_16=month_temp_16_2,month_rainfall_mm_16=month_rainfall_mm_16_2,month_temp_07=month_temp_07_2,month_rainfall_mm_07=month_rainfall_mm_07_2)%>%
  dplyr::select(-month_temp_16_2, -month_rainfall_mm_16_2, -month_temp_07_2,-month_rainfall_mm_07_2)

#codebook_data%>% dplyr::select(monthly_temp_1,monthly_temp_30,monthly_prec_1,monthly_prec_30,month_temp_16_1,month_temp_16_30,month_rainfall_mm_16_1,month_rainfall_mm_16_30)%>% summary()
#codebook_data%>% dplyr::select(monthly_temp_1,monthly_temp_30,monthly_prec_1,monthly_prec_30,month_temp_16_1,month_temp_16_30,month_rainfall_mm_16_1,month_rainfall_mm_16_30)%>% View()
#dplyr::filter(iso3=="CHN"

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:  
colnames(codebook_data)[colSums(is.na(codebook_data)) > 0] #para ver datos perdidos
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:

codebook::metadata(codebook_data)$name <- "Join of Datasets for COVID"
codebook::metadata(codebook_data)$description <- "Owid data is available here (https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data-codebook.md); The reported weather station refers to the nearest station which provides temperature measurements, but rainfall and snowfall may come from a different nearby weather station. In all cases, only weather stations which are at most 300km from the location coordinates are considered; AverageTmp comes from ERA5 data"

codebook::var_label(codebook_data) <- list(
  country = 'Country Name (OWID)',
  iso_code = '3-letter-ISO Code (OWID)',
  
  #dates = 'Date (Date format) (JHU)',
  #date_month = '3-char Month of Date (Character) (JHU)',
  #cases = 'No. of Confirmed Cases (JHU)',
  #cases_deaths = 'No. of Confirmed Deaths (JHU)',
  
  #ndays = 'Days since the first Confirmed Case by Country (JHU)',
  #ndays_zero = 'Days since the first Confirmed Case (JHU)',
  text = 'Summary of Information Regarding Cases and ID of the Country',
  
  continent = 'Continent of the Country (OWID)',
  population = 'Total Pop. (GAPMINDER, HYDE & UN by OWID)',
  population_density = 'No. people/land area, in km2 (2017) (WB in OWID)',
  median_age = 'Median age of the population, UN projection for 2020 from 2017 (UN in OWID)',
  #aged_65_older = 'Share of the population that is >=65 yrs, most recent year available (WB Dev Ind in OWID)',
  aged_70_older = 'Share of the population that is >=65 yrs, most recent year in 2015 (WB Dev Ind in OWID)',
  gdp_per_capita = 'Gross domestic product at purchasing power parity (constant 2011 international dollars), most recent year available (WB Dev Ind)',
  #extreme_poverty = 'Share of the population living in extreme poverty, most recent year available since 2010 (WB Dev Ind in OWID)',
  #cvd_death_rate = 'Death rate from cardiovascular disease in 2017 (GBD 2017 in OWID)',
  diabetes_prevalence = 'Diabetes prevalence (% of population aged 20 to 79) in 2017 (WB Dev Ind in OWID)',
  #female_smokers = 'Share of women who smoke, most recent year available	(WB Dev Ind in OWID)',
  #male_smokers = 'Share of men who smoke, most recent year available (WB Dev Ind in OWID)',
  #handwashing_facilities = 'Share of the population with basic handwashing facilities on premises, most recent year available	(UN Statistics in OWID)',
  #hospital_beds_per_thousand = 'Hospital beds per 1,000 people, most recent year available since 2010 (OECD, WB, Eurostat in OWID)',
  life_expectancy = 'Life expectancy at birth in 2019 (UN in OWID)',
  
  #stringency_ind_oxf = 'Government Response Stringency Index (OXF)',
  
  #monthly_temp = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 (rWBclimate)',
  #monthly_prec = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 (rWBclimate)',
  #decade_temp = 'Decadanal avg. temperature (celsius) at 2010 (rWBclimate)',
  #decade_prec = 'Decadanal avg. precipitation (mm) at 2010 (rWBclimate)',
  
  #month_temp_16 = 'Avg. Monthly Temperature (celsius) in 2016 (CCKP)',
  #month_rainfall_mm_16 = 'Avg. Monthly Rain (Millimiters) in 2016 (CCKP)', 
  
  #noaa_station = "Identifier for the weather station (NOAA)",
  ##noaa_distance = "Distance between the location coordinates and the weather station	(NOAA)",
  #average_temperature = "Recorded hourly average temperature	(NOAA)",
  #minimum_temperature = "Recorded hourly minimum temperature	(NOAA)",
  #maximum_temperature = "Recorded hourly maximum temperature	(NOAA)",
  #rainfall = "Rainfall during the entire day	(NOAA)",
  
  #cpi_score_2019 =  "Corruption Perceptions Index (0-100) (Transparency Int)",
  
  hdi_rank_2018 =  "Human Development Ranking 2018 (UN)",
  hdi_index_2018 =  "Human Development Index 2018 (0-100) (UN)",
  
  #gci_2018_rank = 'Good Country Index Ranking in 2018 (GCI)',
    
  #qualification = 'Classification Provided in 2019 (EIU)',
  #eiu_2019_rank = 'Democracy Index Ranking in 2019 (EIU)',
  #eiu_2019_overall_score = 'Overall Score in 2019 (EIU)',
  
  year_total_pop = 'Year of the available Population Number (WB)',
  total_pop = 'Population Number (WB)',
  year_pop_density = 'Year of the available Population Density (WB)',
  pop_density = 'Population Number (WB)',
  #year_physicians_per_1000 = 'Year of the available number of Physicians (per 1,000 people) (WB)',
  #physicians_per_1000 = 'Physicians (per 1,000 people) (WB)',
  #year_hosp_beds_per_1000 = 'Year of the available number of Hospital beds (per 1,000 people) (WB)',
  #hosp_beds_per_1000 = 'Hospital beds (per 1,000 people) (WB)',
  year_air_pollution_year_pm25 = 'Year of available Air pollution, mean annual exposure (mm per m^3) for GBD17 (WB)',
  air_pollution_year_pm25 = 'Air pollution, mean annual exposure (mm per m^3) for GBD17 (WB)',
  year_life_exp = 'Year of the available number of Life expectancy at birth (WB)',
  life_exp = 'Life expectancy at birth (WB)',
  
  death_rate_crude =  'Death rate, crude (per 1,000 people) (WB)',
  year_death_rate_crude = 'Year of the Death rate, crude (per 1,000 people) (WB)',
  
  dalys_asthma_normalized = 'YLLs to premature death and disabillity due to asthma (GBD in COVID19 spreadsheet)',
  dalys_lung_disease = 'YLLs to premature death and disabillity due to lung disease (GBD in COVID19 spreadsheet)',
  obesity_both_percent =  'Percentage of Obesity for Both Sexes (GBD in COVID19 spreadsheet)',
  who_tot_deaths_year = 'Year of the available Data of WHO All-cause mortality',
  tot_deaths = 'All-cause mortality, Last available with more data by cntry (WHO)',
  owid_gbd_year = 'Year of the available Data of Global Burden of Disease (GBD in OWID)',
  low_resp_inf_dths = 'Deaths due to Lower Respiratory Infections (GBD in OWID)',
  respiratory_diseases_deaths = 'Deaths due to Respiratory Diseases (GBD in OWID)',
  diabetes_deaths = 'Deaths due to Diabetes (GBD in OWID)',
  life_exp_15_20 = 'Estimated Life expectancy at age 60 (2015-2020) (WHO)',

  rate_lo_resp_inf_dth = 'Deaths due to Lower Respiratory Infections per 100M (GBD in OWID)',
  prop_lo_resp_inf_dth = 'Prop. of Deaths due to Lower Respiratory Infections of the Total Pop (GBD in OWID)',
  
  
  #2021-10-10
  dalys_all_ages_rate = 'DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: All Ages (Rate)',
  dalys_std_age_rate = 'DALYs (Disability-Adjusted Life Years) - All causes - Sex: Both - Age: Age-standardized (Rate)',
  
  #2021-09-19
  mnth='Month in numeric format (ERA5)',
  yr='Year in numeric format (ERA5)',
  TemperatureAvg_1='Avg. Monthly Temperature (celsius) in 2020 (ERA5) at 0 day(s) since first case',
  TemperatureAvg_30='Avg. Monthly Temperature (celsius) in 2020 (ERA5) at 30 day(s) since first case',
  TemperatureAvg_60='Avg. Monthly Temperature (celsius) in 2020 (ERA5) at 60 day(s) since first case',
  TemperatureAvg_90='Avg. Monthly Temperature (celsius) in 2020 (ERA5) at 90 day(s) since first case',
  TemperatureAvg_120='Avg. Monthly Temperature (celsius) in 2020 (ERA5) at 120 day(s) since first case',
  
  month_temp_16 = 'Avg. Monthly Temperature (celsius) in 2016 (CCKP)',
  month_rainfall_mm_16 =  'Avg. Monthly Rain (Millimiters) in 2016 (CCKP)', 
  month_temp_07 = 'Avg. Monthly Temperature (celsius) in 2007 (CCKP)',
  month_rainfall_mm_07 =  'Avg. Monthly Rain (Millimiters) in 2007 (CCKP)', 
  
  month_temp_16_m = 'Avg. Yearly Temperature (celsius) in 2016 (CCKP)',
  month_rainfall_mm_16_m =  'Avg. Yearly Rain (Millimiters) in 2016 (CCKP)', 
  month_temp_07_m = 'Avg. Yearly  Temperature (celsius) in 2007 (CCKP)',
  month_rainfall_mm_07_m =  'Avg. Yearly Rain (Millimiters) in 2007 (CCKP)', 
  
  #cases_deaths_mth = 'Max. no. of Confirmed Cases in the Month (JHU)',
  #cases_mth = 'Max. no. of Confirmed Deaths in the Month(JHU)',
  #ndays_zero_mth = 'Max. no. of days since the first Confirmed Case (JHU)',
  #ndays_mth = 'Max no. of days since the first Confirmed Case by Country (JHU)',

  #stringency_ind_oxf_mth = 'Government Response Stringency Index in the Month (OXF)'
  dates_1 = 'Date (Date format) at 0 day(s) since first case (JHU)',
  date_month_1 = '3-char Month of Date (Character) at 0 day(s) since first case (JHU)',
  cases_1 = 'No. of Confirmed Deaths at 0 day(s) since first case (JHU)',
  cases_deaths_1 = 'No. of Confirmed Deaths at 0 day(s) since first case (JHU)',
  ndays_zero_1 = 'No. of Days since the first case worldwide at 0 day(s) since first case',
  stringency_ind_oxf_1 = 'Government Response Stringency Index at 0 day(s) since first case (OXF)',
  monthly_temp_1 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 0 day(s) since first case (rWBclimate)',
  monthly_prec_1 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 0 day(s) since first case (rWBclimate)',
  month_temp_16_1 = 'Avg. Monthly Temperature (celsius) in 2016 at 0 day(s) since first case (CCKP)',
  month_rainfall_mm_16_1 =  'Avg. Monthly Rain (Millimiters) in 2016 at 0 day(s) since first case (CCKP)', 
  month_temp_07_1 = 'Avg. Monthly Temperature (celsius) in 2007 at 0 day(s) since first case (CCKP)',
  month_rainfall_mm_07_1 =  'Avg. Monthly Rain (Millimiters) in 2007 at 0 day(s) since first case (CCKP)', 
  #dates = 'Date (Date format) (JHU)',
  #date_month = '3-char Month of Date (Character) (JHU)',
  #cases = 'No. of Confirmed Cases (JHU)',
  #cases_deaths = 'No. of Confirmed Deaths (JHU)',
    dates_30 = 'Date (Date format) at 30 day(s) since first case (JHU)',
  date_month_30 = '3-char Month of Date (Character) at 30 day(s) since first case (JHU)',
  cases_30 = 'No. of Confirmed Deaths at 30 day(s) since first case (JHU)',
  cases_deaths_30 = 'No. of Confirmed Deaths at 30 day(s) since first case (JHU)',
  ndays_zero_30 = 'No. of Days since the first case worldwide at 30 day(s) since first case',
  stringency_ind_oxf_30 = 'Government Response Stringency Index at 30 day(s) since first case (OXF)',
  monthly_temp_30 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 30 day(s) since first case (rWBclimate)',
  monthly_prec_30 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 30 day(s) since first case (rWBclimate)',
  month_temp_16_30 = 'Avg. Monthly Temperature (celsius) in 2016 at 30 day(s) since first case (CCKP)',
  month_rainfall_mm_16_30 =  'Avg. Monthly Rain (Millimiters) in 2016 at 30 day(s) since first case (CCKP)',
  month_temp_07_30 = 'Avg. Monthly Temperature (celsius) in 2007 at 30 day(s) since first case (CCKP)',
  month_rainfall_mm_07_30 =  'Avg. Monthly Rain (Millimiters) in 2007 at 30 day(s) since first case (CCKP)', 
  
  dates_60 = 'Date (Date format) at 60 day(s) since first case (JHU)',
  date_month_60 = '3-char Month of Date (Character) at 60 day(s) since first case (JHU)',
  cases_60 = 'No. of Confirmed Deaths at 60 day(s) since first case (JHU)',
  cases_deaths_60 = 'No. of Confirmed Deaths at 60 day(s) since first case (JHU)',
  ndays_zero_60 = 'No. of Days since the first case worldwide at 60 day(s) since first case',
  stringency_ind_oxf_60 = 'Government Response Stringency Index at 60 day(s) since first case (OXF)',
  monthly_temp_60 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 60 day(s) since first case (rWBclimate)',
  monthly_prec_60 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 60 day(s) since first case (rWBclimate)',
  month_temp_16_60 = 'Avg. Monthly Temperature (celsius) in 2016 at 60 day(s) since first case (CCKP)',
  month_rainfall_mm_16_60 =  'Avg. Monthly Rain (Millimiters) in 2016 at 60 day(s) since first case (CCKP)', 
  month_temp_07_60 = 'Avg. Monthly Temperature (celsius) in 2007 at 60 day(s) since first case (CCKP)',
  month_rainfall_mm_07_60 =  'Avg. Monthly Rain (Millimiters) in 2007 at 60 day(s) since first case (CCKP)', 
  
  jan = 'Avg. Monthly Temperature (celsius) in 2016, January',
  feb = 'Avg. Monthly Temperature (celsius) in 2016, February',
  mar = 'Avg. Monthly Temperature (celsius) in 2016, March',
  apr = 'Avg. Monthly Temperature (celsius) in 2016, April',
  may = 'Avg. Monthly Temperature (celsius) in 2016, May',
  # 2021-09-19
  jun = 'Avg. Monthly Temperature (celsius) in 2016, June',
  jul = 'Avg. Monthly Temperature (celsius) in 2016, July',
  aug = 'Avg. Monthly Temperature (celsius) in 2016, August',
  sep = 'Avg. Monthly Temperature (celsius) in 2016, September',
  oct = 'Avg. Monthly Temperature (celsius) in 2016, October',
  nov = 'Avg. Monthly Temperature (celsius) in 2016, November',
  dec = 'Avg. Monthly Temperature (celsius) in 2016, December',
  
    dates_90 = 'Date (Date format) at 90 day(s) since first case (JHU)',
  date_month_90 = '3-char Month of Date (Character) at 90 day(s) since first case (JHU)',
  cases_90 = 'No. of Confirmed Deaths at 90 day(s) since first case (JHU)',
  cases_deaths_90 = 'No. of Confirmed Deaths at 90 day(s) since first case (JHU)',
  ndays_zero_90 = 'No. of Days since the first case worldwide at 90 day(s) since first case',
  stringency_ind_oxf_90 = 'Government Response Stringency Index at 90 day(s) since first case (OXF)',
  monthly_temp_90 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 90 day(s) since first case (rWBclimate)',
  monthly_prec_90 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 90 day(s) since first case (rWBclimate)',
  month_temp_16_90 = 'Avg. Monthly Temperature (celsius) in 2016 at 90 day(s) since first case (CCKP)',
  month_rainfall_mm_16_90 =  'Avg. Monthly Rain (Millimiters) in 2016 at 90 day(s) since first case (CCKP)',
  month_temp_07_90 = 'Avg. Monthly Temperature (celsius) in 2007 at 90 day(s) since first case (CCKP)',
  month_rainfall_mm_07_90 =  'Avg. Monthly Rain (Millimiters) in 2007 at 90 day(s) since first case (CCKP)',
  
  dates_120 = 'Date (Date format) at 120 day(s) since first case (JHU)',
  date_month_120 = '3-char Month of Date (Character) at 120 day(s) since first case (JHU)',
  cases_120 = 'No. of Confirmed Deaths at 120 day(s) since first case (JHU)',
  cases_deaths_120 = 'No. of Confirmed Deaths at 120 day(s) since first case (JHU)',
  ndays_zero_120 = 'No. of Days since the first case worldwide at 120 day(s) since first case',
  stringency_ind_oxf_120 = 'Government Response Stringency Index at 120 day(s) since first case (OXF)',
  monthly_temp_120 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 120 day(s) since first case (rWBclimate)',
  monthly_prec_120 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 120 day(s) since first case (rWBclimate)',
  month_temp_16_120 = 'Avg. Monthly Temperature (celsius) in 2016 at 120 day(s) since first case (CCKP)',
  month_rainfall_mm_16_120 =  'Avg. Monthly Rain (Millimiters) in 2016 at 120 day(s) since first case (CCKP)',
  month_temp_07_120 = 'Avg. Monthly Temperature (celsius) in 2007 at 120 day(s) since first case (CCKP)',
  month_rainfall_mm_07_120 =  'Avg. Monthly Rain (Millimiters) in 2007 at 120 day(s) since first case (CCKP)',
  
  month_rain_agg97_06_1 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 0 day(s) since first case (CCKP)',
  month_rain_agg97_06_30 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 30 day(s) since first case (CCKP)',
  month_rain_agg97_06_60 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 60 day(s) since first case (CCKP)',
  month_rain_agg97_06_90 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 90 day(s) since first case (CCKP)',
  month_rain_agg97_06_120 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 120 day(s) since first case (CCKP)',

  month_temp_agg07_16_1 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 0 day(s) since first case (CCKP)',
  month_temp_agg07_16_30 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 30 day(s) since first case (CCKP)',
  month_temp_agg07_16_60 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 60 day(s) since first case (CCKP)',
  month_temp_agg07_16_90 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 90 day(s) since first case (CCKP)',
  month_temp_agg07_16_120 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 120 day(s) since first case (CCKP)',
  
  month_temp_agg97_06_1 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 0 day(s) since first case (CCKP)',
  month_temp_agg97_06_30 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 30 day(s) since first case (CCKP)',
  month_temp_agg97_06_60 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 60 day(s) since first case (CCKP)',
  month_temp_agg97_06_90 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 90 day(s) since first case (CCKP)',
  month_temp_agg97_06_120 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 120 day(s) since first case (CCKP)',

  month_rain_agg07_16_1 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 0 day(s) since first case (CCKP)',
  month_rain_agg07_16_30 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 30 day(s) since first case (CCKP)',
  month_rain_agg07_16_60 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 60 day(s) since first case (CCKP)',
  month_rain_agg07_16_90 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 90 day(s) since first case (CCKP)',
  month_rain_agg07_16_120 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 120 day(s) since first case (CCKP)'
)

codebook_data<-codebook_data%>%
  dplyr::mutate(dates_1=as.Date(dates_1))%>%
  dplyr::mutate(dates_30=as.Date(dates_30))
                  
  
df_def<-
data.frame(cbind(var_name= names(codebook_data),var_def=data.table(codebook::var_label(codebook_data), keep.rownames = T), type=data.table(sapply(codebook_data, class)),can_be_na=data.table(rep(FALSE,length(names(codebook_data))))))%>%
  dplyr::rename("var_def"="var_def.V1","type"="type.V1","can_be_na"="can_be_na.V1")


#World Bank Climate Data, Aggregated Decennial. decennial average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal, by getting the average number of the available monthly data by country: one from 1997-2006, and other from 2017-2016
```


```{r worldmap, echo=T, eval=T, fig.align='center', fig.pos='H', message=FALSE, warning=FALSE,interval=1, fig.cap="Figure 7.Worlwide View of the Number of Deaths since each country's first diagnosed", error=T}
library(cshapes)      # for historic country boundaries.  Load this early as it calls plyr which clashes with dplyr
library(ggplot2)
library(scales)
library(RColorBrewer) # for brewer.pal(...)
library(openxlsx)
library(countrycode)  # for ISO country codes
library(ggthemes)     # for theme_map
library(dplyr)
library(tidyr)        # for reshaping the UTIP EHII data

      # thanks to cshapes project for historical countries: http://nils.weidmann.ws/projects/cshapes.html
      
      world2 <- cshp()      
      
      codebook_data_long<- codebook_data%>% pivot_longer(cols =starts_with("cases_deaths"),names_to = "days",values_to="cases_deaths")%>%
        dplyr::mutate(days=case_when(days=="cases_deaths_1"~1,
                                  days=="cases_deaths_30"~30,
                                  days=="cases_deaths_60"~60,
                                  days=="cases_deaths_90"~90,
                                  days=="cases_deaths_120"~120,
                                  TRUE~NA_real_))%>%
                dplyr::select(iso_code,country,cases_deaths,days)

      
      # convert the shapefile into a data frame for use with ggplot2,
      # and join it to the ISO3 country codes for later use:
      world_map <- fortify(ne_countries(scale = "medium", returnclass = "sf"))
      # filter the data to those five years and take the average
      # of any years of data we have for each country in those 
      # years:
    #   the_data <- monthly_dataset_comp_wise %>%
    #     group_by(iso3c) %>%
    #     dplyr::summarise(Gini = mean(Gini, na.rm = TRUE)) %>%
    #     filter(!is.na(Gini))
      
      # these next messages and printing are checks to see which  monthly_dataset_comp_wise
      # if any countries we are missing out on drawing due to
      # data mismatches:
      #all_gini_countries <- unique(monthly_dataset_comp_wise$iso_code)
      all_gini_countries <- unique(codebook_data_long$iso_code)
      all_map_countries <- unique(world_map$adm0_a3_is)
      
      missed1 <- sum(!all_map_countries %in% all_gini_countries)
      missed2 <- sum(!all_gini_countries %in% all_map_countries)
      message(paste(missed1, "countries in map but no Gini", i))
      message(paste(missed2, "countries have a Gini but no map in ", i))
      message(paste(missed3, "countries have no iso3c code in", i))
      
      # print the countries that had data which wasn't mapped
      print(all_gini_countries[!all_gini_countries %in% all_map_countries])
      
      # Puerto Rico, Macau and Hong Kong often are missing from the map
      # DDR has data 1970 to 1988 and won't be shown
      # ERI has data from 1963 despite not really being a country until 1993
      #     If we use 1995 maps it will show up but we have to drop DDR.
      # PNG has data pre its independence in 1975; need a map from later than
      #     1975 for its borders to show up.
      
      # Back to the main routine needed for drawing the map.         
      # Merge the Gini coefficient data with the world map
      #the_data <- right_join(monthly_dataset_comp_wise, 
      the_data <- left_join(world_map,codebook_data_long, 
           by = c("adm0_a3_is"="iso_code"))
      fechas_distintas<- length(unique(the_data$days))-1
      # Draw the map
  ggplot(data = the_data, aes(fill=cases_deaths)) +
    geom_sf()+
        #scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6))+
        scale_fill_gradientn(colours = brewer.pal(6, "Reds"), #na.value = "white",limits = limits, 
                             trans=log10_trans()) +
        theme_void()+
        #theme(legend.position = c(0, 0)) +
        labs(fill = "Deaths(MM)",
             caption = "@ags") +
        theme(legend.title.align = 0.5)+
        
        #transition_manual(dates)+
        transition_manual(days)+
        theme(plot.caption = element_text(face = "italic",size=9))+
        ease_aes("linear")+
        enter_grow() +
        enter_fade()+
        ggtitle("Deaths attributed to COVID19 over different days since the first case: {frame}")+
        labs(caption= "Note. Each time frame correspond\nto the 1st epidemiological day of the country,30th (=2), 60th (=3), 90th (=4), and 120th (=5)")
    # Combine all the frames into a single animated GIF, using ImageMagick
    # note since upgrade to v7 ImageMagick uses magick not convert, which makes
    # things much easier for Windows users (no conflict with Windows convert, which
    # does something completely different)
 #dplyr::filter(ndays %in% c(1,30,60,90))%>%
```

```{r prepare_codebook, echo=T, error=T, warning=FALSE}

invisible(c("DataExp"))
#https://boxuancui.github.io/DataExplorer/
#DataExplorer::create_report(coronavirus_iso3c_8)
    
mostrar="no"
    if(mostrar=="si"){
        ExPanDaR::ExPanD(df = codebook_data,
               export_nb_option = F,  #para proteger la base de datos
               title= "COVID19 Exploration of Dataset", 
               abstract= "Summarised information of the variables. ID: iso_code" ,
               df_name= "COVID19_Cons", 
              # df_def= df_def,
               cs_id = "iso_code",
               key_phrase = "ags", #proteger la bd
               store_encrypted= T) 
    }

library(codebook)

# to import an SPSS file from the same folder uncomment and edit the line below
# codebook_data <- rio::import("mydata.sav")
# for Stata
# codebook_data <- rio::import("mydata.dta")
# for CSV
# codebook_data <- rio::import("mydata.csv")

# omit the following lines, if your missing values are already properly labelled
codebook_data <- detect_missing(codebook_data,
    only_labelled = TRUE, # only labelled values are autodetected as
                                   # missing
    negative_values_are_missing = FALSE, # negative values are missing values
    ninety_nine_problems = FALSE,   # 99/999 are missing values, if they
                                   # are more than 5 MAD from the median
    )

# If you are not using formr, the codebook package needs to guess which items
# form a scale. The following line finds item aggregates with names like this:
# scale = scale_1 + scale_2R + scale_3R
# identifying these aggregates allows the codebook function to
# automatically compute reliabilities.
# However, it will not reverse items automatically.
codebook_data <- detect_scales(codebook_data)

remove(list=apropos("borders"))
rm(list=ls(pattern="^t_.{3}$"))  
rm(list=ls(pattern="^t2019"))
rm(list=ls(pattern="^t2020"))
remove(list="weather")
remove(list="temp_list")
remove(list=c("tNA","tSA","tIceland","tGlobal","tTimor","tAfrica","tCar","tCongo","vim_agg","tEU"))

#remove(list=startsWith("borders")) "^t_.{3}$" "weather" temp_list

      tryCatch(
                     {
      save.image("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_proj_post_ago.RData")
      rio::export(codebook_data, "C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_post_ago_2021.dta")
                     },
                         error = function(e){
      save.image(paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"merged_data_proj_post_ago.RData"))
      rio::export(codebook_data, paste0(gsub("Dataset_Cons_post_ago.Rmd","",rstudioapi::getSourceEditorContext()$path),"merged_data_post_ago_post_ago_2021.dta"))
                         }
                   )
sessionInfo()
#unlink("Dataset_Cons_post_ago_cache", recursive = TRUE)
#rmarkdown::render("Dataset_Cons_post_ago.Rmd", output_format = "html_document")
```

# References

-   Hale T, Angrist N, Kira B, et al. (May 25, 2020). Variation in government responses to COVID-19 (version 6.0).Blavatnik School of Government working paper. <https://www.bsg.ox.ac.uk/sites/default/files/2020-05/BSG-WP-2020-032-v6.0.pdf> (accessed July 11, 2020).

-   Hart,E. (). rWBclimate: A package for accessing World Bank climate data. R package version 0.1.3 <http://github.com/ropensci/rWBclimate>

-   Global Burden of Disease Collaborative Network. Global Burden of Disease Study 2017 (GBD 2017) Results. Seattle, United States: Institute for Health Metrics and Evaluation (IHME), 2018. Available from <http://ghdx.healthdata.org/gbd-results-tool>.
