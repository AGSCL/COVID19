---
title: "Dataset Consolidation"
output:
  html_document: 
    code_folding: hide
    fig_height: 6
    fig_width: 8
    theme: spacelab
    toc: yes
    toc_depth: 5
    toc_float: yes
    number_sections: yes
---

<style type="text/css">
.tablelines table, .tablelines td, .tablelines th {
  border: 1px solid black;
  }
.centrado {
  text-align: center;
}
.table.center {
  margin-left:auto; 
  margin-right:auto;
}
.table_wrapper{
  display: block;
  overflow-x: auto;
  white-space: nowrap;
}
code.r{
  font-size: 8px;
}
body{ /* Normal  */
    text-align: justify;
}
.superbigimage{
  overflow-y:scroll;
  white-space: nowrap;
}
.superbigimage img{
  overflow-y: scroll;
  overflow-x: hidden;
}
p.comment {
  background-color: #FF7F79;
    padding: 10px;
  border: 1px solid black;
  margin-left: 25px;
  border-radius: 5px;
  font-style: italic;
}
</style>
  
  <style>
  p.comment {
    background-color: #ff9a9a;
      padding: 10px;
    border: 1px solid red;
    margin-left: 25px;
    border-radius: 5px;
    font-style: italic;
  }

</style>
```{r setup0, include=FALSE}
rm(list=ls());gc()
```

```{r setup, include=FALSE}
#arriba puse algunas opciones para que por defecto escondiera el código
#también cargue algunos estilo .css para que el texto me apareciera justificado, entre otras cosas.
local({r <- getOption("repos")
       r["CRAN"] <- "http://cran.r-project.org" 
       options(repos=r)
})

`%>%` <- magrittr::`%>%`
copiar_nombres <- function(x,row.names=FALSE,col.names=TRUE,dec=",",...) {
  if(class(ungroup(x))[1]=="tbl_df"){
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(data.frame(x)),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)    
        }
  } else {
        if(options()$OutDec=="."){
            options(OutDec = dec)
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ".")
          return(x)
        } else {
            options(OutDec = ",")
            write.table(format(x),"clipboard",sep="\t",row.names=FALSE,col.names=col.names,...)
            options(OutDec = ",")
          return(x)       
  }
 }
}  

unlink('ThePoliticsOfCoronavirusInChile_cache', recursive = TRUE) #para borrar datos alojados en cache
pacman::p_unlock(lib.loc = .libPaths()) #para no tener problemas reinstalando paquetes
knitr::opts_chunk$set(echo = TRUE)
#dejo los paquetes estadísticos que voy a utilizar
try(devtools::install_github("joachim-gassen/tidycovid19", quiet=T,  upgrade="never"))   
try(if(!require(rWBclimate)){devtools::install_github("ropensci/rWBclimate", quiet=T,  upgrade="never")})
try(if(!require(wwmetrics)){devtools::install_github("emlaet/wwmetrics", quiet=T,  upgrade="never")})
try(if(!require(ExPanDaR)){devtools::install_github("joachim-gassen/ExPanDaR", quiet=T,  upgrade="never")})

if(!require(polycor)){install.packages("polycor")}
if(!require(ggcorrplot)){install.packages("ggcorrplot")}
if(!require(codebook)){install.packages("codebook")}
if(!require(plotly)){install.packages("plotly")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(lubridate)){install.packages("lubridate")}
if(!require(htmlwidgets)){install.packages("htmlwidgets")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(gganimate)){install.packages("gganimate")}
if(!require(gapminder)){install.packages("gapminder")}
if(!require(gifski)){install.packages("gifski")}
if(!require(readr)){install.packages("readr")}
if(!require(stringr)){install.packages("stringr")}
if(!require(data.table)){install.packages("data.table")}
if(!require(DT)){install.packages("DT")}
if(!require(ggplot2)){install.packages("ggplot2")}
if(!require(ggseas)){install.packages("ggseas")}
if(!require(lattice)){install.packages("lattice")}
if(!require(forecast)){install.packages("forecast")}
if(!require(zoo)){install.packages("zoo")}
if(!require(panelView)){install.packages("panelView")}
if(!require(janitor)){install.packages("janitor")}
if(!require(rjson)){install.packages("rjson")}
if(!require(estimatr)){install.packages("estimatr")} 
if(!require(jsonlite)){install.packages("jsonlite")}
if(!require(RJSONIO)){install.packages("RJSONIO")}
if(!require(RCurl)){install.packages("RCurl")}
if(!require(textreg)){install.packages("textreg")}
if(!require(sjPlot)){install.packages("sjPlot")}
if(!require(geojson)){install.packages("geojson")}
if(!require(rworldmap)){install.packages("rworldmap")}
if(!require(tweenr)){install.packages("tweenr")}
if(!require(ggthemes)){install.packages("ggthemes")}
if(!require(rgeos)){install.packages("rgeos")}
if(!require(curl)){install.packages("curl")}
if(!require(countrycode)){install.packages("countrycode")}
if(!require(wbstats)){install.packages("wbstats")}
if(!require(climate)){install.packages("climate")}
if(!require(dplyr)){install.packages("dplyr")}

Sys.setlocale(category = "LC_ALL", locale = "english")

```

## First Join of the Datasets

In first place, we downloaded the data and count the amount of rows that every country in a single date. The following countries show more than one entry in each single date: 

```{r setting, echo=T, cache= T, paged.print=TRUE, warning=F}

jhudata <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv", sep=",", encoding="UTF-8", header=T)

jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 1: ', htmltools::em('Countries with more than one entry by date')))
```
<br>

We explored these countries, and found that Australia, Canada, China France had the information disaggregated by provinces. In contrast, United Kingdom, Netherlands & Denmark had an entry that seems to be the total amount of cases by date. For the former countries, we collapsed the information by getting the sum of the cases by province; but for the latter, we dropped the reports regarding provinces or regions. This let us have one a dataset with one entry by country and date.

<br>

```{r setting2, echo=T, cache= T, paged.print=TRUE, warning=F,message=F}
coronavirus<-
jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  #elimino a los casos distintos
  dplyr::mutate(descarte=case_when(country=="United Kingdom"&Province.State!=""~1,
                          country=="Netherlands"&Province.State!=""~1,
                          country=="Denmark"&Province.State!=""~1,
                          TRUE~0))%>%
  dplyr::filter(descarte==0)%>%
  #genero una suma para cada fecha por país
  dplyr::group_by(country, dates)%>%
  dplyr::summarise(cases=sum(sum,na.rm=T))%>%
  dplyr::ungroup()%>%
  dplyr::group_by(country)%>%
  dplyr::mutate(ndays_zero=row_number())%>%
 # dplyr::filter(cases>0)%>%
  dplyr::ungroup()
```

<br>

Next, we added a 3-letter ISO format to every country and a date column in ISO 8601 format (YYYY-MM_DD). We used data available from the following [webpage] (https://ourworldindata.org/coronavirus-source-data).  However, some countries did not matched any of the available labels, as can be seen in the following table. For more information about the official, please go to the following [link](https://unstats.un.org/unsd/methodology/m49/).

<br>

```{r setting3, echo=T, cache= T, paged.print=TRUE, warning=F}
owid_covid_data <- readr::read_csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv")%>%
  distinct(iso_code,.keep_all=T)
#Aplicando distinct, nos permite que no se generen valroes duplicados en la combinación de bases de datos.

coronavirus%>%
    dplyr::left_join(dplyr::select(owid_covid_data,location,iso_code), by=c("country"="location"))%>% dplyr::filter(is.na(iso_code))%>% group_by(country) %>% 
  dplyr::summarise("% w/ missing values"=scales::percent(sum(is.na(iso_code))/max(ndays_zero)))%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 2: ', htmltools::em('Not matched countries w/ Owid Data')))
  #combinar con otra base de datos que tiene los iso. 

earlyDate<-min(coronavirus$dates)
```

<br>

We decided to work with some of these countries, particularly those with a greater population, testings or more relevant public policies. That is why we only changed the names of "US" "South Korea", "Taiwan", "Congo "Congo (Kinshasa)", "Democratic Congo" and "Czechia". The rest of countries will be dropped, since they were not eligible for further analysis. Also, we had information of China since January 22, 52 days after the first case in Dec. 1st of 2019. We added 52 days to China.

<br>

```{r setting4, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus%>%
    dplyr::mutate(country=case_when(country=="Korea, South"~"South Korea",
                                    country=="Taiwan*"~"Taiwan",
                                    country=="Congo (Kinshasa)"~"Democratic Republic of Congo",
                                    country=="Congo (Brazzaville)"~"Congo",
                                    country=="Cabo Verde"~"Cape Verde",
                                    country=="Czechia"~"Czech Republic",
                                    country=="Eswatini"~"Swaziland",
                                    country=="Timor-Leste"~"Timor",
                                    
                                    country=="US"~"United States",TRUE~country))%>%
    #combinar con otra base de datos que tiene los iso. 
    dplyr::left_join(owid_covid_data,location, by=c("country"="location"), suffix=c("","owid"))%>% 
    dplyr::filter(!is.na(iso_code))%>% #me baja de 32,148 a 30,096
    #group_by(country) %>% summarise(perc_days_with_nas=sum(is.na(iso_code))/max(ndays))%>%datatable()
    assign("coronavirus_iso3c",., envir = .GlobalEnv)

corona_no_day_zero<-
    coronavirus_iso3c%>%
    dplyr::group_by(iso_code)%>%
    dplyr::filter(cases>0)%>%
    #assigned china +52 days since 01-12-2019
    dplyr::mutate(ndays=case_when(iso_code=="CHN"~as.numeric(row_number())+52,
                                  TRUE~as.numeric(row_number())))
  
  coronavirus_iso3c%>%
    dplyr::left_join(select(corona_no_day_zero,iso_code,dates,ndays),by=c("iso_code"="iso_code","dates"="dates"))%>%
    dplyr::select(country,dates,cases,ndays_zero,iso_code,continent,population,population_density,
                  median_age,aged_65_older,aged_70_older,gdp_per_capita,extreme_poverty,
                  diabetes_prevalence,female_smokers,male_smokers,handwashing_facilities,hospital_beds_per_thousand,
                  life_expectancy,ndays)%>%
    assign("coronavirus_iso3c",., envir = .GlobalEnv)
```

<br>

WHO data may have errors regarding cumulative number of cases, as shown below. **It is important to solve these type of errors somehow**.

<br>

```{r test_serial, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c%>%
  dplyr::arrange(iso_code, dates)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate(lag_cases=dplyr::lag(cases),
                lag_dates=dplyr::lag(dates),
                diff_cases=cases-lag_cases)%>%
  dplyr::filter(diff_cases<0)%>%
  dplyr::select(country,iso_code,dates,cases,lag_cases,lag_dates)%>%
  datatable( filter = 'top',caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 3: ', htmltools::em('Problems with serial report of New Cases by Countries')))
```

# Deaths JHU

We joined the confirmed cases with WHO Datasets.

<br>

```{r set_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}

jhudata <- read.csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv", sep=",", encoding="UTF-8", header=T)

jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%
    datatable(caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 4: ', htmltools::em('Countries with more than one entry by date, data of deaths')))
```

<br>

We explored these countries, and found that Australia, Canada, China France had the information disaggregated by provinces. In contrast, United Kingdom, Netherlands & Denmark had an entry that seems to be the total amount of cases by date. For the former countries, we collapsed the information by getting the sum of the cases by province; but for the latter, we dropped the reports regarding provinces or regions. This let us have one a dataset with one entry by country and date.

<br>

```{r set_deaths2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_deaths<-
  jhudata %>%
  tidyr::pivot_longer(cols=starts_with("X"), names_to = "dates", values_to = "sum")%>%
  dplyr::rename("country"="Country.Region")%>%
  dplyr::mutate(dates=stringr::str_sub(dates,2,12))%>%
  dplyr::mutate(dates=lubridate::parse_date_time(as.character(dates),"%m.%d.%y"))%>%
  dplyr::mutate(dates=as.Date(as.character(dates)))%>%
  dplyr::arrange(country, dates)%>%
  #elimino a los casos distintos
  dplyr::mutate(descarte=case_when(country=="United Kingdom"&Province.State!=""~1,
                                   country=="Netherlands"&Province.State!=""~1,
                                   country=="Denmark"&Province.State!=""~1,
                                   TRUE~0))%>%
  dplyr::filter(descarte==0)%>%
  dplyr::mutate(country=case_when(country=="Korea, South"~"South Korea",
                                country=="Taiwan*"~"Taiwan",
                                country=="Congo (Kinshasa)"~"Democratic Republic of Congo",
                                country=="Congo (Brazzaville)"~"Congo",
                                country=="Cabo Verde"~"Cape Verde",
                                country=="Czechia"~"Czech Republic",
                                country=="Eswatini"~"Swaziland",
                                country=="Timor-Leste"~"Timor",
                                
                                country=="US"~"United States",TRUE~country))%>%
  #genero una suma para cada fecha por país
  dplyr::group_by(country, dates)%>%
  dplyr::summarise(cases=sum(sum,na.rm=T))%>%
  dplyr::ungroup()%>%
  dplyr::group_by(country)%>%
  dplyr::mutate(ndays_zero=row_number())%>%
  # dplyr::filter(cases>0)%>%
  dplyr::rename("cases_deaths"="cases")%>%
  dplyr::ungroup()

if(
coronavirus_deaths%>%
  dplyr::arrange(country, dates)%>%
  dplyr::group_by(country,dates)%>%
  add_tally() %>%   #cuento la cantidad de entradas por día que tiene cada país
  ungroup()%>%  
  dplyr::filter(n>1)%>% #filtro a los que tienen más de una entrada en cada fecha
  dplyr::group_by(country)%>%
  dplyr::summarise(n=n())%>%nrow()
>0){"still problems with duplicated data"}
```

<br>

Next, we merged this dataset with our consolidated dataset. However, must notice that, similar to the dataset of cases, some countries could not be matched, as can be seen in the following Table.

<br>

```{r set_deaths3, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_deaths%>%
  dplyr::left_join(coronavirus_iso3c, by="country", suffix=c("","_cons"))%>% 
  dplyr::filter(is.na(iso_code))%>% 
  group_by(country) %>% 
  dplyr::summarise("% w/ missing values"=scales::percent(sum(is.na(iso_code))/max(ndays_zero)))%>%
    datatable(caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 5: ', htmltools::em('Not matched countries of Deaths w/ Consolidated Dataset')))
  #combinar con otra base de datos que tiene los iso. 
earlyDate_deaths<-min(coronavirus_deaths$dates)

```
<br>


```{r cons_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c%>%
  #combinar con otra base de datos que tiene los iso. 
  dplyr::left_join(coronavirus_deaths, by=c("country","dates"), suffix=c("","_deaths"))%>% 
  #group_by(country) %>% summarise(perc_days_with_nas=sum(is.na(iso_code))/max(ndays))%>%datatable()
  dplyr::mutate(text= paste("Country:", country,"<br> Dates:", dates,"<br> Cum.cases:",formatC(cases, format="f", big.mark=",", digits=0),"<br> No. Days Since 1st Case:",ndays, "<br> Cum.deaths:",formatC(cases_deaths, format="f", big.mark=",", digits=0)))%>%
  assign("coronavirus_iso3c_1",., envir = .GlobalEnv)
Sys.setlocale(category = "LC_ALL", locale = "english")
gg<- ggplot(data=coronavirus_iso3c_1,aes(x= dates, y=log10(cases_deaths),group=iso_code, text= text, color=iso_code))+
   geom_line()+
  sjPlot::theme_sjplot2() +
theme(panel.border = element_blank(),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      axis.line = element_line(colour = "black"),
      plot.margin = margin(5.5, 40, 5.5, 5.5))+
    #scale_x_date(date_breaks= "14 days", date_minor_breaks = "7 days", date_labels = "%m/%d") +
    theme(plot.caption = element_text(hjust = 0, face= "italic"))+
    theme(plot.tag.position =  c(.81,0.01),
          plot.tag = element_text(hjust = -.05, size=8,
                                  margin = margin(l = 10)))+
   # xlim(c(earlyDate,lastDate))+
   # scale_y_log10(labels = scales::trans_format("log10", scales::math_format(10^.x)))+
    theme(legend.position = "none", axis.title.x = element_blank())

ggplotly(gg,tooltip = "text", dynamicTicks=T) 
```

<br>

WHO data does not show errors regarding cumulative number of deaths, as shown below.

<br>

```{r test_serial_deaths, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_1%>%
  dplyr::arrange(iso_code, dates)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate(lag_cases=dplyr::lag(cases_deaths),
                lag_dates=dplyr::lag(cases_deaths),
                diff_cases=cases-lag_cases)%>%
  dplyr::filter(diff_cases<0)%>%
  dplyr::select(country,iso_code,dates,cases,lag_cases,lag_dates)%>%
  datatable(caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 6: ', htmltools::em('Problems with serial report of New Deaths by Countries')))
if(
coronavirus_iso3c_1%>%
    dplyr::mutate(error_no_days=ifelse(ndays_zero!=ndays_zero_deaths,1,0))%>%
    dplyr::filter(error_no_days==1)%>% nrow()>0
){"there are some cases with different days available in datasets of deaths and new cases"}
```

# Oxford Dataset


Academics from the University of Oxford have launched a dataset that track government responses (https://www.bsg.ox.ac.uk/sites/default/files/2020-06/Lockdown%20Rollback%20Checklist%20v4.pdf). This tool tracks the following indicators:
- school closure;
- workplace closures;
- public event cancellation;
- public transport closure;
- public information campaigns;
- restriction on internal movement;
- international travel controls;
- fiscal measures;
- monetary measures;
- emergency investment in healthcare;
- investment in vaccines.

Then, they generated an index that compares the stringency of policy responses by countries. Despite the ‘Stringency Index’ is not a direct measure of “the appropriateness or effectiveness of a country’s response” to the evolution of contagion, may be useful to understand measures that could be effective in determined periods and countries.


```{r set_oxford, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, fig.cap="Figure 2. Linear Trends of Stringency Index by Country"}
library(readr)
OxCGRT_latest <- read_csv("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv")%>%
                  dplyr::mutate(Date=as.Date(as.character(Date), "%Y%m%d"))%>% 
                  janitor::clean_names()
                  
#oxf_npi<- download_oxford_npi_data(cached = TRUE, silent = TRUE)
#oxf_npi<- https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv

OxCGRT_latest_join<-
    OxCGRT_latest%>%
      #dplyr::group_by(CountryCode, Date)%>% 
      dplyr::select(country_code,country_name, date,stringency_index)
Sys.setlocale(category = "LC_ALL", locale = "english")


plot_ly(
  x     = ~date, y = ~stringency_index, 
  color = ~country_code,
  data  = OxCGRT_latest,
  type = 'scatter',
        mode = 'lines')%>%
  layout(showlegend = FALSE)%>%
 # highlight(on = "plotly_click",off = "plotly_doubleclick")
  #highlight(on = "plotly_hover", off = "plotly_deselect", color = "red")
  highlight(on="plotly_hover",off="plotly_deselect",color="blue",opacityDim=.2, persistent = F)%>%
  layout(xaxis=list(spikethickness=4, spikecolor="gray50"))%>%
  layout(scene = list(
      xaxis = list(title = "Date"),
      yaxis = list(title = "Stringency Index")))


#BASE DE DATOS OXFORD Y 
coronavirus_iso3c_1%>%
    dplyr::mutate(iso_code= ifelse(iso_code=="OWID_KOS","RKS", as.character(iso_code)))%>%
    dplyr::left_join(dplyr::select(OxCGRT_latest_join,-country_name),by=c("iso_code"="country_code","dates"="date"))%>%
    dplyr::rename("stringency_ind_oxf"="stringency_index")->
                "coronavirus_iso3c_2"

unmatched_2_no_inf_on_quarantene<-
  coronavirus_iso3c_2%>% 
    dplyr::filter(is.na(stringency_ind_oxf))%>% 
    dplyr::group_by(iso_code)%>% 
    dplyr::summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
    dplyr::filter(N>=100)%>%
    dplyr::ungroup()%>%
    distinct(iso_code)%>%
    unlist()%>%
  as.character()
```

<br>

In case of Kosovo, we changed the ISO 3 code created by OWID dataset (OWID_KOS) in order to match with Oxford (RKS), but we must take note that Kosovo could be identified with the letters "XKO". In contrast, we selected countries that did not had information on specific dates. These missing values tend to be present on most recent dates. Possibly due to lack of updates on Oxford datasets.
 
<br>

```{r set_oxford2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
#para ver el comportamiento de los países en iso3 que no calzan con la base de datos de las medidas de oxford
#
#coronavirus_iso3c_2%>% 
#  dplyr::filter(iso_code %in% unmatched_2_no_inf_on_quarantene)%>% View()
coronavirus_iso3c_2%>% 
    dplyr::filter(is.na(stringency_ind_oxf))%>% 
    dplyr::group_by(iso_code,country)%>% 
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N<=100,N>1)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 7: ', htmltools::em('Dates with missing values on each country in Stringency Index as a result of the match')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '80%'});",
        "}")))

```

<br>

Reversely, the following countries did not joined with our dataset. Most of these countries are still in a complicated position in terms of geopolitical matters.
 
<br>

```{r set_oxford3, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
OxCGRT_latest_join%>%
    dplyr::anti_join(coronavirus_iso3c_2,by=c("country_code"="iso_code","date"="dates"))%>%
    dplyr::filter(date>="2020-01-22")%>%
    group_by(country_code,country_name)%>%
    summarise(N=n(),first_date=min(date),last_date=max(date))%>%
    dplyr::filter(N>10)%>%
      datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
                caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 8: ', htmltools::em('Countries of merged dataset that did not matched with Oxford Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '80%'});",
        "}")))

#"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
#coronavirus%>% dplyr::filter(grepl("Guam",country)), por lo visto no hay ninguno
```

<br>

Once the dataset is merged, we may see that some variables still have missing data in different variables (Table 10). Most of them are available or not by country, because this measure was not available for the whole country (time-invariant variable), and not only for a single or few days, excepting for `stringency_ind_oxf`, which had missing values beacause of the updates, as seen in Table 7.

<br>

```{r set_wb_oxf_miss1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_2%>%
  dplyr::select(-ndays_zero_deaths, -text, -ndays)%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:stringency_ind_oxf),~scales::percent(sum(is.na(.))/n()))%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 9. Percentage of Missing data in the Different Time Points By Country"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_2),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

<br>

We can see the variables that had the most share of missing values in the following table.

<br>

```{r set_wb_oxf_miss2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
coronavirus_iso3c_2%>%
  dplyr::select(-ndays_zero_deaths, -text, -ndays)%>%
    summarise_at(vars(population:stringency_ind_oxf),~scales::percent(sum(is.na(.))/n()))%>%
  data.frame()%>% t()%>%  data.table::as.data.table(keep.rownames = T)%>% 
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 10. Percentage of Missing data in the Different Time Points & Country By Variables"),
               align =rep('c', 101),
               col.names = c("Variables", "% of Miss.")) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c("Note. "), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")

rm(list=setdiff(ls(), c("coronavirus_iso3c_2","copiar_nombres")))
```

<br>

# Environmental Datasets

## World Bank Climate Data

We joined the dataset with `ropensci/rWBclimate` [repository](https://github.com/ropensci/rWBclimate), which is an R interface for the World Bank climate data used in the World Bank climate knowledge portal. Unfortunately, Kosovo (RKS), South Sudan (SSD), was not in the datasets. **This is very strange, because "SSD" notation is present in UN coding**. We obtained the monthly historical average temperature for each country, based on records from 1901 to 2009. The average obtained by month will depend on the historical data available by country. Additionally, we obtained the average indicator of decade for each variable, selecting the data related to 2010. **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_wb_climate, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=F}

    #https://cran.r-project.org/web/packages/rWBclimate/rWBclimate.pdf
    #Monthly average	The monthly average for all 12 months for a given time period
    #Annual average	a single average for a given time period
    #Monthly anomaly	Average monthly change (anomaly). The control period is 1961-1999 for temperature and precipitation variables, and 1961-2000 for derived statistics.
    #Annual anomaly	Average annual change (anomaly). The control period is 1961-1999 for temperature and precipitation variables, and 1961-2000 for derived statistics.
    #install.packages("rWBclimate")
    #https://github.com/ropensci/rWBclimate
#Month will return 12 values, a historical average for that month across all years.

country.list <- coronavirus_iso3c_2 %>% dplyr::filter(!iso_code %in% c("RKS", "SSD"))%>% distinct(iso_code)%>% unlist()%>% as.character()

### Grab temp data
global_hist_temp_month <-  get_historical_temp(country.list, "month") %>% dplyr::mutate(date_month=stringr::str_extract(month, "^.{3}"))
global_hist_temp_decade <-  get_historical_temp(country.list, "decade")

global_hist_prec_month <- get_historical_precip(country.list, "month") %>% dplyr::mutate(date_month=stringr::str_extract(month, "^.{3}"))
global_hist_prec_decade<- get_historical_precip(country.list, "decade")

```

<br>

In order to match with monthly information, we had to transform the datasets, incluiding a variable to identify the month of each date, in a three-character format (`date_month`).

<br>

```{r set_wb_climate1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
#rm(list=setdiff(ls(), c("coronavirus_iso3c_2", "global_hist_temp_month", "global_hist_temp_decade","global_hist_prec_month","global_hist_prec_decade")))
Sys.setlocale(category = "LC_ALL", locale = "english")
global_hist_prec_month <- 
global_hist_prec_month%>% dplyr::mutate(date_month=stringr::str_extract(tolower(month), "^.{3}"))
Sys.setlocale(category = "LC_ALL", locale = "english")
global_hist_temp_month <- 
global_hist_temp_month%>% dplyr::mutate(date_month=stringr::str_extract(tolower(month), "^.{3}"))

if(abs(nrow(global_hist_temp_month)-nrow(global_hist_temp_month))>0){
  paste("different amount of rows in the dataset")
}

if(abs(nrow(global_hist_temp_decade)-nrow(global_hist_prec_decade))>0){
  paste("different amount of rows in the dataset")
}
if(abs(nrow(global_hist_temp_decade)-nrow(global_hist_temp_decade))>0){
  paste("different amount of rows in the dataset")
}

if(identical(data.frame(iso=unique(global_hist_prec_month$locator)),data.frame(iso=unique(global_hist_temp_month$locator)))==F){
  paste0("countries obtained are different in the datasets")
}
if(identical(data.frame(iso=unique(global_hist_prec_decade$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)))==F){
  paste0("countries obtained are different in the datasets")
}
if(identical(data.frame(iso=unique(global_hist_prec_month$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)))==F){
  paste0("countries obtained are different in the datasets")
}

global_hist_temp_decade <-global_hist_temp_decade%>% dplyr::filter(year=="2010")
global_hist_prec_decade <-global_hist_prec_decade%>% dplyr::filter(year=="2010")

#all.equal(data.frame(iso=unique(global_hist_prec_decade$locator)),data.frame(iso=unique(global_hist_temp_decade$locator)), tolerance = 0)

#data.frame(isos=unique(global_hist_prec_decade$locator))%>% dplyr::anti_join(data.frame(isos=unique(global_hist_temp_decade$locator)))

Sys.setlocale(category = "LC_ALL", locale = "english")
coronavirus_iso3c_2%>%
    dplyr::select(-ndays_zero_deaths)%>%
    dplyr::mutate(date_month=months(dates),
                  date_month=stringr::str_extract(tolower(date_month), "^.{3}"))%>%
    dplyr::left_join(dplyr::select(global_hist_temp_month,locator,date_month,data),by=c("date_month"="date_month","iso_code"="locator"))%>%
    dplyr::rename("monthly_temp"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_prec_month,locator,date_month,data),by=c("date_month"="date_month","iso_code"="locator"))%>%
    dplyr::rename("monthly_prec"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_temp_decade,locator,data),by=c("iso_code"="locator"))%>%
    dplyr::rename("decade_temp"="data")%>%
    dplyr::left_join(dplyr::select(global_hist_prec_decade,locator,data),by=c("iso_code"="locator"))%>%
    dplyr::rename("decade_prec"="data")%>%
    dplyr::select(country, iso_code, dates, date_month,cases, cases_deaths, ndays,ndays_zero,text,everything())->
  #dplyr::select(dates, date_month)%>% View()
  coronavirus_iso3c_3
```

<br>

The following countries could not be joined with the dataset, becasuse they were not found. From the dataset, it could be possible that dichotomous response of missing vs. not-missing may be explained because there were  no monthly differences in availability of information. **We must think about the convenience of including these countries**.

<br>

```{r set_wb_climate2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
coronavirus_iso3c_3%>%
    dplyr::group_by(iso_code, country) %>% 
    summarise_at(vars(monthly_temp:decade_prec),~sum(is.na(.))/n())%>%
    dplyr::ungroup()%>%
    dplyr::mutate(sumVar = rowSums(.[3:6]))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::select(-sumVar)%>%
    dplyr::mutate_at(vars(monthly_temp:decade_prec),~scales::percent(.))%>%
  #dplyr::mutate(sumVar = rowSums(dplyr::select(monthly_temp:decade_prec)))%>% 
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Monthly Temp' = 4,'Monthly Prec' = 5,'Decade Temp' = 6,'Decade Prec' = 7),
              caption = htmltools::tags$caption(
                  style = 'caption-side: top; text-align: left;',
                  'Table 11: ', htmltools::em('Countries of merged dataset that did not matched with WB Climate Datasets')),
              options=list(
                  initComplete = JS(
                      "function(settings, json) {",
                      "$(this.api().tables().body()).css({'font-size': '80%'});",
                      "}")))
```

## World Bank Climate Data at 2016

We added the monthly average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal [available in this link]("https://climateknowledgeportal.worldbank.org/download-data"). **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_cckp_temp1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/temp.csv")
    },
    error = function(e){
        readr::read_csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/temp.csv")
    }
)

temp <- temp%>% 
  dplyr::filter(Year==2016)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,temperature_celsius)%>%
  dplyr::rename("month_temp_16"="temperature_celsius")

temp%>%
  dplyr::anti_join(coronavirus_iso3c_3,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("aug", "sep", "oct", "nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 12: ', htmltools::em('Countries and Months of CCKP dataset (Temp) that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")

```

<br>

As seen in Table 13, many countries did not had a 3-letter ISO code, possibly to geopolitical reasons. We replaced the missing values of ISO3 to join the dataset adequately.

<br>

```{r set_cckp_temp2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp<- 
 temp%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))
 
coronavirus_iso3c_3%>%
  dplyr::left_join(dplyr::select(temp,iso3,date_month, month_temp_16),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_temp_16))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 14: ', htmltools::em('Countries of our dataset (Temp) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_1<-
      coronavirus_iso3c_3%>%
        dplyr::left_join(dplyr::select(temp,iso3,date_month, month_temp_16),by= c("iso_code"="iso3","date_month"="date_month"))
```

<br>

Then, we added the dataset of rainfalls. We already resolved some of the problems in 3-letter ISO codes in Temperatures dataset.

<br>

```{r set_cckp_rain, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain <-tryCatch(
        {
           readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/rainfall.csv")
        },
        error = function(e){
           readr::read_csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/rainfall.csv")
        }
)

rain <- rain%>%
  dplyr::filter(Year==2016)%>% 
  janitor::clean_names()%>% 
  dplyr::mutate(date_month=stringr::str_extract(tolower(statistics), "^.{3}"))%>%
  dplyr::select(iso3,country,year, date_month,rainfall_mm)%>%
  dplyr::rename("month_rainfall_mm_16"="rainfall_mm")

rain <-
rain%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))

rain%>%
  dplyr::anti_join(coronavirus_iso3c_3,by= c("iso3"="iso_code","date_month"="date_month"))%>%
  dplyr::filter(!date_month %in% c("aug", "sep", "oct", "nov", "dec"))%>%
  dplyr::distinct(country,iso3,date_month)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Date Month' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 14: ', htmltools::em('Countries and Months of CCKP (rain) dataset that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

```{r set_cckp_rain2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
coronavirus_iso3c_3%>%
  dplyr::left_join(dplyr::select(rain,iso3,date_month, month_rainfall_mm_16),by= c("iso_code"="iso3","date_month"="date_month"))%>%
  dplyr::filter(is.na(month_rainfall_mm_16))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 15: ', htmltools::em('Countries of our dataset (Temp) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_2<-
        coronavirus_iso3c_3_1%>%
          dplyr::left_join(dplyr::select(rain,iso3,date_month, month_rainfall_mm_16),by= c("iso_code"="iso3","date_month"="date_month"))
```
<br>

## World Bank Climate Data, Aggregated Decennial

We added the decennial average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal, by getting the average number of the available monthly data by country: one from 1997-2006, and other from 2007-2016 [available in this link]("https://climateknowledgeportal.worldbank.org/download-data"). **In case of China, we used climatological data of the month of November as the starting point of the disease**.

<br>

```{r set_cckp_97_06_07_16_temp1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp_agg <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/tmp_1991_2016.csv")
    },
    error = function(e){
        readr::read_csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/tmp_1991_2016.csv")
    }
)

temp_agg_97_06 <- temp_agg%>% 
  dplyr::filter(Year>=1997 & Year <= 2006)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,countrycode)%>%
  dplyr::select(countrycode,country,year, statistics,temperature_celsius)%>%
  summarise(month_temp_agg97_06=mean(temperature_celsius, na.rm=T))%>%
  dplyr::rename("iso3"="countrycode")%>%
  ungroup()
temp_agg_07_16 <- temp_agg%>% 
  dplyr::filter(Year>=2007 & Year <= 2016)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,countrycode)%>%
  dplyr::select(countrycode,country,year, statistics,temperature_celsius)%>%
  summarise(month_temp_agg07_16=mean(temperature_celsius, na.rm=T))%>%
  dplyr::rename("iso3"="countrycode")%>%
  ungroup()

temp_agg_97_06%>%
  dplyr::anti_join(coronavirus_iso3c_3_2,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 16a: ', htmltools::em('Countries and Months of CCKP dataset (Temp) from 1997 to 2006, that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))

temp_agg_07_16%>%
  dplyr::anti_join(coronavirus_iso3c_3_2,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 16b: ', htmltools::em('Countries and Months of CCKP dataset (Temp) from 2007 to 2016, that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")

```

<br>

As seen in Tables 16, many countries did not had a 3-letter ISO code, possibly to geopolitical reasons. We replaced the missing values of ISO3 to join the dataset adequately.

<br>

```{r set_cckp_97_06_07_16_temp2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
temp_agg_97_06<- 
 temp_agg_97_06%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))
temp_agg_07_16<- 
 temp_agg_07_16%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))

coronavirus_iso3c_3_2%>%
  dplyr::left_join(dplyr::select(temp_agg_97_06,iso3,month_temp_agg97_06),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_temp_agg97_06))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 17a: ', htmltools::em('Countries of our dataset (Aggr. Temp 97-06) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_2%>%
  dplyr::left_join(dplyr::select(temp_agg_07_16,iso3,month_temp_agg07_16),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_temp_agg07_16))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 17b: ', htmltools::em('Countries of our dataset (Aggr. Temp 07-16) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_21<-
      coronavirus_iso3c_3_2%>%
  dplyr::left_join(dplyr::select(temp_agg_97_06,iso3,month_temp_agg97_06),by= c("iso_code"="iso3"))%>%
        dplyr::left_join(dplyr::select(temp_agg_07_16,iso3,month_temp_agg07_16),by= c("iso_code"="iso3"))
  
```

<br>

Then, we added the dataset of rainfalls. We already resolved some of the problems in 3-letter ISO codes in Temperatures dataset.

<br>

```{r set_cckp_97_06_07_16_rain1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain_agg <- tryCatch(
    {
        readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/pr_1991_2016.csv")
    },
    error = function(e){
        readr::read_csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/pr_1991_2016.csv")
    }
)

rain_agg_97_06 <- rain_agg%>% 
  dplyr::filter(Year>=1997 & Year <= 2006)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,iso3)%>%
  dplyr::select(iso3,country,year, statistics,rainfall_mm)%>%
  summarise(month_rain_agg97_06=mean(rainfall_mm, na.rm=T))%>%
  ungroup()
rain_agg_07_16 <- rain_agg%>% 
  dplyr::filter(Year>=2007 & Year <= 2016)%>% 
  janitor::clean_names()%>% 
  dplyr::group_by(country,iso3)%>%
  dplyr::select(iso3,country,year, statistics,rainfall_mm)%>%
  summarise(month_rain_agg07_16=mean(rainfall_mm, na.rm=T))%>%
  ungroup()

rain_agg_97_06%>%
  dplyr::anti_join(coronavirus_iso3c_3_21,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 18a: ', htmltools::em('Countries and Months of CCKP dataset (Rain) from 1997 to 2006, that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))

rain_agg_07_16%>%
  dplyr::anti_join(coronavirus_iso3c_3_21,by= c("iso3"="iso_code"))%>%
  dplyr::distinct(iso3,.keep_all=T)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' =3,'Avg Temp' =4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 18b: ', htmltools::em('Countries and Months of CCKP dataset (Rain) from 2007 to 2016, that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#monthly_temp_1 monthly_temp_30 month_temp_16_1 month_temp_16_30 month_rainfall_mm_16_1 month_rainfall_mm_16_30 as.Date("2019-12-30") as.Date("2019-12-01")
```

```{r set_cckp_97_06_07_16_rain2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F,message=T}
rain_agg_97_06<- 
 rain_agg_97_06%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))
rain_agg_07_16<- 
 rain_agg_07_16%>%
    dplyr::mutate(iso3= dplyr::case_when(iso3=="The" & country=="Bahamas"~"BHS",
                                        iso3=="The" & country=="Gambia"~"GMB", 
                                        iso3=="Republic of" & country=="Korea"~"KOR",
                                        iso3=="United Republic of" & country=="Tanzania"~"TZA", TRUE~as.character(iso3)))

coronavirus_iso3c_3_21%>%
  dplyr::left_join(dplyr::select(rain_agg_97_06,iso3,month_rain_agg97_06),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_rain_agg97_06))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 19a: ', htmltools::em('Countries of our dataset (Aggr. Temp 97-06) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_21%>%
  dplyr::left_join(dplyr::select(rain_agg_07_16,iso3,month_rain_agg07_16),by= c("iso_code"="iso3"))%>%
  dplyr::filter(is.na(month_rain_agg07_16))%>%
  dplyr::group_by(iso_code,country)%>%
  summarise(N=n(),first_date=min(dates),last_date=max(dates))%>%
  dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 19b: ', htmltools::em('Countries of our dataset (Aggr. Temp 07-16) that did not matched with CCKP dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
coronavirus_iso3c_3_22<-
      coronavirus_iso3c_3_21%>%
  dplyr::left_join(dplyr::select(rain_agg_97_06,iso3,month_rain_agg97_06),by= c("iso_code"="iso3"))%>%
        dplyr::left_join(dplyr::select(rain_agg_07_16,iso3,month_rain_agg07_16),by= c("iso_code"="iso3"))
```
<br>

## NOAA Datasets

This data was obtained from `open-covid-19/weather` repository ([link](https://github.com/open-covid-19/weather)), and takes information from NOAA. It reproduces the last 2 years worth of records for all active stations from the Global Historical Climatology Network from the National Oceanic and Atmospheric Administration. Weather stations which are at most 300km from the location coordinates are considered. However, if we take a look into the nearer 100 stations to Chile, we may see that they could be very different and far away from the centroids, so we may be cautious when using these variables. 

<br>

```{r noaa, echo=T, cache= T, paged.print=TRUE,eval=T, fig.height=13,fig.width=4,  warning=F,message=F}
library(climate)
tryCatch(
    {
ns = climate::nearest_stations_nooa(country ="CHILE",#SPAIN NORWAY UNITED KINGDOM
                                    no_of_stations = 100, add_map = TRUE)
    },
    error = function(e){
                    tryCatch(
                            {
                              knitr::include_graphics('C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/map_chile_stations_noaa.png', dpi=96)
                            },
                            error = function(e){
                             knitr::include_graphics('C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/map_chile_stations_noaa.png', dpi=96)
                            }
                    )
          }
)


```

<br>

We checked the process and what they did is to obtain daily information from NOAA ("https://www.ncei.noaa.gov/data/global-historical-climatology-network-daily/access/"`{station.id}`".csv"`), then they got all the weather stations with data up until 2020 from [link]("https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-inventory.txt") and that provide at least max and min temperatures. We included the 3-letter-ISO into the dataset, to let us merge it with out dataset.

<br>

```{r noaa_1, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
index <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/index.csv")
weather <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/weather.csv")%>%
      dplyr::left_join(select(index,key,`3166-1-alpha-3`,aggregation_level),
                       by=c("key"="key"))%>%
      dplyr::filter(aggregation_level==0)%>%
      dplyr::rename("iso_3"=`3166-1-alpha-3`)%>%
      select(iso_3,everything())

#rm(list=setdiff(ls(), c("coronavirus_iso3c_3_2","copiar_nombres","weather","index")))
```

<br>

We looked into the countries that could have more than one entry by date.

<br>

```{r noaa_2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F}
#40190099999
  weather%>%
         dplyr::group_by(iso_3, date)%>%
         mutate(n=n())%>%
         dplyr::filter(n>1)%>%
        dplyr::select(iso_3,date, key,n)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Date' =3,'Key' = 4,'No. of Times' = 5),
              caption = htmltools::tags$caption(
                  style = 'caption-side: top; text-align: left;',
                  'Table 20: ', htmltools::em('Countries with more than one entry by date')),
              options=list(
                   autoWidth = TRUE,
                  initComplete = JS(
                      "function(settings, json) {",
                      "$(this.api().tables().body()).css({'font-size': '80%'});",
                      "}")))
```

<br>

As can be seen in the following dataset Netherlands Antilles (AN) and Gaza (NZ) were not a member of a recognized state. Most of these countries are still in a complicated position in terms of geopolitical matters. That is why **we deleted them from the join with our dataset.**.

<br>

Next, we filtered the dataset starting from Jan. 22, and looked over the dates that did not match with our entries.

<br>

```{r noaa_3, echo=T, cache= T, paged.print=TRUE,eval=T}
#40190099999
weather%>%
  dplyr::filter(key!="AN"|key!="GZ")%>%
  dplyr::filter(date>="2020-01-22")%>%
  dplyr::anti_join(coronavirus_iso3c_3_2,by=c("iso_3"="iso_code","date"="dates"))%>%
  dplyr::left_join(select(index,key,`3166-1-alpha-3`,country_name),
                       by=c("key"="key"))%>%
  group_by(iso_3,country_name)%>%
  summarise(N=n(),first_date=min(date),last_date=max(date))%>%
  dplyr::filter(N>10)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 21: ', htmltools::em('Countries of NOAA dataset that did not matched with our dataset')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

As seen in Table 21, most of these countries are still in a complicated position in terms of geopolitical matters. **We decided to exclude them from analysis**.

<br>

```{r noaa_4, echo=T, cache= T, paged.print=TRUE,eval=T}
#40190099999
weather<-
      weather%>%
        dplyr::filter(key!="AN"|key!="GZ")%>%
        dplyr::filter(date>="2020-01-22")  

  coronavirus_iso3c_3_22%>%
  dplyr::left_join(dplyr::select(weather,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(dates) %>% 
    summarise_at(vars(noaa_station:rainfall),~sum(is.na(.))/n())%>%
    dplyr::ungroup()%>%
    dplyr::mutate(sumVar = scales::percent(rowSums(.[2:7])/6))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::rename("mean_miss_data_noaa"="sumVar")%>%
    dplyr::mutate_at(vars(noaa_station:rainfall),~scales::percent(.))%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 22. Percentage Dates of our dataset that did not matched with NOAA dataset"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_3_2),"observations of the total dataset")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```

<br>

We decided to join the dataset but excluding `snowfall` variable, due to lack of information among many countries. Still, there is a considerable amount of missing data (Table 14). Possibly, this problem may be explained because a determined country or date does not have stations, or because more reent dates are still being updated (such as `r max(coronavirus_iso3c_3_2$dates)`)

<br>

In the following two tables we may see countries with missing information in NOAA stations. In Table 23_1, we see that many developed countries did not have information related to climate from NOAA stations.

<br>

```{r noaa_5_1, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_22%>%
  dplyr::left_join(dplyr::select(weather,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 23_1: ', htmltools::em('Missing Information by Country in NOAA Station (In approx. every date)')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
#ESP	Spain  FRA	France FIN	Finland BEL	Belgium	 DNK	Denmark	GBR	United Kingdom	PRT	Portugal NOR	Norway NLD	Netherlands IRL	Ireland ISL	Iceland SWE	Sweden	
```

<br>

Most of these data could not be retrieved because is aggregated by macroregion within countries, but do not represent the whole country. Excluding Eritrea, England in Great Britain & Svalbard in Norway, every country had more than one regional information.**We should discuss what would be inclusion criteria in this matter**.

<br>

```{r noaa_mod_by_find_in_5_1, echo=T, cache= T, paged.print=TRUE,eval=T}
country_noaa_data_only_subregions<-
coronavirus_iso3c_3_22%>%
    dplyr::left_join(dplyr::select(weather,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    distinct(iso_code)%>%
    unlist()%>%
    as.character()

weather_or <- readr::read_csv("https://storage.googleapis.com/covid19-open-data/v2/weather.csv")%>%
    dplyr::left_join(select(index,key,`3166-1-alpha-3`,subregion1_name,aggregation_level),
                     by=c("key"="key"))%>%
    dplyr::rename("iso_3"=`3166-1-alpha-3`)%>%
    dplyr::filter(iso_3 %in% country_noaa_data_only_subregions)%>%
    select(iso_3,everything())

weather_or%>%
    dplyr::distinct(subregion1_name,.keep_all=T)%>% 
  dplyr::select(iso_3, noaa_station, noaa_distance, subregion1_name)%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Station' = 3,'Distance' = 4, "Subregion"= 5),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 23_2: ', htmltools::em('Countries with not aggregated data concerning Climate')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
#*The reported weather station refers to the nearest station which provides temperature measurements, but rainfall and snowfall may come from a different nearby weather station. In all cases, only weather stations which are at most 300km from the location coordinates are considered.

#noaa_station= Identifier for the weather station	
#noaa_distance= Distance between the location coordinates and the weather station	
#average_temperature= Recorded hourly average temperature	
#minimum_temperature= Recorded hourly minimum temperature	
#maximum_temperature= Recorded hourly maximum temperature	
#rainfall= Rainfall during the entire day	
```

<br>

In the following two tables we may see countries with missing information in NOAA stations.**Most of these countries should not be considered**.

<br>

```{r noaa_5_2, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_22%>%
  dplyr::left_join(dplyr::select(weather,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))%>%
    dplyr::group_by(iso_code, country)%>% 
    dplyr::filter(is.na(noaa_station))%>%
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N<=100,N>1)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 23_3: ', htmltools::em('Missing Information by Country in NOAA Station (Not in every date, but at least in more than one)')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

Considering this temporary limitations, **for now** we merged the data for countries with aggregated data only. Meaning that **information directly obtained from NOAA was not considered for posterior analyses**.

<br>

```{r noaa_6, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_3_22%>%
  dplyr::left_join(dplyr::select(weather,iso_3,date,noaa_station, noaa_distance, average_temperature, minimum_temperature, maximum_temperature, rainfall),by=c("iso_code"="iso_3","dates"="date"))->
  coronavirus_iso3c_4
```

# Worldwide Indicators

## Corruption Perceptions Index

We accessed Transparency International to query the [Coruption Perceptions Index](https://www.transparency.org/en/cpi/2019), which ranks 180 countries and territories by their perceived levels if public sector corruption. It is a composite index, a combination of surveys and assessments of corruption, collected by a variety of reputable institutions. The CPI is one of the most widely used indicatora of corruption worldwide. The data is available in the following [link](https://images.transparencycdn.org/images/2019_CPI_FULLDATA.zip).

<br>

```{r CPI2019, echo=T, cache= T, paged.print=TRUE,eval=T}


CPI2019 <- tryCatch(
                            {
                            readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/CPI2019.xlsx", skip=2,
    range = "A3:d1000")%>% janitor::clean_names()%>%
  dplyr::filter(!is.na(country))
                            },
                            error = function(e){
                              readxl::read_excel("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/CPI2019.xlsx", skip=2,
    range = "A3:d1000")%>% janitor::clean_names()%>%
  dplyr::filter(!is.na(country))
                            }
                    )
```

<br>

We first explored for the countries that could not be matched.

<br>

```{r CPI2019_2, echo=T, cache= T, paged.print=TRUE,eval=T}
CPI2019%>%
  dplyr::anti_join(coronavirus_iso3c_4, by=c("iso3"="iso_code"))%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Region' = 4,'CPI Score' = 5),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 24: ', htmltools::em('Countries of CPI2019 dataset that did not matched with our dataset')),
      options=list(
    autoWidth = TRUE,
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
#es de 0 a 100
```
<br>

The following Table shows countries that could not be match because they were not available in the dataset of CPI 2019. Most of the countries shown are developed countries or are still in a complicated position in terms of geopolitical matters. **We should not consider them**.

<br>

```{r CPI2019_3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_4%>%
  dplyr::left_join(CPI2019, by=c("iso_code"="iso3"), suffix=c("",".y"))%>%
  dplyr::select(-country.y, -region)%>%
  dplyr::filter(is.na(cpi_score_2019))%>%
  dplyr::group_by(iso_code, country)%>%
   summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 25: ', htmltools::em('Missing Information by Country in CPI2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))  

coronavirus_iso3c_4%>%
  dplyr::left_join(CPI2019, by=c("iso_code"="iso3"), suffix=c("",".y"))%>%
  dplyr::select(-country.y, -region)->
coronavirus_iso3c_5  
#es de 0 a 100
```

<br>

# UN HDI Dataset

We incorporated the Human Development Index (1990-2018), but some entries did not matched with country names of our dataset. Most of them are in a complicated position in geopolitical terms, and other did not correspond to actual countries or had never been one (such as aggregated regions, global, etc.).

<br>

```{r hdi, echo=T, cache= T, paged.print=TRUE,eval=T}
hdi <- tryCatch(
  {
      readr::read_csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/Human Development Index (HDI).csv", 
    skip = 1)%>% janitor::clean_names()
  },
      error = function(e){
      readr::read_csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/Human Development Index (HDI).csv", 
    skip = 1)%>% janitor::clean_names()
      }
)

hdi%>%
  dplyr::select(hdi_rank_2018,country,x2018)%>%
  dplyr::anti_join(coronavirus_iso3c_5,by="country")%>%
  dplyr::distinct(country,.keep_all=T)%>%    
    datatable(filter = 'top', colnames = c('Rank HDI 18' =2,'Country' = 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 26: ', htmltools::em('Countries of HDI dataset that did not matched with our dataset')),
      options=list(
    autoWidth = TRUE,
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

We standardized the names of many countries. However, **we still have problems with a few of them**.

<br>

```{r hdi_3, echo=T, cache= T, paged.print=TRUE,eval=T}
hdi<-hdi%>%
  dplyr::mutate(country=case_when(country=="Bolivia (Plurinational State of)"~"Bolivia",
                                country=="Brunei Darussalam"~"Brunei",
                                country=="Cabo Verde"~"Cape Verde",
                                country=="Congo (Democratic Republic of the)"~"Democratic Republic of Congo",
                                country=="Czechia"~"Czech Republic",
                                country=="Côte d'Ivoire"~"Cote d'Ivoire",
                                country=="Eswatini (Kingdom of)"~"Swaziland",
                                country=="Iran (Islamic Republic of)"~"Iran",
                                country=="Korea (Republic of)"~"South Korea",
                                country=="Lao People's Democratic Republic"~"Laos",
                                country=="Syrian Arab Republic"~"Syria",
                                country=="Tanzania (United Republic of)"~"Tanzania",
                                country=="Venezuela (Bolivarian Republic of)"~"Venezuela",
                                country=="Russian Federation"~"Russia",
                                country=="Timor-Leste"~"Timor",
                                country=="Moldova (Republic of)"~"Moldova",
                                country=="Viet Nam"~"Vietnam",TRUE~country))
hdi%>%
  dplyr::select(hdi_rank_2018,country,x2018)%>%
  dplyr::anti_join(coronavirus_iso3c_5,by="country")%>%
  dplyr::distinct(country,.keep_all=T)%>%    
    datatable(filter = 'top', colnames = c('Rank HDI 18' =2,'Country' = 3),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 27: ', htmltools::em('Countries of HDI dataset that did not matched with our dataset (tidy)')),
      options=list(
    autoWidth = TRUE,
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```
<br>

We merged the HDI dataset with our dataset. However, there still are some issues with some of the countries shown in Table 27.

<br>

```{r hdi_4, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_5%>%
    dplyr::left_join(dplyr::select(hdi,hdi_rank_2018,country,x2018),by="country")%>%
    dplyr::filter(is.na(hdi_rank_2018))%>%
    dplyr::group_by(iso_code, country)%>% 
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>100)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 28: ', htmltools::em('Missing Information by Country in HDI 2018')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))

coronavirus_iso3c_5%>%
    dplyr::left_join(dplyr::select(hdi,hdi_rank_2018,country,x2018),by="country")%>%
  dplyr::rename("hdi_index_2018"="x2018")%>%
  dplyr::mutate(hdi_rank_2018=as.numeric(hdi_rank_2018))%>%
  dplyr::mutate(hdi_index_2018=as.numeric(hdi_index_2018))->
  coronavirus_iso3c_6
```

<br>

# Good Country Index

Good country index (v. 1.3) measures how much each of the countries contribute to the planet and the human race through their policies and behaviors, consistent in Science & Technology, Culture, International Peace & Securitym World Order, Planet & Climate, Prosperity & Equality, and Health & Well-being [link](https://www.goodcountry.org/index/source-data/). Cubre a 153 países. For more information about this index, please go to the following [link](https://www.goodcountry.org/index/source-data/).

<br>

```{r gci, echo=T, cache= T, paged.print=TRUE,eval=T}
gci_dataset <- tryCatch(
  {
     readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/gci dataset.xlsx")
  },
      error = function(e){
        readxl::read_excel("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/gci dataset.xlsx")
      }
)

gci_dataset%>%
  dplyr::left_join(dplyr::select(index,country_name,`3166-1-alpha-3`), by=c("country"="country_name"))%>%
  dplyr::rename("iso_code"=`3166-1-alpha-3`)%>%
  dplyr::filter(is.na(iso_code))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 29: ', htmltools::em('Missing Information by Country in GCI 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the above, some countries did not match with ISO codes available due to their condition or character mistypings. We assumed that Republic of Korea corresponded to South Korea. In case of Congo, **we did not know if corresponded to Kinshasa or Brazzaville, but we decided to match it with Brazzaville (Republic of Congo)**.

<br>

```{r gci2, echo=T, cache= T, paged.print=TRUE,eval=T}
gci_dataset_iso<-
gci_dataset%>%
  dplyr::left_join(dplyr::select(index,country_name,`3166-1-alpha-3`), by=c("country"="country_name"))%>%
  dplyr::rename("iso_code"=`3166-1-alpha-3`)%>%
  dplyr::mutate(iso_code=dplyr::case_when(country=="Republic of Macedonia / FYROM"~"MKD",
                                          country=="Republic of Korea"~"KOR",
                                          country=="Russian Federation"~"RUS",
                                          country=="Viet Nam"~"VNM",
                                          country=="Brunei Darussalam"~"BRN",
                                          country=="Congo"~"COG",
                                          country=="Côte d'Ivoire"~"CIV",TRUE~iso_code))%>%
  dplyr::distinct(iso_code,.keep_all=T)

coronavirus_iso3c_6%>%
  dplyr::left_join(dplyr::select(gci_dataset_iso, iso_code, rank), by="iso_code")%>%
  dplyr::rename("gci_2018_rank"="rank")->
coronavirus_iso3c_7
#gci_dataset_iso%>%
 # dplyr::filter(is.na(iso_code))
coronavirus_iso3c_7%>%
  dplyr::filter(is.na(gci_2018_rank))%>% 
  dplyr::group_by(iso_code, country)%>%
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>0)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 30: ', htmltools::em('Missing Information by Country in GCI 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

There are some countries that do not include this indicator because there is not many information available to construct this index [(more info on this in the link) ]("https://www.goodcountry.org/index/your-questions/countries-included/").

<br>


# Economist Intelligence Unit's Democracy Index

<br>

The Unit of Intelligence of The Economist created a Democracy Index of different countries worldwide categorizing  them from full democracies through to authoritarian regimes.

<br>

```{r eiu, echo=T, cache= T, paged.print=TRUE,eval=T}
The_Economist_Dem_Index <- tryCatch(
  {
     readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/The Economist Dem Index.xlsx", 
    skip = 1)%>% janitor::clean_names()
  },
      error = function(e){
        readxl::read_excel("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/The Economist Dem Index.xlsx", 
    skip = 1)%>% janitor::clean_names()
      }
)

The_Economist_Dem_Index%>%
    dplyr::anti_join(coronavirus_iso3c_7, by="country")%>%
    dplyr::distinct(country,.keep_all=T)%>%
  dplyr::select(country, qualification,rank, everything())%>%
  dplyr::select(1:4)%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Rank' = 4,'Overall Score' = 5),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 31: ', htmltools::em('Missing Information by Country in EIU 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As shown in the Table above, most of these countries could not be matched due to mistyping, or because they do not provide data on confirmed cases with COVID-19. For those that were type in a different manner, we changed their names to match with our dataset.

<br>

```{r eiu2, echo=T, cache= T, paged.print=TRUE,eval=T}
The_Economist_Dem_Index<-
  The_Economist_Dem_Index%>%
    dplyr::mutate(country=dplyr::case_when(country=="United States of America"~"United States",
                                            country=="Cabo Verde"~"Cape Verde",
                                            country=="Timor-Leste"~"Timor",
                                            country=="Kyrgyz Republic"~"Kyrgyzstan",
                                            country=="Côte d’Ivoire"~"Cote d'Ivoire",
                                            country=="Bosnia and Hercegovina"~"Bosnia and Herzegovina",
                                            country=="eSwatini"~"Swaziland",
                                            country=="Congo (Brazzaville)"~"Congo",
                                            country=="Côte d'Ivoire"~"CIV",TRUE~country))%>%
  dplyr::select(country, qualification,rank, overall_score)
  #dplyr::anti_join(coronavirus_iso3c_7, by="country")%>%
  #  dplyr::distinct(country,.keep_all=T)%>%
  #dplyr::select(country, qualification,rank, everything())%>%
  #dplyr::select(1:4)
  
coronavirus_iso3c_7%>%
  dplyr::left_join(The_Economist_Dem_Index, by="country")%>%
  dplyr::rename("eiu_2019_rank"="rank")%>%
  dplyr::rename("eiu_2019_overall_score"="overall_score")->
coronavirus_iso3c_8
#gci_dataset_iso%>%
 # dplyr::filter(is.na(iso_code))
coronavirus_iso3c_8%>%
  dplyr::filter(is.na(eiu_2019_rank))%>% 
  dplyr::group_by(iso_code, country)%>%
    summarise(N=n(), first_date=min(dates),last_date=max(dates))%>%
    dplyr::filter(N>0)%>%
    dplyr::arrange(desc(N))%>%
    datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 32: ', htmltools::em('Missing Information by Country in EIU 2019')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, most of the countries that were not considered in thisindex are undeveloped countries or in a complicated position in geopolitical terms. 

<br>

# World Bank datasets

<br>

We considered the following additional variables to include them in the dataset: 
- SP.POP.TOTL= Population, Total

- EN.POP.DNST= Population Density

- SH.MED.PHYS.ZS= Physicians (per 1,000 people)

- SH.MED.BEDS.ZS= Hospital beds (per 1,000 people)

- EN.ATM.PM25.MC.M3 PM2.5= air pollution, mean annual exposure (micrograms per cubic meter) Brauer, M. et al. 2017, for the Global Burden of Disease Study 2017

- SP.DYN.LE00.IN= Life expectancy at birth, total (years)

<br>

However, we must consider the time span for which we would tolerate lagged years, depending on the amount of countries that had this information updated.

<br>

```{r wb_candidates1, echo=T, cache= T, paged.print=TRUE,eval=T, fig.cap="Figure 4.No of Countries By Tolerance on Last Days in Variables of Interest", error=T}
#SH.MED.PHYS.ZS Physicians (per 1,000 people)
#SH.MED.BEDS.ZS Hospital beds (per 1,000 people)
#SH.PRV.SMOK Smoking prevalence, total (ages 15+)
#EN.ATM.PM25.MC.M3 PM2.5 air pollution, mean annual exposure (micrograms per cubic meter) Brauer, M. et al. 2017, for the Global Burden of Disease Study 2017.
require(wbstats)
 #wb(country = "all", indicator = "SH.PRV.SMOK", mrv = 3) #no funciona
data_frame<-data.frame(iso3c="1",N=1, name="1",v="1")
  for (i in c("SP.POP.TOTL","EN.POP.DNST","SH.MED.PHYS.ZS","SH.MED.BEDS.ZS","EN.ATM.PM25.MC.M3","SP.DYN.LE00.IN")) {
      for (v in 1:7){
        df<-wb(country = "all", indicator = i, mrv = v)%>% 
                        group_by(iso3c)%>% summarise(N=n())%>%
          dplyr::mutate(name=paste0(i),v=paste0(v))
          #assign(paste0(i,"_",v),., envir = .GlobalEnv)
        data_frame<-rbind(data_frame,df)
      }
  }
data_frame<-
  data_frame%>%
    dplyr::filter(iso3c!="1")%>%
  dplyr::select(name, iso3c,v,N)%>%
  dplyr::rename("years_covered"="v")%>%
  group_by(name, years_covered)%>%
  summarise(no_countries=n())%>%
  ungroup()

ggplot(data_frame, aes(x=name, y=no_countries, fill=years_covered))+
  geom_bar(stat="identity")+
  geom_hline(yintercept =170, color="darkred",linetype=5)+
   facet_grid(years_covered~.)+
  theme_minimal()+
  labs(caption="red line= 170 countries")+ 
  theme(legend.position="bottom")+
  guides(fill=guide_legend(ncol=7))

```

<br>

Considering the figure above and what we discussed with Kassim & Thamara, we decided to tolerate 6 years of delay in the update of these statistics, in order to include a greater amount of countries.

<br>

Additionally, we test whether `EN.ATM.PM25.MC.M3` had different values from the consolidated dataset obtained from this [link](https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/edit#gid=0).

<br>

```{r wb_prueba_con_covid19_con_wb, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}

  for (i in c("SP.POP.TOTL","EN.POP.DNST","SH.MED.PHYS.ZS","SH.MED.BEDS.ZS","EN.ATM.PM25.MC.M3","SP.DYN.LE00.IN")) {
        wb(country = "all", indicator = i, mrv = 6)%>%
        assign(paste0("wb_",i),.,envir=.GlobalEnv)
  }
#https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/export?format=csv&id=1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8&gid=447690624

google_covid19 <- readr::read_csv("https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/export?format=csv&id=1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8&gid=0")%>%
  janitor::clean_names()


#no calza en un puros paises de pija
invisible(
google_covid19 %>%
  dplyr::select(iso3,name_engli,air_pollution)%>%
  dplyr::anti_join(wb_EN.ATM.PM25.MC.M3,by=c("iso3"="iso3c"))
)

invisible(
                  wb_EN.ATM.PM25.MC.M3%>%
                    #dplyr::select(iso3c,name_engli,air_pollution)%>%
                    dplyr::anti_join(google_covid19,by=c("iso3c"="iso3"))%>%
                    dplyr::select(iso3c,country,date)%>%
                    dplyr::group_by(iso3c,country)%>%
                    summarise(N=n(),first_date=min(date),last_date=max(date))
)
#SELECCIONO EL DATO MAS RECIENTE POR PAIS
invisible(
wb_EN.ATM.PM25.MC.M3%>%
    group_by(iso3c)%>%
    dplyr::filter(!is.na(value))%>%
    dplyr::filter(date==max(date))%>%
  #janitor::tabyl(iso3c,date) #todos 2017
  dplyr::ungroup()%>%
  dplyr::anti_join(google_covid19,by=c("iso3c"="iso3"))
)

#no eran paises los que no calzaron

if(
wb_EN.ATM.PM25.MC.M3%>%
    group_by(iso3c)%>%
    dplyr::filter(!is.na(value))%>%
    dplyr::filter(date==max(date))%>%
  #janitor::tabyl(iso3c,date) #todos 2017
  dplyr::ungroup()%>%
  dplyr::left_join(google_covid19,by=c("iso3c"="iso3"))%>%
  #dplyr::filter(is.na(value)) #no hay perdidos
  dplyr::mutate(distinct=abs(air_pollution-value))%>%
  #dplyr::mutate(distinct=ifelse(air_pollution-value,1,0))%>%
  dplyr::filter(distinct>0.00001)%>%
  dplyr::select(iso3c, name_engli,air_pollution,value,distinct)%>%
  nrow()>0){toupper("**there are differences between covid19 dataset and world bank**")}
#NO HAY DIFERENCIAS MAYORES DE 0.00001

#If you do not know the latest date an indicator you are interested in is available for you country you can use the mrv instead of startdate and enddate. mrv stands for most recent value and takes a integer corresponding to the number of most recent values you wish to return

#If you use the mrv parameter in wb() with mutliple countries or regions, it searches for the most recent dates for which any country or region in your selection has data and then returns the data for those dates. In other words the mrv value is not determined on a country by country basis, rather it is determined across the entire selection.

#Unless you know the country and indicator codes that you want to download the first step would be searching for the data you are interested in. wbsearch() provides grep style searching of all available indicators from the World Bank API and returns the indicator information that matches your query.

#To access what countries or regions are available you can use the countries data frame from either wb_cachelist or the saved return from wbcache(). This data frame contains relevant information regarding each country or region. More information on how to use this for downloading data is covered later.

```

```{r wb1_miss_a, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
t1<-wb_SP.POP.TOTL%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t2<-wb_EN.POP.DNST%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t3<-wb_SH.MED.PHYS.ZS%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t4<-wb_SH.MED.BEDS.ZS%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t5<-wb_EN.ATM.PM25.MC.M3%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)
t6<-wb_SP.DYN.LE00.IN%>% dplyr::group_by(iso3c,country)%>% summarise(n=n(),year=max(date))%>% dplyr::arrange(year)

coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SP.POP.TOTL,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("total_pop"="value", "year_total_pop"="date")%>%
  dplyr::filter(is.na(total_pop))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33a: ', htmltools::em('Missing Information by Country in Total Pop')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
```{r wb1_miss_b, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_EN.POP.DNST,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("pop_density"="value", "year_pop_density"="date")%>%
  dplyr::filter(is.na(pop_density))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33b: ', htmltools::em('Missing Information by Country in Pop Density')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
```{r wb1_miss_c, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SH.MED.PHYS.ZS,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("physicians_per_1000"="value", "year_physicians_per_1000"="date")%>%
  dplyr::filter(is.na(physicians_per_1000))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33c: ', htmltools::em('Missing Information by Country in No. of Physicians')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
```{r wb1_miss_d, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_SH.MED.BEDS.ZS,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("hosp_beds_per_1000"="value", "year_hosp_beds_per_1000"="date")%>%
  dplyr::filter(is.na(hosp_beds_per_1000))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33d: ', htmltools::em('Missing Information by Country in Hospital Beds')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
```{r wb1_miss_e, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
    dplyr::left_join(dplyr::select(wb_EN.ATM.PM25.MC.M3,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("air_pollution_year_pm25"="value", "year_air_pollution_year_pm25"="date")%>%
  dplyr::filter(is.na(air_pollution_year_pm25))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33e: ', htmltools::em('Missing Information by Country in Pollution PM25')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
```{r wb1_miss_f, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_8%>%
  dplyr::left_join(dplyr::select(wb_SP.DYN.LE00.IN,iso3c,date,value),
                     by=c("iso_code"="iso3c"))%>%
  dplyr::rename("life_exp"="value", "year_life_exp"="date")%>%
  dplyr::filter(is.na(life_exp))%>%
  dplyr::group_by(country, iso_code)%>%
  summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
  dplyr::ungroup()%>%
      datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 33f: ', htmltools::em('Missing Information by Country in Life Expectancy')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
<br>

Considering the missing data patterns, we decided to merge these indicators anyway.

<br>

```{r wb2, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
wb_SP.POP.TOTL<-
  wb_SP.POP.TOTL%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_EN.POP.DNST<-
  wb_EN.POP.DNST%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_SH.MED.PHYS.ZS<-
  wb_SH.MED.PHYS.ZS%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
        ungroup()
wb_SH.MED.BEDS.ZS<-
    wb_SH.MED.BEDS.ZS%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()
wb_EN.ATM.PM25.MC.M3<-
    wb_EN.ATM.PM25.MC.M3%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()
wb_SP.DYN.LE00.IN<-
    wb_SP.DYN.LE00.IN%>%
    dplyr::group_by(iso3c)%>%
     slice(1)%>%
      ungroup()

coronavirus_iso3c_9<- coronavirus_iso3c_8%>%
        dplyr::left_join(dplyr::select(wb_SP.POP.TOTL,iso3c,date,value),
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("total_pop"="value", "year_total_pop"="date")%>%
        dplyr::left_join(dplyr::select(wb_EN.POP.DNST,iso3c,date,value),
                         by=c("iso_code"="iso3c"))%>%  
        dplyr::rename("pop_density"="value", "year_pop_density"="date")%>%
        dplyr::left_join(dplyr::select(wb_SH.MED.PHYS.ZS,iso3c,date,value),
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("physicians_per_1000"="value", "year_physicians_per_1000"="date")%>%
        dplyr::left_join(dplyr::select(wb_SH.MED.BEDS.ZS,iso3c,date,value),
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("hosp_beds_per_1000"="value", "year_hosp_beds_per_1000"="date")%>%
        dplyr::left_join(dplyr::select(wb_EN.ATM.PM25.MC.M3,iso3c,date,value),
                         by=c("iso_code"="iso3c"))%>%
        dplyr::rename("air_pollution_year_pm25"="value", "year_air_pollution_year_pm25"="date")%>%
        dplyr::left_join(dplyr::select(wb_SP.DYN.LE00.IN,iso3c,date,value),
                             by=c("iso_code"="iso3c"))%>%
            dplyr::rename("life_exp"="value", "year_life_exp"="date")
```

#  COVID19 dataset indices

Taking into account that  `EN.ATM.PM25.MC.M3` matched almost perfectly with the source ow World Bank, we considered that the information from this [link](https://docs.google.com/spreadsheets/d/1eeg9dpIlP9jENJsp-cWY51Kw8fojpLnh6mhxORCTPL8/edit#gid=0) was reliable.

<br>

 - `dalys_asthma_normalized`: Years of healthy life lost to premature death and disability due to asthma. DALYs are the sum of years of life lost (YLLs) and years lived with disability (YLDs).
 - `dalys_lung_disease`= "Years of healthy life lost to premature death and disability due to lung disease. DALYs are the sum of years of life lost (YLLs) and years lived with disability (YLDs)."
 - `obesity_both_percent`=  Percentage of Obesity for Both Sexes.

<br>

```{r covid19_data1, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
google_covid19%>%
  dplyr::select(iso3,name_engli,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent)%>%
  dplyr::anti_join(coronavirus_iso3c_9, by=c("iso3"="iso_code"))%>%
        datatable(filter = 'top',colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 34: ', htmltools::em('Countries of COVID19 dataset that did not match with our Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
<br>

As seen in the Table above, most of these regions had a problematic status in geopolitical terms. Posteriorly, we analized if the merging with our datasets may generate missing data in any country.

<br>

```{r covid19_data2, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_9%>%
  dplyr::left_join(dplyr::select(google_covid19,iso3,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent), by=c("iso_code"="iso3"))%>%
  dplyr::mutate(obesity_both_percent=str_replace(obesity_both_percent, "%", ""),
                obesity_both_percent=as.numeric(obesity_both_percent))%>%
  dplyr::group_by(country) %>% 
  summarise_at(vars(dalys_asthma_normalized:obesity_both_percent),~sum(is.na(.))/n())%>%  
  dplyr::mutate(sumVar = rowSums(select(., .dots = all_of(c("dalys_asthma_normalized","dalys_lung_disease","obesity_both_percent")))))%>%
  dplyr::mutate_at(vars(dalys_asthma_normalized:obesity_both_percent),~scales::percent(.))%>%
  dplyr::filter(sumVar>0)%>%
  dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
        datatable(filter = 'top',
                  colnames = c('Country' =2,'Sum of Missing Data' = 3,'DALYs Asthma' = 4,'DALYs Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 35: ', htmltools::em('Countries with missing values in COVID19 dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, most of these regions had a problematic status in geopolitical terms. **That is why we merged the datasets anyway**.

<br>

```{r covid19_data3, echo=T, cache= T, paged.print=TRUE,eval=T, error=T}
coronavirus_iso3c_10<-
    coronavirus_iso3c_9%>%
      dplyr::left_join(dplyr::select(google_covid19,iso3,dalys_asthma_normalized,dalys_lung_disease, obesity_both_percent), by=c("iso_code"="iso3"))%>%
      dplyr::mutate(obesity_both_percent=str_replace(obesity_both_percent, "%", ""),
                    obesity_both_percent=as.numeric(obesity_both_percent))
```

<br>

# Causes of Death, OWID Data

```{r who_mortality1, echo=T, cache= T, paged.print=TRUE,eval=F}
#  WHO Mortality database (MDB)

#The deaths registered in national vital registration systems up to Dec 15 (obtained from [here](https://www.who.int/healthinfo/statistics/mortality_rawdata/en/)), with underlying cause of death as coded by the relevant national authority. More information on this [link](http://www.ccs.neu.edu/home/kathleen/classes/cs3200/WHODocumentation2015.pdf). We selected the maximum available year with information for each country.

#<br>
  
invisible(c("https://rdrr.io/github/eugejoh/WHOmortality/man/download_who.html"))
invisible(c("https://rdrr.io/github/eugejoh/WHOmortality/"))
invisible(c("https://www.rdocumentation.org/packages/heemod/versions/0.9.0/topics/who-mortality"))
#For instance, it would be useful to extract the number of deaths by country around 2016 (if I do not mistake on the year we are finally using) but only those attributed to respiratory infections (A.2 or A.2.2 and A.2.3)

invisible(c(key= "TdicjbOHEEs96ujLEseRyJmqJy0UotIq56pvg3+00/cYJCOdj+1xePAuK+yBx4lU")) 

#
invisible(c("http://svante.mit.edu/~mwli/Li_2019/Data_and_Analysis/Health/WHO/y0_oz_ICD10.R"))

library(WHOmortality)

data(dd_mort)
#List of ICD revision used � see Annex Table 2 below.
#Cause of death � For details consult Part 2 below or ICD publications

dd_mort[1:10,1]
#
country_code_who <-read.csv("https://raw.githubusercontent.com/dancingCamel/WHO-Mortality-Data-API/master/raw_data/country_codes.csv", header=T)
Morticd10_part1 <-read.csv("G:/Mi unidad/covid19/Morticd10_part1", header=T,skip=0)
Morticd10_part2 <- read.csv("G:/Mi unidad/covid19/Morticd10_part2", header=T,skip=0)

rbind(Morticd10_part1,Morticd10_part2)%>%
  dplyr::mutate_at(dplyr::vars(tidyselect::matches("Deaths[0-9]{,2}$|Pop|Lb")), as.numeric)%>%
  dplyr::mutate_at(dplyr::vars("Sex"), as.factor)%>%
  dplyr::mutate_at(dplyr::vars("Year"), as.integer)%>%
  dplyr::left_join(country_code_who, by=c("Country"="country"))%>%
  dplyr::select(Country, name,Admin1,SubDiv, Year, List, Cause, Sex, Frmat, IM_Frmat, Deaths1)%>%
  janitor::clean_names()%>%
  group_by(country)%>%
  dplyr::filter(year==max(year))%>%
  assign("Morticd10_total_std_col",.,envir=.GlobalEnv)

dd_icd10<-dd_icd10%>%
  dplyr::mutate(code=as.character(code))

pop <- read.csv("G:/Mi unidad/covid19/pop", header=T,skip=0)%>% janitor::clean_names()

Morticd10_total_std_col%>%
 dplyr::left_join(dd_icd10, by=c("cause"="code"))


We selected the following diseases: 
 - 1073= Influenza
 - 1074= Pneumonia
 - 1006= Other Tuberculosis
 - 1005= Respiratory Tuberculosis
 - 1010= Whooping Cough
 - 1020= HIV
 - 1075= Other accute lower respiratorio infections

#ICD-10 Code  Diagnoses
#Upper Respiratory Infections
#J00  Acute Nasopharyngitis (Common Cold)
#J01.90 Acute Sinusitis, Unspecified
#J02.0  Streptococcal Pharyngitis
#J02.9  Acute Pharyngitis, Unspecified
#J03.90 Acute Tonsillitis, Unspecified
#J06.9  Acute Upper Respiratory Infection, Unspecified
#J31.0  Chronic Rhinitis
#J32.9  Chronic Sinusitis, Unspecified
#R05  Cough

#Lower Respiratory Infections
#A37.90 Whooping Cough, Unspecified Species Without Pneumonia
#B97.4  Respiratory Syncytial Virus As The Cause Of Diseases Classified Elsewhere
#J18.9  Pneumonia, Unspecified Organism
#J20.9  Acute Bronchitis, Unspecified
#R06.02 Shortness Of Breath
#R06.89 Other Abnormalities Of Breathing
#R09.1  Pleurisy
#R76.11 Nonspecific Reaction To Tuberculin Skin Test Without Active Tuberculosis

Morticd10_total_std_col%>%
  dplyr::filter()

#data("eiu")
#eiu%>%
#    group_by(eiu_country)%>%
#    dplyr::filter(year==max(year))%>% #resulta que todos son 2018
#  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
#               caption = paste0("Table 27. Whole Dataset (maxmimum)"),
#               align =rep('c', 101)) %>%
#  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
#  kableExtra::add_footnote( c(paste("Note. ",nrow(coronavirus_iso3c_7),"observations")), 
#                            notation = "none") %>%
#  kableExtra::scroll_box(width = "100%", height = "375px")

```

<br>

We obtained the causes of death by country from an OWID repository (available in this [link](https://ourworldindata.org/causes-of-death)).

<br>

```{r who_mortality_owid, echo=T, cache= T, paged.print=TRUE,eval=T}

ann_no_deaths_by_cause<- tryCatch(
               {
                           read.csv("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/annual-number-of-deaths-by-cause.csv")%>%
          janitor::clean_names()%>%
          dplyr::select(entity, code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths)
               },
                   error = function(e){
                           read.csv("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/annual-number-of-deaths-by-cause.csv")%>%
        janitor::clean_names()%>%
        dplyr::select(entity, code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths)
                   }
             )

ann_no_deaths_by_cause%>%
    dplyr::anti_join(coronavirus_iso3c_10, by=c("code"="iso_code"))%>%
  dplyr::group_by(code,entity)%>%
  summarise(N=n(),min_year=min(year),max_year=max(year))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 36: ', htmltools::em('Countries of OWID Causes Of Death Dataset that did not match with our Dataset')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```

<br>

As seen in the Table above, many of these countries that did not match, correspond to aggregated territories or countries that do not exist at 2020, or are still in a complicated position in geopolitical terms.

<br>

```{r who_mortality_owid2, echo=T, cache= T, paged.print=TRUE,eval=T}
ann_no_deaths_by_cause <- 
    ann_no_deaths_by_cause%>%
    dplyr::group_by(code)%>%
     slice(1)%>%
        ungroup()

    coronavirus_iso3c_10%>%
    dplyr::left_join(dplyr::select(ann_no_deaths_by_cause,code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths), by=c("iso_code"="code"))%>%
    dplyr::rename("owid_gbd_year"="year")%>%
    dplyr::group_by(country,iso_code)%>%
    dplyr::filter(is.na(dalys_asthma_normalized))%>%
    summarise(N=n(),min_year=min(dates),max_year=max(dates))%>%
        datatable(filter = 'top',
                  #colnames = c('ISO 3-letter' =2,'Country' = 3,'Asthma' = 4,'Lung Disease' = 5,"Obesity" =6),
              caption = htmltools::tags$caption(
          style = 'caption-side: top; text-align: left;',
          'Table 37: ', htmltools::em('Countries of our dataset that did not matched with OWID Data')),
        options=list(
  initComplete = JS(
        "function(settings, json) {",
        "$(this.api().tables().body()).css({'font-size': '70%'});",
        "}")))
```
<br>

As seen in the Table above, some countries did not contained any information regarding causes of death.

<br>

```{r who_mortality_owid3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_11<-
    coronavirus_iso3c_10%>%
    dplyr::left_join(dplyr::select(ann_no_deaths_by_cause,code,year,lower_respiratory_infections_deaths,respiratory_diseases_deaths,diabetes_deaths), by=c("iso_code"="code"))%>%
    dplyr::rename("owid_gbd_year"="year")
```

## Life Expectancy at Age 60 (e60)

We incorporated the Life expectancy at age 60 (years) ([link](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/life-expectancy-at-age-60-(years))), as one of the prospect that WHO has available. We had to standardize the names of the following countries: Czechia, Venezuela, Bolivia, Macronesia, Moldova, Russia, North Macedonia, Tanzania, Congo, Sao Tome and Principe, Eswatini, Cabo Verde, Cote d Ivoire, Syria, Iran, Macao, North & South Korea, Brunei, Lao, Timor-Leste, Vietnam, and Guadeloupe.

<br>

```{r life_exp_60_1, echo=T, cache= T, paged.print=TRUE,eval=T}
# Life Expectancy at Age 60 (e60) 
WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES <-tryCatch(
    {
       readxl::read_excel("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES.xlsx", 
    skip = 16)%>%
  dplyr::select(3,5,7,`2015-2020`)
    },
    error = function(e){
 readxl::read_excel("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES.xlsx", 
    skip = 16)%>%
  dplyr::select(3,5,7,`2015-2020`)
    }
)
who_life_exp_60_both_sex<-
WPP2019_MORT_F13_1_LIFE_EXPECTANCY_60_BOTH_SEXES%>%
  left_join(select(index,country_name,`3166-1-alpha-3`), by=c("Region, subregion, country or area *"="country_name"))%>%
  dplyr::mutate(iso= 
                  dplyr::case_when(`Region, subregion, country or area *`=="Czechia"~"CZE",
                      `Region, subregion, country or area *`=="Venezuela (Bolivarian Republic of)"~"VEN",
                      `Region, subregion, country or area *`=="Bolivia (Plurinational State of)"~"BOL",
                      `Region, subregion, country or area *`=="Micronesia (Fed. States of)"~"FSM",
                      `Region, subregion, country or area *`=="Republic of Moldova"~"MDA",
                      `Region, subregion, country or area *`=="Russian Federation"~"RUS",
                      `Region, subregion, country or area *`=="North Macedonia"~"MKD",
                      `Region, subregion, country or area *`=="United Republic of Tanzania"~"TZA",
                      `Region, subregion, country or area *`=="Congo"~"COG",
                      `Region, subregion, country or area *`=="Sao Tome and Principe"~"STP",
                      `Region, subregion, country or area *`=="Eswatini"~"SWZ",
                      `Region, subregion, country or area *`=="Cabo Verde"~"CPV",
                      `Region, subregion, country or area *`=="Côte d'Ivoire"~"CIV",
                      `Region, subregion, country or area *`=="Syrian Arab Republic"~"SYR",
                      `Region, subregion, country or area *`=="Iran (Islamic Republic of)"~"IRN",
                      `Region, subregion, country or area *`=="China, Macao"~"MAC",
                      `Region, subregion, country or area *`=="Republic of Korea Dem. People's"~"PRK",
                      `Region, subregion, country or area *`=="Republic of Korea"~"KOR",
                      `Region, subregion, country or area *`=="Brunei Darussalam"~"BRN",
                      `Region, subregion, country or area *`=="Lao People's Democratic Republic"~"LAO",
                      `Region, subregion, country or area *`=="Timor-Leste"~"TLS",
                      `Region, subregion, country or area *`=="Viet Nam"~"VNM",
                      `Region, subregion, country or area *`=="Guadeloupe"~"GLP",
                            TRUE~as.character(`3166-1-alpha-3`)))%>%
  distinct(iso,.keep_all=T)
```

```{r life_exp_60_2, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_11%>%
    dplyr::left_join(dplyr::select(who_life_exp_60_both_sex,iso, `2015-2020`),
                     by=c("iso_code"="iso"))%>%
    dplyr::filter(is.na(`2015-2020`))%>%
    dplyr::group_by(iso_code,country)%>%
    summarise(N=n(), last_date=max(dates),first_date=min(dates))%>%
    dplyr::filter(N>0)%>%
    datatable(filter = 'top', colnames = c('ISO 3-letter' =2,'Country' = 3,'Data Points' = 4),
              caption = htmltools::tags$caption(
        style = 'caption-side: top; text-align: left;',
        'Table 38: ', htmltools::em('Countries of our dataset that did not matched with  dataset in Life-Expectancy at 60')),
      options=list(
initComplete = JS(
      "function(settings, json) {",
      "$(this.api().tables().body()).css({'font-size': '80%'});",
      "}")))
```

<br>

As seen in the Table above, most of these countries did have a complicated position in geopolitical terms. **That is why we matched the data anyways.**

<br>

```{r life_exp_60_3, echo=T, cache= T, paged.print=TRUE,eval=T}
coronavirus_iso3c_12<-
          coronavirus_iso3c_11%>%
              dplyr::left_join(dplyr::select(who_life_exp_60_both_sex,iso, `2015-2020`),
                               by=c("iso_code"="iso"))%>%
            dplyr::rename("life_exp_15_20"="2015-2020")%>%
            dplyr::group_by(iso_code)%>%
            dplyr::mutate(ndays_zero=row_number()+52)%>%
            ungroup()
```

# Exploration

## Missing values By Countries

<br>

```{r miss_by_cntry, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
col_names_df<-coronavirus_iso3c_12%>%
    dplyr::select(population:life_exp_15_20)%>% 
    names()

coronavirus_iso3c_12%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:life_exp_15_20),~sum(is.na(.))/n())%>%
      dplyr::mutate(sumVar = rowSums(select(., .dots = all_of(col_names_df))))%>%
      dplyr::mutate_at(vars(population:eiu_2019_overall_score),~scales::percent(.))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 39. Percentage of Missing data in the Different Time Points By Country"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote(c(paste("Note. ",nrow(coronavirus_iso3c_12),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
``` 

```{r miss_total, echo=T, cache= T, paged.print=TRUE,eval=F, warning=F, error=T}
myvars <- names(coronavirus_iso3c_12) %in% c("ndays") 

VIM::aggr(coronavirus_iso3c_12[!myvars], col=c('navyblue','yellow'),
                    numbers=F, sortVars=TRUE,
                    labels=names(coronavirus_iso3c_12[!myvars]), cex.axis=.5,
                    gap=3, ylab=c("Missing data","Pattern"))
``` 

# Collapse Information into Monthly Data

We collapsed the information into monthly basis, by selecting the maximum number by each month on time variant variables. Also we deleted some variables related to NOAA (`noaa_station`, `noaa_distance`,`average_temperature`, `minimum_temperature`,`maximum_temperature` & `rainfall`) and some of the World Bank Datasets, due to a great amount of missing values (`handwashing_facilities` & `extreme_poverty`).

<br>

```{r collapse, message=F,eval=T, error=T, fig.show = 'hide', warning=F}
coronavirus_iso3c_12%>% 
  dplyr::group_by(iso_code)%>%
  #dplyr::mutate_at(.vars = vars(cases_deaths, cases,ndays_zero,ndays,dates),
  #          .funs = funs(`mth`=max(.,na.rm=T)))%>%
  dplyr::ungroup()%>%
#  dplyr::distinct(iso_code,date_month,.keep_all=T)%>%
  dplyr::filter(ndays %in% c(1,30,60,90))%>%
  dplyr::select(-noaa_station, -noaa_distance,-average_temperature, -minimum_temperature,- maximum_temperature,-rainfall,-handwashing_facilities)%>%
  dplyr::group_by(iso_code)%>%
  dplyr::summarise_all(n_distinct)%>%
  dplyr::filter_at(vars(population:life_exp_15_20), all_vars(.>=2))%>% nrow()
  
coronavirus_iso3c_12%>% 
  dplyr::group_by(iso_code)%>%
  #dplyr::mutate_at(.vars = vars(cases_deaths, cases,ndays_zero,ndays,stringency_ind_oxf),
  #         .funs = funs(`mth`=max(.)))%>%
  #dplyr::mutate(dates=max(dates))%>%
  dplyr::filter(ndays %in% c(1,30,60,90))%>%
  dplyr::ungroup()%>%
  #dplyr::distinct(iso_code,date_month,.keep_all=T)%>%
  dplyr::select(-noaa_station, -noaa_distance,-average_temperature, -minimum_temperature,- maximum_temperature,-rainfall,-handwashing_facilities,-extreme_poverty)%>%
  dplyr::select(-male_smokers, -female_smokers, -gci_2018_rank, -year_hosp_beds_per_1000, -hosp_beds_per_1000,
  -qualification, -eiu_2019_rank, -eiu_2019_overall_score, -hospital_beds_per_thousand, 
  -decade_temp, -decade_prec, -year_physicians_per_1000, -physicians_per_1000, -aged_65_older, -cpi_score_2019)%>%
assign("every_30_days_dataset",.,envir=.GlobalEnv)
  #assign("monthly_dataset",.,envir=.GlobalEnv)
```
<br>

We analyzed the variables with missing data. **We must determine the tolerable number of missing values**. If not, we may ignore that variable.

<br>

```{r miss_by_cntry2_col, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
col_names_df<-every_30_days_dataset%>% #monthly_dataset%>%
    dplyr::select(population:life_exp_15_20)%>% 
    names()

#monthly_dataset%>%
every_30_days_dataset%>%
    dplyr::group_by(country) %>% 
    summarise_at(vars(population:life_exp_15_20),~sum(is.na(.))/n())%>%
    dplyr::mutate(sumVar = rowSums(select(., .dots = all_of(col_names_df))))%>%
    summarise_at(vars(population:life_exp_15_20),~sum(as.numeric(.)))%>% t()%>% data.frame()%>%
  dplyr::arrange(desc(.))%>%
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 40. Variables with no. of countries with missing data"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote(c(paste("Note. ",nrow(every_30_days_dataset),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")
```


```{r miss_scenarios, echo=T, cache= T, paged.print=TRUE,eval=F, warning=F, error=T}
#monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
every_30_days_dataset[,!(names(every_30_days_dataset) %in% drops)]%>%
  na.omit()%>%
    distinct(iso_code)%>%
    nrow()


df<-data.frame(n=0)
for_imp<- c("aged_70_older", "gdp_per_capita", "year_life_exp", "life_exp", "life_exp_15_20",
"median_age", "year_air_pollution_year_pm25", "air_pollution_year_pm25", "dalys_lung_disease", "hdi_rank_2018",
"hdi_index_2018", "year_pop_density", "pop_density", "lower_respiratory_infections_deaths", "respiratory_diseases_deaths", "diabetes_deaths","obesity_both_percent","population_density","diabetes_prevalence",
"month_temp_16","month_rainfall_mm_16","year_total_pop","total_pop","owid_gbd_year","dalys_asthma_normalized","monthly_temp","monthly_prec","life_expectancy","population")
for (i in 1:length(for_imp)){
  drops <- c(c("ndays", "cases_deaths","cases"),for_imp[i])
monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
  na.omit()%>%
    distinct(iso_code)%>%
    nrow()->df2
df<-rbind(df,df2)
}
df<-df[2:length(for_imp),]
data.frame(cbind(for_imp,df))%>% arrange(desc(df))
data.frame(cbind(for_imp,df))%>% arrange(desc(df))

invisible(
    monthly_dataset[,!(names(monthly_dataset) %in% drops)]%>%
          na.omit()%>%
          distinct(iso_code)%>%
          nrow()
)
```

```{r miss_by_cntry2, echo=T, cache= T, paged.print=TRUE,eval=T, warning=F, error=T}
#col_names_df<-monthly_dataset%>%
col_names_df<-every_30_days_dataset%>%
    dplyr::select(population:life_exp_15_20)%>% 
    names()

paste("One variable that has many missing values: stringency_ind_oxf ",
every_30_days_dataset%>%
      #monthly_dataset%>%
    dplyr::group_by(country) %>% 
    summarise_at(vars(population:life_exp_15_20),~sum(is.na(.))/n())%>%
    dplyr::mutate(sumVar = rowSums(select(., .dots = all_of(col_names_df))))%>%
    summarise_at(vars(population:life_exp_15_20),~sum(as.numeric(.)))%>% t()%>% data.frame()%>%
  dplyr::filter(.>=15)%>% round(2),
"%")
#monthly_dataset%>%
every_30_days_dataset%>%
  dplyr::group_by(country) %>% 
    summarise_at(vars(population:life_exp_15_20),~sum(is.na(.))/n())%>%
      dplyr::mutate(sumVar = rowSums(select(., .dots = all_of(col_names_df))))%>%
      dplyr::mutate_at(vars(population:life_exp_15_20),~scales::percent(.))%>%
    dplyr::filter(sumVar>0)%>%
    dplyr::arrange(desc(sumVar))%>%
  dplyr::rename("sum_of_miss"="sumVar")%>%
  dplyr::select(country,sum_of_miss, everything())%>%
  #assign("monthly_dataset_miss",.,envir=.GlobalEnv)%>%
  assign("very_30_days_dataset_miss",.,envir=.GlobalEnv)%>%  
  knitr::kable(.,format = "html", format.args = list(decimal.mark = ".", big.mark = ","),
               caption = paste0("Table 41. Percentage of Missing data in the Different Time Points By Country (monthly Data)"),
               align =rep('c', 101)) %>%
  kableExtra::kable_styling(bootstrap_options = c("striped", "hover"),font_size = 8) %>%
  kableExtra::add_footnote(c(paste("Note. ",nrow(every_30_days_dataset),"observations")), 
                            notation = "none") %>%
  kableExtra::scroll_box(width = "100%", height = "375px")

#excluded_countries<-as.character(unlist(distinct(monthly_dataset_miss,country)))
excluded_countries<-as.character(unlist(distinct(very_30_days_dataset_miss,country)))

#monthly_dataset%>%
every_30_days_dataset%>%
  dplyr::filter(!country %in% excluded_countries)%>%
  dplyr::mutate(rate_lo_resp_inf_dth=lower_respiratory_infections_deaths/100000)%>%
  dplyr::mutate(prop_lo_resp_inf_dth=lower_respiratory_infections_deaths/population)%>%
  dplyr::mutate(life_exp_15_20=as.numeric(life_exp_15_20))%>%
  ungroup()%>%
  #assign("monthly_dataset_comp_wise",.,envir=.GlobalEnv)
  assign("every_30_days_dataset_comp_wise",.,envir=.GlobalEnv)
#105 paises.
#gci_2018_rank	year_hosp_beds_per_1000	hosp_beds_per_1000
``` 

<br>

```{r miss_by_cntry_final_prueba, echo=T, cache= T, paged.print=TRUE,eval=F, warning=F, error=T}
 drops2 <- c(c("ndays", "cases_deaths","cases"))
 #monthly_dataset_comp_wise[,!(names(monthly_dataset_comp_wise) %in% drops2)]%>%
  every_30_days_dataset_comp_wise[,!(names(every_30_days_dataset_comp_wise) %in% drops2)]%>%
   na.omit()%>%
    distinct(iso_code)
```

<br>

Considering the Table above, we decided to eliminate `r nrow(distinct(very_30_days_dataset_miss,country))` countries in the dataset that had missing values on variables of interest. This let us with `r nrow(distinct(every_30_days_dataset_comp_wise,country))` countries.

<br>

```{r worldmap, echo=T, eval=T,fig.align='center', fig.pos='H', message=FALSE, warning=FALSE,interval=1}
library(cshapes)      # for historic country boundaries.  Load this early as it calls plyr which clashes with dplyr
library(ggplot2)
library(scales)
library(RColorBrewer) # for brewer.pal(...)
library(openxlsx)
library(countrycode)  # for ISO country codes
library(ggthemes)     # for theme_map
library(dplyr)
library(tidyr)        # for reshaping the UTIP EHII data

      # thanks to cshapes project for historical countries: http://nils.weidmann.ws/projects/cshapes.html
      
      world2 <- cshp()      
      
      # convert the shapefile into a data frame for use with ggplot2,
      # and join it to the ISO3 country codes for later use:
      world_map <- fortify(world2) %>%
        left_join(data_frame(id = rownames(world2@data), iso3c = world2@data$ISO1AL3)) 
      
      # filter the data to those five years and take the average
      # of any years of data we have for each country in those 
      # years:
    #   the_data <- monthly_dataset_comp_wise %>%
    #     group_by(iso3c) %>%
    #     dplyr::summarise(Gini = mean(Gini, na.rm = TRUE)) %>%
    #     filter(!is.na(Gini))
      
      # these next messages and printing are checks to see which  monthly_dataset_comp_wise
      # if any countries we are missing out on drawing due to
      # data mismatches:
      #all_gini_countries <- unique(monthly_dataset_comp_wise$iso_code)
      all_gini_countries <- unique(every_30_days_dataset_comp_wise$iso_code)
      all_map_countries <- unique(world_map$iso3c)
      
      missed1 <- sum(!all_map_countries %in% all_gini_countries)
      missed2 <- sum(!all_gini_countries %in% all_map_countries)
      missed3 <- sum(is.na(world2@data$ISO1AL3))
      message(paste(missed1, "countries in map but no Gini", i))
      message(paste(missed2, "countries have a Gini but no map in ", i))
      message(paste(missed3, "countries have no iso3c code in", i))
      
      # print the countries that had data which wasn't mapped
      print(all_gini_countries[!all_gini_countries %in% all_map_countries])
      
      # Puerto Rico, Macau and Hong Kong often are missing from the map
      # DDR has data 1970 to 1988 and won't be shown
      # ERI has data from 1963 despite not really being a country until 1993
      #     If we use 1995 maps it will show up but we have to drop DDR.
      # PNG has data pre its independence in 1975; need a map from later than
      #     1975 for its borders to show up.
      
      # Back to the main routine needed for drawing the map.         
      # Merge the Gini coefficient data with the world map
      #the_data <- right_join(monthly_dataset_comp_wise, 
      the_data <- right_join(every_30_days_dataset_comp_wise, 
                             world_map, by = c("iso_code"="iso3c"))
      fechas_distintas<- length(unique(the_data$ndays))-1
      # Draw the map
 ggplot(the_data) +
        aes(x = long, y = lat, group = group, fill = cases_deaths) +
        geom_polygon(colour = "grey20", size = 0.3) +
        theme_map(base_size = 10, base_family = "myfont") +
        coord_equal() +
        #scale_y_continuous(labels = unit_format(unit = "M", scale = 1e-6))+
        scale_fill_gradientn(colours = brewer.pal(6, "Reds"), #na.value = "white",limits = limits, 
                             trans=log10_trans()) +
        theme(legend.position = c(0, 0)) +
        labs(fill = "Deaths(MM)",
             caption = "@ags") +
        theme(legend.title.align = 0.5)+
        #transition_manual(dates)+
        transition_manual(ndays)+
        theme(plot.caption = element_text(face = "italic",size=9))+
        ease_aes("linear")+
        enter_grow() +
        enter_fade()+
        ggtitle("Deaths attributed to COVID19 over different days since the first case: {frame}")+
        labs(caption= "Note. Each time frame correspond to the last day of the month since 01(=1),30(=2), 60(=3), and 90(=4)")
    # Combine all the frames into a single animated GIF, using ImageMagick
    # note since upgrade to v7 ImageMagick uses magick not convert, which makes
    # things much easier for Windows users (no conflict with Windows convert, which
    # does something completely different)
 #dplyr::filter(ndays %in% c(1,30,60,90))%>%
```

## Hetcors

We generated a matrix of heterogeneous correlations, to get an idea of the collinearity of variables.

<br>

```{r hetcor, echo=T, cache= T, paged.print=TRUE,eval=T, error=T, fig.cap="Figure 5.Heterogeneous Correlation Matrix"}
require(polycor)

#monthly_dataset_comp_wise_dt<-monthly_dataset_comp_wise%>% dplyr::select_if(is.numeric)%>% dplyr::select(-stringency_ind_oxf,-owid_gbd_year)%>% dplyr::select(-ends_with("mth")) %>% data.frame()

every_30_days_dataset_comp_wise_dt<-every_30_days_dataset_comp_wise%>% dplyr::select_if(is.numeric)%>% dplyr::select(-stringency_ind_oxf,-owid_gbd_year)%>% dplyr::select(-ends_with("mth")) %>% data.frame()


#Computes a heterogenous correlation matrix, consisting of Pearson product-moment correlations between numeric variables, polyserial correlations between numeric and ordinal variables, and polychoric correlations between 
hetcor_mat<-hetcor(every_30_days_dataset_comp_wise_dt, ML = T, std.err = T, use="complete.obs", bins=4, pd=TRUE)

#mix_cor<- psych::mixedCor(data=monthly_dataset_comp_wise_dt,
          #c=2:20, 
         #p=1, 
         #d=21:27, c(")
#         smooth=TRUE,
#         correct=.5,
#         global=TRUE,
#         ncat=8,
#         use="pairwise",
#         method="kendall",
#         weight=NULL)

# Getting the correlation matrix of the dataset.
# mix_cor$rho

ggcorrplot::ggcorrplot(hetcor_mat$correlations,
          ggtheme = ggplot2::theme_gray,
          colors = c("#E46726", "white", "#6D9EC1"), tl.cex=7) 
#owid_covid_data
#iso_code
#location

#land_area_skm
```
```{r glmulti, dpi = 96, message=F, fig.cap="Figure 10.Variable Importance", error=T, eval=F, fig.show = 'hide'}


drops3 <- c(c("country", "iso_code", "dates", "date_month", "ndays", "cases_deaths","cases","cases_deaths_mth","cases_mth","ndays_zero_mth","ndays_mth", "rate_lo_resp_inf_dth","lower_respiratory_infections_deaths"))
library(glmulti)

res <- glm(prop_lo_resp_inf_dth ~ total_pop+ pop_density+ hdi_rank_2018+ life_expectancy+diabetes_prevalence+gdp_per_capita+aged_70_older+dalys_asthma_normalized, 
               data=monthly_dataset_comp_wise[,!(names(monthly_dataset_comp_wise) %in% drops3)],
               family = "binomial")
               
plot(res)
##########################################################################################
##################DEBIESE INCORPORAR EL TIPO DE PLAN!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
##########################################################################################
```

```{r did, dpi = 96, message=F, error=T, eval=F, fig.show = 'hide'}

```

<br>

Finally, we transformed the dataset into a wide format, with the dates 1, 30, 60, and 90. China had missing data in dates in the day 1 and 30, while Tajikistan and Lesotho had missing information in the days 60 and 90. For China, we replaced the values at day 30 (2019-12-31), with data from WHO (total cases= 27, total deaths=0).

<br>

```{r codebook_prep, echo=T, cache=T, paged.print=TRUE,eval=T, warning=F}

#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#
######3.0.Libro de códigos#####
#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#:#

#every_30_days_dataset_comp_wise
#monthly_dataset_comp_wise
codebook_data<-every_30_days_dataset_comp_wise%>%
                dplyr::rename("low_resp_inf_dths"="lower_respiratory_infections_deaths")%>%
                tidyr::pivot_wider(names_from = ndays, 
                                   names_sep="_",
                                   values_from = c(dates, date_month, cases, cases_deaths, ndays_zero, stringency_ind_oxf, monthly_temp, monthly_prec,
month_temp_16, month_rainfall_mm_16,month_temp_agg97_06,month_temp_agg07_16,month_rain_agg97_06,month_rain_agg07_16))%>%
  dplyr::group_by(iso_code)%>%
  dplyr::mutate_at(vars(dates_1:month_rain_agg07_16_90),~max(.,na.rm=T))%>%
  #dplyr::mutate_at(vars(date_month_1 :date_month_90),~max(.,na.rm=T))%>%
  dplyr::slice(1)%>%
  #C:\Users\CISS Fondecyt\Dropbox\Covid-19_2020\Article_SecondManuscript\LT Environmental analysis\Databases\2020-08-04 Revision on China0s missing values.docx
  dplyr::mutate(cases_1=ifelse(iso_code=="CHN",1,cases_1), #no estoy seguro, nadie lo está, pero bueno.
                cases_30=ifelse(iso_code=="CHN",27,cases_30))%>%
  dplyr::mutate(cases_deaths_1=ifelse(iso_code=="CHN",0,cases_deaths_1), #no estoy seguro, nadie lo está, pero bueno.
                cases_deaths_30= ifelse(iso_code=="CHN",0,cases_deaths_30))%>%
  dplyr::mutate(dates_1=ifelse(iso_code=="CHN",as.Date("2019-12-01"),dates_1),
                dates_30= ifelse(iso_code=="CHN",as.Date("2019-12-30"),dates_30))%>%
  dplyr::mutate(date_month_1=ifelse(iso_code=="CHN","nov",date_month_1),
                date_month_30= ifelse(iso_code=="CHN","dec",date_month_30))%>%
  dplyr::mutate(ndays_zero_1=ifelse(iso_code=="CHN",1,ndays_zero_1),
                ndays_zero_30= ifelse(iso_code=="CHN",30,ndays_zero_30))%>%
  dplyr::mutate(monthly_temp_1=ifelse(iso_code=="CHN",0.4797562,monthly_temp_1),
                monthly_temp_30= ifelse(iso_code=="CHN",6.674736,monthly_temp_30))%>%
    dplyr::mutate(monthly_prec_1=ifelse(iso_code=="CHN",16.94781,monthly_prec_1),
                monthly_prec_30= ifelse(iso_code=="CHN",9.502951,monthly_prec_30))%>%
  dplyr::mutate(month_temp_16_1=ifelse(iso_code=="CHN",0.36,month_temp_16_1),
                month_temp_16_30= ifelse(iso_code=="CHN",3.92,month_temp_16_30))%>%
  dplyr::mutate(month_rainfall_mm_16_1=ifelse(iso_code=="CHN",26.6,month_rainfall_mm_16_1),
                month_rainfall_mm_16_30= ifelse(iso_code=="CHN",10.2,month_rainfall_mm_16_30))%>%
  dplyr::mutate(month_temp_agg97_06_1=ifelse(iso_code=="CHN",month_temp_agg97_06_60,month_temp_agg97_06_1),
                month_temp_agg97_06_30= ifelse(iso_code=="CHN",month_temp_agg97_06_60,month_temp_agg97_06_30))%>%
  dplyr::mutate(month_temp_agg07_16_1=ifelse(iso_code=="CHN",month_temp_agg07_16_60,month_temp_agg07_16_1),
                month_temp_agg07_16_30= ifelse(iso_code=="CHN",month_temp_agg07_16_60,month_temp_agg07_16_30))%>%
  dplyr::mutate(month_rain_agg97_06_1=ifelse(iso_code=="CHN",month_rain_agg97_06_60,month_rain_agg97_06_1),
                month_rain_agg97_06_30= ifelse(iso_code=="CHN",month_rain_agg97_06_60,month_rain_agg97_06_30))%>%
  dplyr::mutate(month_rain_agg07_16_1=ifelse(iso_code=="CHN",month_rain_agg07_16_60,month_rain_agg07_16_1),
                month_rain_agg07_16_30= ifelse(iso_code=="CHN",month_rain_agg07_16_60,month_rain_agg07_16_30))%>%
  ungroup()
#codebook_data%>% dplyr::select(monthly_temp_1,monthly_temp_30,monthly_prec_1,monthly_prec_30,month_temp_16_1,month_temp_16_30,month_rainfall_mm_16_1,month_rainfall_mm_16_30)%>% summary()
#codebook_data%>% dplyr::select(monthly_temp_1,monthly_temp_30,monthly_prec_1,monthly_prec_30,month_temp_16_1,month_temp_16_30,month_rainfall_mm_16_1,month_rainfall_mm_16_30)%>% View()
#dplyr::filter(iso3=="CHN"
  
codebook::metadata(codebook_data)$name <- "Join of Datasets for COVID"
codebook::metadata(codebook_data)$description <- "Owid data is available here (https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-data-codebook.md); The reported weather station refers to the nearest station which provides temperature measurements, but rainfall and snowfall may come from a different nearby weather station. In all cases, only weather stations which are at most 300km from the location coordinates are considered."

codebook::var_label(codebook_data) <- list(
  country = 'Country Name (OWID)',
  iso_code = '3-letter-ISO Code (OWID)',
  
  #dates = 'Date (Date format) (JHU)',
  #date_month = '3-char Month of Date (Character) (JHU)',
  #cases = 'No. of Confirmed Cases (JHU)',
  #cases_deaths = 'No. of Confirmed Deaths (JHU)',
  
  #ndays = 'Days since the first Confirmed Case by Country (JHU)',
  #ndays_zero = 'Days since the first Confirmed Case (JHU)',
  text = 'Summary of Information Regarding Cases and ID of the Country',
  
  continent = 'Continent of the Country (OWID)',
  population = 'Total Pop. (GAPMINDER, HYDE & UN by OWID)',
  population_density = 'No. people/land area, in km2 (2017) (WB in OWID)',
  median_age = 'Median age of the population, UN projection for 2020 from 2017 (UN in OWID)',
  #aged_65_older = 'Share of the population that is >=65 yrs, most recent year available (WB Dev Ind in OWID)',
  aged_70_older = 'Share of the population that is >=65 yrs, most recent year in 2015 (WB Dev Ind in OWID)',
  gdp_per_capita = 'Gross domestic product at purchasing power parity (constant 2011 international dollars), most recent year available (WB Dev Ind)',
  #extreme_poverty = 'Share of the population living in extreme poverty, most recent year available since 2010 (WB Dev Ind in OWID)',
  #cvd_death_rate = 'Death rate from cardiovascular disease in 2017 (GBD 2017 in OWID)',
  diabetes_prevalence = 'Diabetes prevalence (% of population aged 20 to 79) in 2017 (WB Dev Ind in OWID)',
  #female_smokers = 'Share of women who smoke, most recent year available	(WB Dev Ind in OWID)',
  #male_smokers = 'Share of men who smoke, most recent year available (WB Dev Ind in OWID)',
  #handwashing_facilities = 'Share of the population with basic handwashing facilities on premises, most recent year available	(UN Statistics in OWID)',
  #hospital_beds_per_thousand = 'Hospital beds per 1,000 people, most recent year available since 2010 (OECD, WB, Eurostat in OWID)',
  life_expectancy = 'Life expectancy at birth in 2019 (UN in OWID)',
  
  #stringency_ind_oxf = 'Government Response Stringency Index (OXF)',
  
  #monthly_temp = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 (rWBclimate)',
  #monthly_prec = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 (rWBclimate)',
  #decade_temp = 'Decadanal avg. temperature (celsius) at 2010 (rWBclimate)',
  #decade_prec = 'Decadanal avg. precipitation (mm) at 2010 (rWBclimate)',
  
  #month_temp_16 = 'Avg. Monthly Temperature (celsius) in 2016 (CCKP)',
  #month_rainfall_mm_16 = 'Avg. Monthly Rain (Millimiters) in 2016 (CCKP)', 
  
  #noaa_station = "Identifier for the weather station (NOAA)",
  ##noaa_distance = "Distance between the location coordinates and the weather station	(NOAA)",
  #average_temperature = "Recorded hourly average temperature	(NOAA)",
  #minimum_temperature = "Recorded hourly minimum temperature	(NOAA)",
  #maximum_temperature = "Recorded hourly maximum temperature	(NOAA)",
  #rainfall = "Rainfall during the entire day	(NOAA)",
  
  #cpi_score_2019 =  "Corruption Perceptions Index (0-100) (Transparency Int)",
  
  hdi_rank_2018 =  "Human Development Ranking 2018 (UN)",
  hdi_index_2018 =  "Human Development Index 2018 (0-100) (UN)",
  
  #gci_2018_rank = 'Good Country Index Ranking in 2018 (GCI)',
    
  #qualification = 'Classification Provided in 2019 (EIU)',
  #eiu_2019_rank = 'Democracy Index Ranking in 2019 (EIU)',
  #eiu_2019_overall_score = 'Overall Score in 2019 (EIU)',
  
  year_total_pop = 'Year of the available Population Number (WB)',
  total_pop = 'Population Number (WB)',
  year_pop_density = 'Year of the available Population Density (WB)',
  pop_density = 'Population Number (WB)',
  #year_physicians_per_1000 = 'Year of the available number of Physicians (per 1,000 people) (WB)',
  #physicians_per_1000 = 'Physicians (per 1,000 people) (WB)',
  #year_hosp_beds_per_1000 = 'Year of the available number of Hospital beds (per 1,000 people) (WB)',
  #hosp_beds_per_1000 = 'Hospital beds (per 1,000 people) (WB)',
  year_air_pollution_year_pm25 = 'Year of available Air pollution, mean annual exposure (mm per m^3) for GBD17 (WB)',
  air_pollution_year_pm25 = 'Air pollution, mean annual exposure (mm per m^3) for GBD17 (WB)',
  year_life_exp = 'Year of the available number of Life expectancy at birth (WB)',
  life_exp = 'Life expectancy at birth (WB)',
  
  life_exp_15_20 = 'Expected Life Expectancy at Age 60 (WHO)',

  dalys_asthma_normalized = 'YLLs to premature death and disabillity due to asthma (GBD in COVID19 spreadsheet)',
  dalys_lung_disease = 'YLLs to premature death and disabillity due to lung disease (GBD in COVID19 spreadsheet)',
  obesity_both_percent =  'Percentage of Obesity for Both Sexes (GBD in COVID19 spreadsheet)',
  
  owid_gbd_year = 'Year of the available Data of Global Burden of Disease (GBD in OWID)',
  low_resp_inf_dths = 'Deaths due to Lower Respiratory Infections (GBD in OWID)',
  respiratory_diseases_deaths = 'Deaths due to Respiratory Diseases (GBD in OWID)',
  diabetes_deaths = 'Deaths due to Diabetes (GBD in OWID)',
  life_exp_15_20 = 'Estimated Life expectancy at age 60 (2015-2020) (WHO)',
   
  #cases_deaths_mth = 'Max. no. of Confirmed Cases in the Month (JHU)',
  #cases_mth = 'Max. no. of Confirmed Deaths in the Month(JHU)',
  #ndays_zero_mth = 'Max. no. of days since the first Confirmed Case (JHU)',
  #ndays_mth = 'Max no. of days since the first Confirmed Case by Country (JHU)',
  rate_lo_resp_inf_dth = 'Deaths due to Lower Respiratory Infections per 100M (GBD in OWID)',
  prop_lo_resp_inf_dth = 'Prop. of Deaths due to Lower Respiratory Infections of the Total Pop (GBD in OWID)',
  #stringency_ind_oxf_mth = 'Government Response Stringency Index in the Month (OXF)'
  dates_1 = 'Date (Date format) at 0 day(s) since first case (JHU)',
  date_month_1 = '3-char Month of Date (Character) at 0 day(s) since first case (JHU)',
  cases_1 = 'No. of Confirmed Deaths at 0 day(s) since first case (JHU)',
  cases_deaths_1 = 'No. of Confirmed Deaths at 0 day(s) since first case (JHU)',
  ndays_zero_1 = 'No. of Days since the first case worldwide at 0 day(s) since first case',
  stringency_ind_oxf_1 = 'Government Response Stringency Index at 0 day(s) since first case (OXF)',
  monthly_temp_1 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 0 day(s) since first case (rWBclimate)',
  monthly_prec_1 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 0 day(s) since first case (rWBclimate)',
  month_temp_16_1 = 'Avg. Monthly Temperature (celsius) in 2016 at 0 day(s) since first case (CCKP)',
  month_rainfall_mm_16_1 =  'Avg. Monthly Rain (Millimiters) in 2016 at 0 day(s) since first case (CCKP)', 
  #dates = 'Date (Date format) (JHU)',
  #date_month = '3-char Month of Date (Character) (JHU)',
  #cases = 'No. of Confirmed Cases (JHU)',
  #cases_deaths = 'No. of Confirmed Deaths (JHU)',
    dates_30 = 'Date (Date format) at 29 day(s) since first case (JHU)',
  date_month_30 = '3-char Month of Date (Character) at 29 day(s) since first case (JHU)',
  cases_30 = 'No. of Confirmed Deaths at 29 day(s) since first case (JHU)',
  cases_deaths_30 = 'No. of Confirmed Deaths at 29 day(s) since first case (JHU)',
  ndays_zero_30 = 'No. of Days since the first case worldwide at 29 day(s) since first case',
  stringency_ind_oxf_30 = 'Government Response Stringency Index at 29 day(s) since first case (OXF)',
  monthly_temp_30 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 29 day(s) since first case (rWBclimate)',
  monthly_prec_30 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 29 day(s) since first case (rWBclimate)',
  month_temp_16_30 = 'Avg. Monthly Temperature (celsius) in 2016 at 29 day(s) since first case (CCKP)',
  month_rainfall_mm_16_30 =  'Avg. Monthly Rain (Millimiters) in 2016 at 29 day(s) since first case (CCKP)', 
  
    dates_60 = 'Date (Date format) at 59 day(s) since first case (JHU)',
  date_month_60 = '3-char Month of Date (Character) at 59 day(s) since first case (JHU)',
  cases_60 = 'No. of Confirmed Deaths at 59 day(s) since first case (JHU)',
  cases_deaths_60 = 'No. of Confirmed Deaths at 59 day(s) since first case (JHU)',
  ndays_zero_60 = 'No. of Days since the first case worldwide at 59 day(s) since first case',
  stringency_ind_oxf_60 = 'Government Response Stringency Index at 59 day(s) since first case (OXF)',
  monthly_temp_60 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 59 day(s) since first case (rWBclimate)',
  monthly_prec_60 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 59 day(s) since first case (rWBclimate)',
  month_temp_16_60 = 'Avg. Monthly Temperature (celsius) in 2016 at 59 day(s) since first case (CCKP)',
  month_rainfall_mm_16_60 =  'Avg. Monthly Rain (Millimiters) in 2016 at 59 day(s) since first case (CCKP)', 
  
    dates_90 = 'Date (Date format) at 89 day(s) since first case (JHU)',
  date_month_90 = '3-char Month of Date (Character) at 89 day(s) since first case (JHU)',
  cases_90 = 'No. of Confirmed Deaths at 89 day(s) since first case (JHU)',
  cases_deaths_90 = 'No. of Confirmed Deaths at 89 day(s) since first case (JHU)',
  ndays_zero_90 = 'No. of Days since the first case worldwide at 89 day(s) since first case',
  stringency_ind_oxf_90 = 'Government Response Stringency Index at 89 day(s) since first case (OXF)',
  monthly_temp_90 = 'Monthly avg. temperature (celsius) for all 12m from 1901 to 2009 at 89 day(s) since first case (rWBclimate)',
  monthly_prec_90 = 'Monthly avg. precipitation (mm) for all 12m from 1901 to 2009 at 89 day(s) since first case (rWBclimate)',
  month_temp_16_90 = 'Avg. Monthly Temperature (celsius) in 2016 at 89 day(s) since first case (CCKP)',
  month_rainfall_mm_16_90 =  'Avg. Monthly Rain (Millimiters) in 2016 at 89 day(s) since first case (CCKP)',
  month_rain_agg97_06_1 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 0 day(s) since first case (CCKP)',
  month_rain_agg97_06_30 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 29 day(s) since first case (CCKP)',
  month_rain_agg97_06_60 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 59 day(s) since first case (CCKP)',
  month_rain_agg97_06_90 = 'Avg. Decennial Rain (Millimiters) 1997-2006 at at 89 day(s) since first case (CCKP)',

  month_temp_agg07_16_1 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 0 day(s) since first case (CCKP)',
  month_temp_agg07_16_30 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 29 day(s) since first case (CCKP)',
  month_temp_agg07_16_60 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 59 day(s) since first case (CCKP)',
  month_temp_agg07_16_90 = 'Avg. Decennial Temp (Millimiters) 2007-2016 at at 89 day(s) since first case (CCKP)',
  
  month_temp_agg97_06_1 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 0 day(s) since first case (CCKP)',
  month_temp_agg97_06_30 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 29 day(s) since first case (CCKP)',
  month_temp_agg97_06_60 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 59 day(s) since first case (CCKP)',
  month_temp_agg97_06_90 = 'Avg. Decennial Temp (Millimiters) 1997-2006 at at 89 day(s) since first case (CCKP)',

  month_rain_agg07_16_1 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 0 day(s) since first case (CCKP)',
  month_rain_agg07_16_30 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 29 day(s) since first case (CCKP)',
  month_rain_agg07_16_60 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 59 day(s) since first case (CCKP)',
  month_rain_agg07_16_90 = 'Avg. Decennial Rain (Millimiters) 2007-2016 at at 89 day(s) since first case (CCKP)'
)


#World Bank Climate Data, Aggregated Decennial. decennial average temperature (celsius) and rainfall (milliliters) from the Climate Change Knowledge Portal, by getting the average number of the available monthly data by country: one from 1997-2006, and other from 2017-2016
```


# Shiny Application

You can access our web app from [here](https://agscl.shinyapps.io/application).

# Codebook Deployment

```{r prepare_codebook, echo=T}

invisible(c("DataExp"))
#https://boxuancui.github.io/DataExplorer/
#DataExplorer::create_report(coronavirus_iso3c_8)
df_def<-
data.frame(cbind(var_name= names(codebook_data),var_def=data.table(codebook::var_label(codebook_data), keep.rownames = T), type=data.table(sapply(codebook_data, class)),can_be_na=data.table(rep(FALSE,length(names(codebook_data))))))%>%
  dplyr::rename("var_def"="var_def.V1","type"="type.V1","can_be_na"="can_be_na.V1")
    
mostrar="no"
    if(mostrar=="si"){
        ExPanDaR::ExPanD(df = codebook_data,
               export_nb_option = F,  #para proteger la base de datos
               title= "COVID19 Exploration of Dataset", 
               abstract= "Summarised information of the variables. ID: iso_code" ,
               df_name= "COVID19_Cons", 
              # df_def= df_def,
               cs_id = "iso_code",
               key_phrase = "ags", #proteger la bd
               store_encrypted= T) 
    }

library(codebook)
    invisible(c("Esto es para recoger cosas de dropbox"))
evento="no"
if(evento=="si"){
    template <- tempfile(fileext = ".xlsx")
    httr::GET(url = "https://dl.dropbox.com/s/61ektijkh8cge9c/HOMOLOGACION_COMUNAS.xlsx?dl=0",
              httr::write_disk(template))
    HOMOLOGACION_COMUNAS <- readxl::read_excel(template)%>% 
                            dplyr::distinct(cod_comuna,.keep_all=T)%>%
                            data.frame()
}

# to import an SPSS file from the same folder uncomment and edit the line below
# codebook_data <- rio::import("mydata.sav")
# for Stata
# codebook_data <- rio::import("mydata.dta")
# for CSV
# codebook_data <- rio::import("mydata.csv")

# omit the following lines, if your missing values are already properly labelled
codebook_data <- detect_missing(codebook_data,
    only_labelled = TRUE, # only labelled values are autodetected as
                                   # missing
    negative_values_are_missing = FALSE, # negative values are missing values
    ninety_nine_problems = FALSE,   # 99/999 are missing values, if they
                                   # are more than 5 MAD from the median
    )

# If you are not using formr, the codebook package needs to guess which items
# form a scale. The following line finds item aggregates with names like this:
# scale = scale_1 + scale_2R + scale_3R
# identifying these aggregates allows the codebook function to
# automatically compute reliabilities.
# However, it will not reverse items automatically.
codebook_data <- detect_scales(codebook_data)

      tryCatch(
                     {
      save.image("C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_proj.RData")
      rio::export(codebook_data, "C:/Users/andre/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data.dta")
                     },
                         error = function(e){
      save.image("C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data_proj.RData")
      rio::export(codebook_data, "C:/Users/CISS Fondecyt/Dropbox/Covid-19_2020/Article_SecondManuscript/LT Environmental analysis/Databases/merged_data.dta")
                         }
                   )
sessionInfo()
```

```{r codebook_final, echo=T,error=T}
codebook::codebook(codebook_data) #638622
```


#References

 - Hale T, Angrist N, Kira B, et al. (May 25, 2020). Variation in government responses to COVID-19 (version 6.0).Blavatnik School of Government working paper. https://www.bsg.ox.ac.uk/sites/default/files/2020-05/BSG-WP-2020-032-v6.0.pdf (accessed July 11, 2020).  

- Hart,E. (). rWBclimate: A package for accessing World Bank climate data. R package version 0.1.3
  http://github.com/ropensci/rWBclimate

- Global Burden of Disease Collaborative Network. Global Burden of Disease Study 2017 (GBD 2017) Results. Seattle, United States: Institute for Health Metrics and Evaluation (IHME), 2018. Available from http://ghdx.healthdata.org/gbd-results-tool.
  
